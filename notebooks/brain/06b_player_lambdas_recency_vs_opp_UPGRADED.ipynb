{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e1b0d3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# QEPC â€“ Player Lambdas (Recency + vs Opponent) â€“ Upgraded\n",
    "\n",
    "This notebook builds **roster-aware** player-level Î» (lambda) projections for **points, rebounds, assists** using:\n",
    "\n",
    "- Only games **before** the target game date (no data leakage).\n",
    "- A **lookback window** (default 2 seasons) to avoid ancient-history noise.\n",
    "- **Roster detection** (from game_id if available; otherwise inferred from recent games).\n",
    "- A **share model** (team-total Ã— player share) with recency + vs-opp adjustments (shrunk to prevent tiny-sample madness).\n",
    "- Optional fallback logic for players with little/no history.\n",
    "\n",
    "Numbered cells below are designed to be copy/paste safe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1f447",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 1 â€“ PROJECT ROOT AUTO-DETECT + IMPORTS\n",
    "# ==========================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_project_root(start: Path | None = None, package_name: str = \"qepc\") -> Path | None:\n",
    "    r\"\"\"\n",
    "    Find the QEPC project root by walking upward from CWD and checking common locations.\n",
    "    Works across machines (different Windows usernames) without hardcoding C:/Users/<name>/...\n",
    "    \"\"\"\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "\n",
    "    # 1) Walk up from current directory\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / package_name / \"__init__.py\").exists():\n",
    "            return p\n",
    "        if p.name.lower() == \"qepc_project\" and (p / package_name).exists():\n",
    "            return p\n",
    "\n",
    "    # 2) Environment override (optional)\n",
    "    env = os.getenv(\"QEPC_PROJECT_ROOT\")\n",
    "    if env:\n",
    "        cand = Path(env).expanduser().resolve()\n",
    "        if (cand / package_name / \"__init__.py\").exists():\n",
    "            return cand\n",
    "\n",
    "    # 3) Common spots under home directory\n",
    "    home = Path.home()\n",
    "    for cand in [\n",
    "        home / \"qepc_project\",\n",
    "        home / \"Documents\" / \"qepc_project\",\n",
    "        home / \"Desktop\" / \"qepc_project\",\n",
    "    ]:\n",
    "        if (cand / package_name / \"__init__.py\").exists():\n",
    "            return cand\n",
    "\n",
    "    return None\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not auto-detect your QEPC project root.\\n\"\n",
    "        \"Fix options:\\n\"\n",
    "        \"  1) Open Jupyter with working directory inside your repo\\n\"\n",
    "        \"  2) Or set env var QEPC_PROJECT_ROOT to the repo path\\n\"\n",
    "        \"     e.g. PowerShell:  $env:QEPC_PROJECT_ROOT = 'C:/Users/YOU/qepc_project'\\n\"\n",
    "    )\n",
    "\n",
    "# Make sure Python can import `qepc`\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"âœ… PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "import qepc\n",
    "print(\"âœ… qepc package:\", Path(qepc.__file__).resolve())\n",
    "\n",
    "CACHE_IMPORTS = PROJECT_ROOT / \"cache\" / \"imports\"\n",
    "print(\"ðŸ“¦ CACHE_IMPORTS:\", CACHE_IMPORTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f861e27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 2 â€“ LOAD QEPC-READY EOIN DATA (WITH FALLBACKS)\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "\n",
    "def _coerce_game_date(df: pd.DataFrame, col: str = \"game_date\") -> pd.DataFrame:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\").dt.date\n",
    "    return df\n",
    "\n",
    "def _fallback_load_parquet(name: str) -> pd.DataFrame:\n",
    "    path = CACHE_IMPORTS / name\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing cache file: {path}\")\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "# Try QEPC loaders first (preferred)\n",
    "try:\n",
    "    from qepc.nba.eoin_data_source import (\n",
    "        load_eoin_games,\n",
    "        load_eoin_player_boxes,\n",
    "        load_eoin_team_boxes,\n",
    "        print_eoin_summary,\n",
    "    )\n",
    "\n",
    "    games_qepc = load_eoin_games()\n",
    "    player_boxes_qepc = load_eoin_player_boxes()\n",
    "    team_boxes_qepc = load_eoin_team_boxes()\n",
    "\n",
    "    print_eoin_summary(games_qepc, player_boxes_qepc, team_boxes_qepc)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ QEPC loader import failed; falling back to cached parquet in cache/imports/\")\n",
    "    print(\"   Error:\", repr(e))\n",
    "\n",
    "    games_qepc = _fallback_load_parquet(\"games_qepc.parquet\")\n",
    "    player_boxes_qepc = _fallback_load_parquet(\"player_boxes_qepc.parquet\")\n",
    "    team_boxes_qepc = _fallback_load_parquet(\"team_boxes_qepc.parquet\")\n",
    "\n",
    "# Normalize date columns\n",
    "games_qepc = _coerce_game_date(games_qepc, \"game_date\")\n",
    "player_boxes_qepc = _coerce_game_date(player_boxes_qepc, \"game_date\")\n",
    "team_boxes_qepc = _coerce_game_date(team_boxes_qepc, \"game_date\")\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(\"  games_qepc:\", games_qepc.shape)\n",
    "print(\"  player_boxes_qepc:\", player_boxes_qepc.shape)\n",
    "print(\"  team_boxes_qepc:\", team_boxes_qepc.shape)\n",
    "\n",
    "# Quick schema sanity checks (non-fatal)\n",
    "for col in [\"game_id\", \"team_name\", \"opp_team_name\", \"player_id\", \"points\", \"reboundstotal\", \"assists\", \"numminutes\"]:\n",
    "    if col not in player_boxes_qepc.columns:\n",
    "        print(f\"âš ï¸ player_boxes_qepc missing expected column: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82bcba4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 3 â€“ PICK A GAME (BY DATE + OPTIONAL TEAMS) + GET TEAM TOTAL TARGETS\n",
    "# ==========================================================\n",
    "import datetime as _dt\n",
    "\n",
    "# ----- USER CONTROLS -----\n",
    "GAME_DATE = \"2025-12-05\"        # YYYY-MM-DD\n",
    "HOME_TEAM = \"Celtics\"           # or None\n",
    "AWAY_TEAM = \"Lakers\"            # or None\n",
    "\n",
    "# If your matchup engine exists, use it (best).\n",
    "# Otherwise we fall back to a minimal table built from games_qepc.\n",
    "try:\n",
    "    from qepc.nba.matchups_eoin import build_matchups_for_date\n",
    "    matchups = build_matchups_for_date(GAME_DATE)\n",
    "    print(\"âœ… Loaded matchups via qepc.nba.matchups_eoin.build_matchups_for_date\")\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Could not import matchup engine; using games_qepc as fallback.\")\n",
    "    print(\"   Error:\", repr(e))\n",
    "    gd = pd.to_datetime(GAME_DATE).date()\n",
    "    cols = [c for c in [\"game_id\",\"game_date\",\"home_team_name\",\"away_team_name\",\"home_team_id\",\"away_team_id\"] if c in games_qepc.columns]\n",
    "    matchups = games_qepc[games_qepc[\"game_date\"] == gd][cols].copy()\n",
    "    # fallback team totals if matchup engine missing\n",
    "    matchups[\"exp_home_pts\"] = np.nan\n",
    "    matchups[\"exp_away_pts\"] = np.nan\n",
    "\n",
    "print(\"matchups.shape:\", matchups.shape)\n",
    "display(matchups.head(10))\n",
    "\n",
    "# Pick the game row\n",
    "if HOME_TEAM and AWAY_TEAM:\n",
    "    sel = matchups[\n",
    "        (matchups[\"home_team_name\"].astype(str) == str(HOME_TEAM))\n",
    "        & (matchups[\"away_team_name\"].astype(str) == str(AWAY_TEAM))\n",
    "    ]\n",
    "    if len(sel) == 0:\n",
    "        raise ValueError(f\"No matchup found for {GAME_DATE} with {HOME_TEAM} vs {AWAY_TEAM}.\")\n",
    "    game_row = sel.iloc[0]\n",
    "else:\n",
    "    if len(matchups) == 0:\n",
    "        raise ValueError(f\"No games found for date {GAME_DATE}.\")\n",
    "    game_row = matchups.iloc[0]\n",
    "\n",
    "home_team = str(game_row[\"home_team_name\"])\n",
    "away_team = str(game_row[\"away_team_name\"])\n",
    "asof_date = pd.to_datetime(game_row[\"game_date\"]).date()\n",
    "game_id = int(game_row[\"game_id\"]) if \"game_id\" in game_row and pd.notna(game_row[\"game_id\"]) else None\n",
    "\n",
    "print(\"\\nðŸŽ¯ Selected game:\")\n",
    "print(\"  game_id:\", game_id)\n",
    "print(\"  date:\", asof_date)\n",
    "print(\"  matchup:\", f\"{away_team} @ {home_team}\")\n",
    "\n",
    "home_pts_target = float(game_row.get(\"exp_home_pts\", np.nan))\n",
    "away_pts_target = float(game_row.get(\"exp_away_pts\", np.nan))\n",
    "\n",
    "print(\"\\nTeam point targets from matchup engine (NaN means fallback/unknown):\")\n",
    "print(\"  home_pts_target:\", home_pts_target)\n",
    "print(\"  away_pts_target:\", away_pts_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091b595",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 4 â€“ CONFIG: LOOKBACK WINDOW + MODEL WEIGHTS (NO DATA LEAKAGE)\n",
    "# ==========================================================\n",
    "from datetime import timedelta\n",
    "\n",
    "# How much history to use before the target game date\n",
    "LOOKBACK_DAYS = 365 * 2        # ~2 seasons; increase if you want more stability, decrease if you want more recency\n",
    "LAST_N_GAMES = 10              # player recency window (per player)\n",
    "MIN_GAMES_PLAYER = 5           # minimum games to trust season averages\n",
    "MIN_GAMES_VS_OPP = 3           # minimum games vs opponent to even consider it\n",
    "VSOPP_SHRINK_K = 8             # bigger = more shrinkage toward season avg when vs-opp sample is small\n",
    "\n",
    "# Share-model adjustment strengths\n",
    "W_RECENCY = 0.60               # how much recency nudges shares (0..1)\n",
    "W_VSOPP   = 0.40               # how much matchup history nudges shares (0..1)\n",
    "\n",
    "# Clip factors to avoid nuclear weirdness from tiny samples / injuries / etc.\n",
    "FACTOR_CLIP = (0.60, 1.60)\n",
    "\n",
    "# If True, we build points via TEAM_TOTAL Ã— ADJUSTED_SHARE (recommended).\n",
    "# If False, we build points from blended per-player averages then scale to team total.\n",
    "USE_SHARE_MODEL = True\n",
    "\n",
    "print(\"Config loaded.\")\n",
    "print(\"  LOOKBACK_DAYS:\", LOOKBACK_DAYS)\n",
    "print(\"  LAST_N_GAMES:\", LAST_N_GAMES)\n",
    "print(\"  USE_SHARE_MODEL:\", USE_SHARE_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72fb3c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 5 â€“ BUILD HISTORY SLICE + GET ROSTERS (GAME_ID OR RECENT INFERENCE)\n",
    "# ==========================================================\n",
    "def slice_player_history(player_boxes: pd.DataFrame, asof_date: _dt.date, lookback_days: int) -> pd.DataFrame:\n",
    "    pb = player_boxes.copy()\n",
    "    pb[\"game_date\"] = pd.to_datetime(pb[\"game_date\"], errors=\"coerce\").dt.date\n",
    "    pb = pb[pb[\"game_date\"].notna()]\n",
    "    pb = pb[pb[\"game_date\"] < asof_date]  # STRICTLY BEFORE (no leakage)\n",
    "    if lookback_days is not None and lookback_days > 0:\n",
    "        cutoff = asof_date - timedelta(days=int(lookback_days))\n",
    "        pb = pb[pb[\"game_date\"] >= cutoff]\n",
    "    return pb\n",
    "\n",
    "pb_hist = slice_player_history(player_boxes_qepc, asof_date=asof_date, lookback_days=LOOKBACK_DAYS)\n",
    "print(\"pb_hist rows:\", len(pb_hist), \"| date window:\", (pb_hist[\"game_date\"].min(), pb_hist[\"game_date\"].max()))\n",
    "\n",
    "def roster_from_game_id(player_boxes: pd.DataFrame, game_id: int, team_name: str) -> list[int]:\n",
    "    gp = player_boxes[player_boxes[\"game_id\"].astype(int) == int(game_id)]\n",
    "    ids = gp.loc[gp[\"team_name\"].astype(str) == str(team_name), \"player_id\"].unique()\n",
    "    return sorted(int(x) for x in ids)\n",
    "\n",
    "def roster_from_recent_games(player_boxes_hist: pd.DataFrame, team_name: str, lookback_games: int = 6) -> list[int]:\n",
    "    team_rows = player_boxes_hist[player_boxes_hist[\"team_name\"].astype(str) == str(team_name)].copy()\n",
    "    if len(team_rows) == 0:\n",
    "        return []\n",
    "    # last N unique games for that team (in the history slice)\n",
    "    gids = (\n",
    "        team_rows.sort_values(\"game_date\")[\"game_id\"]\n",
    "        .dropna()\n",
    "        .astype(int)\n",
    "        .drop_duplicates()\n",
    "        .tail(int(lookback_games))\n",
    "        .tolist()\n",
    "    )\n",
    "    ids = team_rows[team_rows[\"game_id\"].astype(int).isin(gids)][\"player_id\"].unique()\n",
    "    return sorted(int(x) for x in ids)\n",
    "\n",
    "def get_roster_ids(game_id: int | None, team_name: str) -> list[int]:\n",
    "    if game_id is not None:\n",
    "        ids = roster_from_game_id(player_boxes_qepc, game_id, team_name)\n",
    "        if len(ids) > 0:\n",
    "            return ids\n",
    "    # fallback (works for \"future\" games where we don't have a game_id roster)\n",
    "    return roster_from_recent_games(pb_hist, team_name, lookback_games=6)\n",
    "\n",
    "home_ids = get_roster_ids(game_id, home_team)\n",
    "away_ids = get_roster_ids(game_id, away_team)\n",
    "\n",
    "print(f\"Roster for {home_team}: {len(home_ids)} players\")\n",
    "print(\"  home_ids:\", home_ids)\n",
    "print(f\"Roster for {away_team}: {len(away_ids)} players\")\n",
    "print(\"  away_ids:\", away_ids)\n",
    "\n",
    "if len(home_ids) == 0 or len(away_ids) == 0:\n",
    "    print(\"âš ï¸ One roster is empty. If this is a future game, increase LOOKBACK_DAYS or make sure pb_hist has recent games.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004ddc8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 6 â€“ BUILD ROSTER USAGE TABLES + VS-OPP SPLITS (POINTS/REB/AST)\n",
    "# ==========================================================\n",
    "def _safe_name_from_rows(rows: pd.DataFrame, pid: int) -> str:\n",
    "    if \"firstname\" in rows.columns and \"lastname\" in rows.columns and len(rows) > 0:\n",
    "        first = str(rows[\"firstname\"].iloc[-1]) if pd.notna(rows[\"firstname\"].iloc[-1]) else \"\"\n",
    "        last  = str(rows[\"lastname\"].iloc[-1]) if pd.notna(rows[\"lastname\"].iloc[-1]) else \"\"\n",
    "        nm = (first + \" \" + last).strip()\n",
    "        if nm and nm.lower() != \"nan\":\n",
    "            return nm\n",
    "    return f\"player_{pid}\"\n",
    "\n",
    "def _add_team_totals(pb_team: pd.DataFrame) -> pd.DataFrame:\n",
    "    totals = (\n",
    "        pb_team.groupby([\"team_name\",\"game_id\"], as_index=False)\n",
    "        .agg(\n",
    "            team_pts=(\"points\",\"sum\"),\n",
    "            team_reb=(\"reboundstotal\",\"sum\"),\n",
    "            team_ast=(\"assists\",\"sum\"),\n",
    "        )\n",
    "    )\n",
    "    out = pb_team.merge(totals, on=[\"team_name\",\"game_id\"], how=\"left\")\n",
    "    for num, den, outcol in [\n",
    "        (\"points\",\"team_pts\",\"points_share\"),\n",
    "        (\"reboundstotal\",\"team_reb\",\"reb_share\"),\n",
    "        (\"assists\",\"team_ast\",\"ast_share\"),\n",
    "    ]:\n",
    "        out[outcol] = np.where(out[den] > 0, out[num] / out[den], np.nan)\n",
    "    return out\n",
    "\n",
    "def build_roster_usage(\n",
    "    pb_hist: pd.DataFrame,\n",
    "    team_name: str,\n",
    "    roster_ids: list[int],\n",
    "    last_n_games: int,\n",
    ") -> pd.DataFrame:\n",
    "    # only history for this team + roster\n",
    "    pb_team = pb_hist[\n",
    "        (pb_hist[\"team_name\"].astype(str) == str(team_name))\n",
    "        & (pb_hist[\"player_id\"].astype(int).isin([int(x) for x in roster_ids]))\n",
    "    ].copy()\n",
    "\n",
    "    pb_team = _add_team_totals(pb_team)\n",
    "\n",
    "    # season-ish aggregates (within history slice)\n",
    "    agg = pb_team.groupby(\"player_id\").agg(\n",
    "        games_played=(\"game_id\", \"nunique\"),\n",
    "        avg_points=(\"points\", \"mean\"),\n",
    "        avg_rebounds=(\"reboundstotal\", \"mean\"),\n",
    "        avg_assists=(\"assists\", \"mean\"),\n",
    "        avg_minutes=(\"numminutes\", \"mean\"),\n",
    "        mean_points_share=(\"points_share\", \"mean\"),\n",
    "        mean_rebounds_share=(\"reb_share\", \"mean\"),\n",
    "        mean_assists_share=(\"ast_share\", \"mean\"),\n",
    "        last_seen=(\"game_date\", \"max\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # last N games per player\n",
    "    pb_team_sorted = pb_team.sort_values([\"player_id\", \"game_date\"])\n",
    "    lastN = pb_team_sorted.groupby(\"player_id\", group_keys=False).tail(int(last_n_games))\n",
    "\n",
    "    last_agg = lastN.groupby(\"player_id\").agg(\n",
    "        pts_avg_lastN=(\"points\",\"mean\"),\n",
    "        reb_avg_lastN=(\"reboundstotal\",\"mean\"),\n",
    "        ast_avg_lastN=(\"assists\",\"mean\"),\n",
    "        min_avg_lastN=(\"numminutes\",\"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    usage = agg.merge(last_agg, on=\"player_id\", how=\"left\")\n",
    "\n",
    "    # player names (last known within this team slice; fallback to global last seen)\n",
    "    names = []\n",
    "    for pid in usage[\"player_id\"].astype(int).tolist():\n",
    "        rows = pb_team_sorted[pb_team_sorted[\"player_id\"].astype(int) == int(pid)]\n",
    "        if len(rows) == 0:\n",
    "            rows = pb_hist[pb_hist[\"player_id\"].astype(int) == int(pid)].sort_values(\"game_date\")\n",
    "        names.append(_safe_name_from_rows(rows, int(pid)))\n",
    "    usage[\"player_name\"] = names\n",
    "    usage[\"team_name\"] = str(team_name)\n",
    "\n",
    "    # ensure every roster_id exists (new guys / no history)\n",
    "    have = set(usage[\"player_id\"].astype(int).tolist())\n",
    "    missing = [int(x) for x in roster_ids if int(x) not in have]\n",
    "    if missing:\n",
    "        fb_rows = []\n",
    "        for pid in missing:\n",
    "            rows = pb_hist[pb_hist[\"player_id\"].astype(int) == int(pid)].sort_values(\"game_date\")\n",
    "            fb_rows.append({\n",
    "                \"player_id\": int(pid),\n",
    "                \"team_name\": str(team_name),\n",
    "                \"player_name\": _safe_name_from_rows(rows, int(pid)),\n",
    "                \"games_played\": 0,\n",
    "                \"avg_points\": 0.0,\n",
    "                \"avg_rebounds\": 0.0,\n",
    "                \"avg_assists\": 0.0,\n",
    "                \"avg_minutes\": 0.0,\n",
    "                \"mean_points_share\": np.nan,\n",
    "                \"mean_rebounds_share\": np.nan,\n",
    "                \"mean_assists_share\": np.nan,\n",
    "                \"pts_avg_lastN\": np.nan,\n",
    "                \"reb_avg_lastN\": np.nan,\n",
    "                \"ast_avg_lastN\": np.nan,\n",
    "                \"min_avg_lastN\": np.nan,\n",
    "                \"last_seen\": pd.NaT,\n",
    "            })\n",
    "        usage = pd.concat([usage, pd.DataFrame(fb_rows)], ignore_index=True)\n",
    "\n",
    "    return usage\n",
    "\n",
    "def build_vs_opp_splits(\n",
    "    pb_hist: pd.DataFrame,\n",
    "    team_name: str,\n",
    "    opp_team_name: str,\n",
    "    roster_ids: list[int],\n",
    ") -> pd.DataFrame:\n",
    "    pb_vs = pb_hist[\n",
    "        (pb_hist[\"team_name\"].astype(str) == str(team_name))\n",
    "        & (pb_hist[\"opp_team_name\"].astype(str) == str(opp_team_name))\n",
    "        & (pb_hist[\"player_id\"].astype(int).isin([int(x) for x in roster_ids]))\n",
    "    ].copy()\n",
    "\n",
    "    if len(pb_vs) == 0:\n",
    "        return pd.DataFrame(columns=[\"player_id\",\"games_vs_opp\",\"pts_vs_opp\",\"reb_vs_opp\",\"ast_vs_opp\"])\n",
    "\n",
    "    splits = pb_vs.groupby(\"player_id\").agg(\n",
    "        games_vs_opp=(\"game_id\",\"nunique\"),\n",
    "        pts_vs_opp=(\"points\",\"mean\"),\n",
    "        reb_vs_opp=(\"reboundstotal\",\"mean\"),\n",
    "        ast_vs_opp=(\"assists\",\"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    return splits\n",
    "\n",
    "# Build usage + splits for both teams\n",
    "home_usage = build_roster_usage(pb_hist, home_team, home_ids, LAST_N_GAMES)\n",
    "away_usage = build_roster_usage(pb_hist, away_team, away_ids, LAST_N_GAMES)\n",
    "\n",
    "home_vs = build_vs_opp_splits(pb_hist, home_team, away_team, home_ids)\n",
    "away_vs = build_vs_opp_splits(pb_hist, away_team, home_team, away_ids)\n",
    "\n",
    "home = home_usage.merge(home_vs, on=\"player_id\", how=\"left\")\n",
    "away = away_usage.merge(away_vs, on=\"player_id\", how=\"left\")\n",
    "\n",
    "print(\"home usage shape:\", home.shape)\n",
    "display(home.sort_values(\"avg_points\", ascending=False).head(12))\n",
    "\n",
    "print(\"away usage shape:\", away.shape)\n",
    "display(away.sort_values(\"avg_points\", ascending=False).head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5d744",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 7 â€“ BUILD PLAYER Î» (POINTS/REB/AST) + SCALE TO TEAM TARGETS\n",
    "# ==========================================================\n",
    "def _clip(x: float, lo: float, hi: float) -> float:\n",
    "    return float(min(max(x, lo), hi))\n",
    "\n",
    "def _ratio_factor(season: float, recent: float, vsopp: float, games_vs: float) -> float:\n",
    "    # recency ratio\n",
    "    f_rec = 1.0\n",
    "    if pd.notna(season) and season > 0 and pd.notna(recent):\n",
    "        f_rec = float(recent) / float(season)\n",
    "\n",
    "    # vs-opp ratio (shrunk toward season to avoid 1-game magic)\n",
    "    f_vs = 1.0\n",
    "    if pd.notna(season) and season > 0 and pd.notna(vsopp) and pd.notna(games_vs) and float(games_vs) >= float(MIN_GAMES_VS_OPP):\n",
    "        g = float(games_vs)\n",
    "        shrunk = (float(vsopp) * g + float(season) * float(VSOPP_SHRINK_K)) / (g + float(VSOPP_SHRINK_K))\n",
    "        f_vs = float(shrunk) / float(season)\n",
    "\n",
    "    # combine (exponent weights)\n",
    "    f = (f_rec ** float(W_RECENCY)) * (f_vs ** float(W_VSOPP))\n",
    "    return _clip(f, FACTOR_CLIP[0], FACTOR_CLIP[1])\n",
    "\n",
    "def _team_points_fallback(team_name: str) -> float:\n",
    "    tmp = pb_hist[pb_hist[\"team_name\"].astype(str) == str(team_name)]\n",
    "    if len(tmp) == 0:\n",
    "        return float(\"nan\")\n",
    "    by_game = tmp.groupby(\"game_id\")[\"points\"].sum()\n",
    "    return float(by_game.mean())\n",
    "\n",
    "def _team_stat_target_from_team_boxes(team_name: str, stat: str) -> float:\n",
    "    # stat in {\"rebounds\",\"assists\"} mapped to likely columns\n",
    "    tb = team_boxes_qepc.copy()\n",
    "    if \"team_name\" not in tb.columns:\n",
    "        return float(\"nan\")\n",
    "    tb = tb[tb[\"team_name\"].astype(str) == str(team_name)]\n",
    "    tb = tb[tb[\"game_date\"].notna()]\n",
    "    tb = tb[tb[\"game_date\"] < asof_date]\n",
    "    if LOOKBACK_DAYS is not None and LOOKBACK_DAYS > 0:\n",
    "        cutoff = asof_date - timedelta(days=int(LOOKBACK_DAYS))\n",
    "        tb = tb[tb[\"game_date\"] >= cutoff]\n",
    "\n",
    "    candidates = []\n",
    "    if stat == \"rebounds\":\n",
    "        candidates = [\"reboundstotal\",\"reboundsTotal\",\"rebounds_total\",\"reb_total\"]\n",
    "    elif stat == \"assists\":\n",
    "        candidates = [\"assists\",\"ast\",\"assists_total\"]\n",
    "    elif stat == \"points\":\n",
    "        candidates = [\"points\",\"pts\",\"score\"]\n",
    "    for c in candidates:\n",
    "        if c in tb.columns:\n",
    "            val = tb[c].mean()\n",
    "            return float(val) if pd.notna(val) else float(\"nan\")\n",
    "    return float(\"nan\")\n",
    "\n",
    "def _team_stat_target_from_player_boxes(team_name: str, col: str) -> float:\n",
    "    tmp = pb_hist[pb_hist[\"team_name\"].astype(str) == str(team_name)]\n",
    "    if len(tmp) == 0:\n",
    "        return float(\"nan\")\n",
    "    by_game = tmp.groupby(\"game_id\")[col].sum()\n",
    "    return float(by_game.mean())\n",
    "\n",
    "def _get_team_targets(team_name: str) -> dict:\n",
    "    pts = _team_points_fallback(team_name)\n",
    "    reb = _team_stat_target_from_team_boxes(team_name, \"rebounds\")\n",
    "    ast = _team_stat_target_from_team_boxes(team_name, \"assists\")\n",
    "\n",
    "    if not np.isfinite(reb):\n",
    "        reb = _team_stat_target_from_player_boxes(team_name, \"reboundstotal\")\n",
    "    if not np.isfinite(ast):\n",
    "        ast = _team_stat_target_from_player_boxes(team_name, \"assists\")\n",
    "\n",
    "    return {\"pts\": pts, \"reb\": reb, \"ast\": ast}\n",
    "\n",
    "home_targets = _get_team_targets(home_team)\n",
    "away_targets = _get_team_targets(away_team)\n",
    "\n",
    "# If matchup engine gave point targets, use them; otherwise fall back to team averages in history slice.\n",
    "if not np.isfinite(home_pts_target):\n",
    "    home_pts_target = home_targets[\"pts\"]\n",
    "if not np.isfinite(away_pts_target):\n",
    "    away_pts_target = away_targets[\"pts\"]\n",
    "\n",
    "print(\"Team targets (points from matchup engine if available):\")\n",
    "print(\"  home:\", home_team, \"| pts:\", home_pts_target, \"| reb:\", home_targets[\"reb\"], \"| ast:\", home_targets[\"ast\"])\n",
    "print(\"  away:\", away_team, \"| pts:\", away_pts_target, \"| reb:\", away_targets[\"reb\"], \"| ast:\", away_targets[\"ast\"])\n",
    "\n",
    "def _base_share_fallback(df: pd.DataFrame, season_col: str, share_col: str) -> pd.Series:\n",
    "    s = df[share_col]\n",
    "    if s.notna().sum() > 0 and float(s.fillna(0).sum()) > 0:\n",
    "        return s\n",
    "    # fallback to season averages\n",
    "    denom = df[season_col].fillna(0).sum()\n",
    "    if denom <= 0:\n",
    "        return pd.Series(np.ones(len(df)) / max(len(df), 1), index=df.index)\n",
    "    return df[season_col].fillna(0) / denom\n",
    "\n",
    "def build_team_lambdas(team_df: pd.DataFrame, team_pts: float, team_reb: float, team_ast: float) -> pd.DataFrame:\n",
    "    df = team_df.copy()\n",
    "\n",
    "    # ---- POINTS ----\n",
    "    if USE_SHARE_MODEL:\n",
    "        base = _base_share_fallback(df, \"avg_points\", \"mean_points_share\")\n",
    "        factors = df.apply(\n",
    "            lambda r: _ratio_factor(\n",
    "                r.get(\"avg_points\", np.nan),\n",
    "                r.get(\"pts_avg_lastN\", np.nan),\n",
    "                r.get(\"pts_vs_opp\", np.nan),\n",
    "                r.get(\"games_vs_opp\", np.nan),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        adj = base.fillna(0) * factors.astype(float)\n",
    "        if float(adj.sum()) <= 0:\n",
    "            adj = np.ones(len(df))\n",
    "        share = adj / float(adj.sum())\n",
    "        df[\"lambda_points\"] = float(team_pts) * share\n",
    "    else:\n",
    "        # blended per-player mean then scaled (older approach)\n",
    "        w_season, w_recent, w_vs = 0.50, 0.35, 0.15\n",
    "        def _blend(season, recent, vs, games_vs):\n",
    "            parts, weights = [], []\n",
    "            if pd.notna(season): parts.append(float(season)); weights.append(w_season)\n",
    "            if pd.notna(recent): parts.append(float(recent)); weights.append(w_recent)\n",
    "            if pd.notna(vs) and pd.notna(games_vs) and float(games_vs) >= float(MIN_GAMES_VS_OPP):\n",
    "                parts.append(float(vs)); weights.append(w_vs)\n",
    "            if not parts: return 0.0\n",
    "            w = np.array(weights, dtype=float); w = w / w.sum()\n",
    "            return float(np.dot(parts, w))\n",
    "        df[\"lambda_points_raw\"] = df.apply(lambda r: _blend(r.get(\"avg_points\",np.nan), r.get(\"pts_avg_lastN\",np.nan), r.get(\"pts_vs_opp\",np.nan), r.get(\"games_vs_opp\",np.nan)), axis=1)\n",
    "        s = float(df[\"lambda_points_raw\"].sum())\n",
    "        df[\"lambda_points\"] = df[\"lambda_points_raw\"] * (float(team_pts)/s) if s > 0 else df[\"lambda_points_raw\"]\n",
    "\n",
    "    # ---- REBOUNDS ----\n",
    "    base_reb = _base_share_fallback(df, \"avg_rebounds\", \"mean_rebounds_share\")\n",
    "    reb_factors = df.apply(\n",
    "        lambda r: _ratio_factor(\n",
    "            r.get(\"avg_rebounds\", np.nan),\n",
    "            r.get(\"reb_avg_lastN\", np.nan),\n",
    "            r.get(\"reb_vs_opp\", np.nan),\n",
    "            r.get(\"games_vs_opp\", np.nan),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    adj_reb = base_reb.fillna(0) * reb_factors.astype(float)\n",
    "    if float(adj_reb.sum()) <= 0:\n",
    "        adj_reb = np.ones(len(df))\n",
    "    reb_share = adj_reb / float(adj_reb.sum())\n",
    "    df[\"lambda_rebounds\"] = float(team_reb) * reb_share if np.isfinite(team_reb) else df.get(\"avg_rebounds\", 0.0)\n",
    "\n",
    "    # ---- ASSISTS ----\n",
    "    base_ast = _base_share_fallback(df, \"avg_assists\", \"mean_assists_share\")\n",
    "    ast_factors = df.apply(\n",
    "        lambda r: _ratio_factor(\n",
    "            r.get(\"avg_assists\", np.nan),\n",
    "            r.get(\"ast_avg_lastN\", np.nan),\n",
    "            r.get(\"ast_vs_opp\", np.nan),\n",
    "            r.get(\"games_vs_opp\", np.nan),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    adj_ast = base_ast.fillna(0) * ast_factors.astype(float)\n",
    "    if float(adj_ast.sum()) <= 0:\n",
    "        adj_ast = np.ones(len(df))\n",
    "    ast_share = adj_ast / float(adj_ast.sum())\n",
    "    df[\"lambda_assists\"] = float(team_ast) * ast_share if np.isfinite(team_ast) else df.get(\"avg_assists\", 0.0)\n",
    "\n",
    "    return df\n",
    "\n",
    "home_lambdas = build_team_lambdas(home, team_pts=home_pts_target, team_reb=home_targets[\"reb\"], team_ast=home_targets[\"ast\"])\n",
    "away_lambdas = build_team_lambdas(away, team_pts=away_pts_target, team_reb=away_targets[\"reb\"], team_ast=away_targets[\"ast\"])\n",
    "\n",
    "print(\"\\nSanity checks (sums):\")\n",
    "print(\"  sum(home Î»_points):\", round(float(home_lambdas[\"lambda_points\"].sum()), 3))\n",
    "print(\"  sum(away Î»_points):\", round(float(away_lambdas[\"lambda_points\"].sum()), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f950da",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CELL 8 â€“ CLEAN VIEW OUTPUT + TOP PLAYERS\n",
    "# ==========================================================\n",
    "def clean_view(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = [\n",
    "        \"team_name\",\"player_id\",\"player_name\",\n",
    "        \"games_played\",\n",
    "        \"avg_points\",\"pts_avg_lastN\",\"pts_vs_opp\",\"games_vs_opp\",\"lambda_points\",\n",
    "        \"avg_rebounds\",\"reb_avg_lastN\",\"reb_vs_opp\",\"lambda_rebounds\",\n",
    "        \"avg_assists\",\"ast_avg_lastN\",\"ast_vs_opp\",\"lambda_assists\",\n",
    "        \"last_seen\",\n",
    "    ]\n",
    "    keep = [c for c in cols if c in df.columns]\n",
    "    out = df[keep].copy()\n",
    "\n",
    "    # nicer rounding\n",
    "    for c in [x for x in out.columns if x.startswith(\"avg_\") or x.endswith(\"_lastN\") or x.startswith(\"pts_\") or x.startswith(\"reb_\") or x.startswith(\"ast_\") or x.startswith(\"lambda_\")]:\n",
    "        if c in out.columns and pd.api.types.is_numeric_dtype(out[c]):\n",
    "            out[c] = out[c].astype(float).round(3)\n",
    "    return out\n",
    "\n",
    "home_view = clean_view(home_lambdas).sort_values(\"lambda_points\", ascending=False).reset_index(drop=True)\n",
    "away_view = clean_view(away_lambdas).sort_values(\"lambda_points\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top home players by Î»_points:\")\n",
    "display(home_view.head(12))\n",
    "\n",
    "print(\"Top away players by Î»_points:\")\n",
    "display(away_view.head(12))\n",
    "\n",
    "final_view = pd.concat([home_view, away_view], ignore_index=True)\n",
    "print(\"\\nFINAL (home + away) preview:\")\n",
    "display(final_view.head(30))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
