{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543451c8-e684-44de-90d5-61e7968f872b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parents[1]\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"qepc in root?\", (PROJECT_ROOT / \"qepc\").exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ad79b-3898-463e-86f8-4d834196f483",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from qepc.brain.games_loader import fetch_league_games, build_games_table\n",
    "from qepc.brain.scripts import label_game_scripts_by_total_points\n",
    "from qepc.brain.lambda_builder import build_script_level_lambdas\n",
    "\n",
    "season = \"2023-24\"\n",
    "\n",
    "team_games = fetch_league_games(season)\n",
    "games_df = build_games_table(team_games)\n",
    "\n",
    "print(\"games_df rows:\", len(games_df))\n",
    "display(games_df.head())\n",
    "\n",
    "scripts_df = label_game_scripts_by_total_points(\n",
    "    games_df,\n",
    "    low_quantile=0.25,\n",
    "    high_quantile=0.75,\n",
    ")\n",
    "\n",
    "print(\"scripts_df rows:\", len(scripts_df))\n",
    "display(scripts_df.head())\n",
    "\n",
    "script_lambdas = build_script_level_lambdas(games_df, scripts_df)\n",
    "\n",
    "print(\"Script-level lambdas:\")\n",
    "display(script_lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd4381-e7da-497e-a67f-47730b5034aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from qepc.brain.teams_loader import fetch_league_team_season_stats\n",
    "import pandas as pd\n",
    "\n",
    "# Advanced team stats (OFF_RATING, DEF_RATING, NET_RATING, PACE, PIE)\n",
    "team_stats_adv = fetch_league_team_season_stats(\n",
    "    season,\n",
    "    measure_type=\"Advanced\",\n",
    ")\n",
    "\n",
    "adv_cols_keep = [\n",
    "    \"TEAM_ID\",\n",
    "    \"TEAM_NAME\",\n",
    "    \"TEAM_ABBREVIATION\",\n",
    "    \"GP\",\n",
    "    \"W\",\n",
    "    \"L\",\n",
    "    \"W_PCT\",\n",
    "    \"MIN\",\n",
    "    \"OFF_RATING\",\n",
    "    \"DEF_RATING\",\n",
    "    \"NET_RATING\",\n",
    "    \"PACE\",\n",
    "    \"PIE\",\n",
    "]\n",
    "adv_cols_keep = [c for c in adv_cols_keep if c in team_stats_adv.columns]\n",
    "team_adv_small = team_stats_adv[adv_cols_keep].copy()\n",
    "\n",
    "home_adv = team_adv_small.add_prefix(\"HOME_\")\n",
    "away_adv = team_adv_small.add_prefix(\"AWAY_\")\n",
    "\n",
    "games_feat = games_df.copy()\n",
    "\n",
    "games_feat = games_feat.merge(\n",
    "    home_adv,\n",
    "    left_on=\"HOME_TEAM_ID\",\n",
    "    right_on=\"HOME_TEAM_ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "games_feat = games_feat.merge(\n",
    "    away_adv,\n",
    "    left_on=\"AWAY_TEAM_ID\",\n",
    "    right_on=\"AWAY_TEAM_ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(\"games_feat shape:\", games_feat.shape)\n",
    "display(games_feat.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c3ab7-089e-40d3-834e-5c11674ff381",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "games_with_scripts = games_feat.merge(\n",
    "    scripts_df[[\"GAME_ID\", \"SCRIPT_LABEL\", \"SCRIPT_INDEX\"]],\n",
    "    on=\"GAME_ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(\"games_with_scripts shape:\", games_with_scripts.shape)\n",
    "display(games_with_scripts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b97cd-4a0e-4dfb-a32f-92ba654c9ee9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_dir = PROJECT_ROOT / \"data\" / \"processed\" / \"nba\" / \"models\"\n",
    "model_path = model_dir / f\"script_classifier_rf_{season}.joblib\"\n",
    "\n",
    "print(\"Loading classifier from:\", model_path)\n",
    "clf = joblib.load(model_path)\n",
    "\n",
    "print(\"Loaded classifier:\", clf)\n",
    "print(\"Classes:\", clf.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40cbdf3-937c-465b-897b-dea8c73786a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_cols = [\n",
    "    \"HOME_OFF_RATING\",\n",
    "    \"HOME_DEF_RATING\",\n",
    "    \"HOME_NET_RATING\",\n",
    "    \"HOME_PACE\",\n",
    "    \"HOME_PIE\",\n",
    "    \"AWAY_OFF_RATING\",\n",
    "    \"AWAY_DEF_RATING\",\n",
    "    \"AWAY_NET_RATING\",\n",
    "    \"AWAY_PACE\",\n",
    "    \"AWAY_PIE\",\n",
    "]\n",
    "\n",
    "feature_cols = [c for c in feature_cols if c in games_with_scripts.columns]\n",
    "print(\"Using feature columns:\", feature_cols)\n",
    "\n",
    "model_df = games_with_scripts.dropna(subset=[\"SCRIPT_INDEX\"]).copy()\n",
    "X_all = model_df[feature_cols].values.astype(float)\n",
    "\n",
    "print(\"model_df shape:\", model_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb7de5-b4e2-4a5c-99f7-87fb2465dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one game to demo\n",
    "row_idx = 0  # you can change this to inspect a different game\n",
    "\n",
    "game_row = model_df.iloc[row_idx]\n",
    "x_row = X_all[row_idx : row_idx + 1]  # 2D slice for sklearn\n",
    "\n",
    "print(\"Available columns in game_row:\")\n",
    "print(list(game_row.index))\n",
    "\n",
    "# Try to show the most informative ones that exist\n",
    "candidate_cols = [\n",
    "    \"GAME_ID\",\n",
    "    \"GAME_DATE\",\n",
    "    \"HOME_TEAM_NAME\",\n",
    "    \"AWAY_TEAM_NAME\",\n",
    "    \"HOME_TEAM\",\n",
    "    \"AWAY_TEAM\",\n",
    "    \"HOME_TEAM_ABBREVIATION\",\n",
    "    \"AWAY_TEAM_ABBREVIATION\",\n",
    "    \"HOME_TEAM_TRICODE\",\n",
    "    \"AWAY_TEAM_TRICODE\",\n",
    "    \"TOTAL_POINTS\",\n",
    "    \"SCRIPT_LABEL\",\n",
    "]\n",
    "\n",
    "preview_cols = [c for c in candidate_cols if c in game_row.index]\n",
    "\n",
    "print(\"\\nDemo game (subset of columns):\")\n",
    "display(game_row[preview_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb7c32-e8eb-44c3-ae0b-44d13b9c2af2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_row)[0]  # shape (3,)\n",
    "class_order = list(clf.classes_)     # e.g. [0, 1, 2]\n",
    "\n",
    "# Map class indices to GRIND/BALANCED/CHAOS\n",
    "i_grind = class_order.index(0)\n",
    "i_bal   = class_order.index(1)\n",
    "i_chaos = class_order.index(2)\n",
    "\n",
    "p_grind = float(probs[i_grind])\n",
    "p_bal   = float(probs[i_bal])\n",
    "p_chaos = float(probs[i_chaos])\n",
    "\n",
    "print(\"Script probabilities for this game:\")\n",
    "print(f\"P_GRIND   = {p_grind:.3f}\")\n",
    "print(f\"P_BALANCED= {p_bal:.3f}\")\n",
    "print(f\"P_CHAOS   = {p_chaos:.3f}\")\n",
    "print(\"Sum:\", p_grind + p_bal + p_chaos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec979515-24a9-4187-b8ac-c3d082b29495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qepc.brain.lambda_builder import expected_total_from_script_mix\n",
    "\n",
    "expected_total = expected_total_from_script_mix(\n",
    "    script_lambdas=script_lambdas,\n",
    "    p_grind=p_grind,\n",
    "    p_balanced=p_bal,\n",
    "    p_chaos=p_chaos,\n",
    ")\n",
    "\n",
    "print(\"\\nScript-level lambdas:\")\n",
    "display(script_lambdas)\n",
    "\n",
    "print(\"\\nFor this specific game:\")\n",
    "actual_total = float(game_row[\"TOTAL_POINTS\"])\n",
    "print(f\"Actual final total:         {actual_total:.1f}\")\n",
    "print(f\"Script-mixture expected total: {expected_total:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde82124-e1fe-4600-abaa-e151f4072b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Global league-average total for the season\n",
    "league_avg_total = games_df[\"TOTAL_POINTS\"].mean()\n",
    "\n",
    "print(f\"League average total for {season}: {league_avg_total:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c12cb9-98bf-4528-9cc9-3d2c90e67ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qepc.brain.lambda_builder import expected_total_from_script_mix\n",
    "\n",
    "# 1) Script probabilities for all games\n",
    "probs_all = clf.predict_proba(X_all)  # shape (n_games, 3)\n",
    "class_order = list(clf.classes_)      # e.g. [0, 1, 2]\n",
    "\n",
    "i_grind = class_order.index(0)\n",
    "i_bal   = class_order.index(1)\n",
    "i_chaos = class_order.index(2)\n",
    "\n",
    "model_df_with_preds = model_df.copy()\n",
    "\n",
    "model_df_with_preds[\"P_GRIND\"]    = probs_all[:, i_grind]\n",
    "model_df_with_preds[\"P_BALANCED\"] = probs_all[:, i_bal]\n",
    "model_df_with_preds[\"P_CHAOS\"]    = probs_all[:, i_chaos]\n",
    "\n",
    "# 2) Use script mixture to get expected total for each game\n",
    "def _mix_expected_total(row):\n",
    "    return expected_total_from_script_mix(\n",
    "        script_lambdas=script_lambdas,\n",
    "        p_grind=row[\"P_GRIND\"],\n",
    "        p_balanced=row[\"P_BALANCED\"],\n",
    "        p_chaos=row[\"P_CHAOS\"],\n",
    "    )\n",
    "\n",
    "model_df_with_preds[\"EXPECTED_TOTAL_QEPC\"] = model_df_with_preds.apply(\n",
    "    _mix_expected_total,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# 3) Baseline prediction (same number for every game)\n",
    "model_df_with_preds[\"EXPECTED_TOTAL_BASELINE\"] = league_avg_total\n",
    "\n",
    "print(\"model_df_with_preds shape:\", model_df_with_preds.shape)\n",
    "display(model_df_with_preds.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a5633-264a-4ef4-b7bc-01b7c52b389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "actual = model_df_with_preds[\"TOTAL_POINTS\"].values\n",
    "pred_qepc = model_df_with_preds[\"EXPECTED_TOTAL_QEPC\"].values\n",
    "pred_base = model_df_with_preds[\"EXPECTED_TOTAL_BASELINE\"].values\n",
    "\n",
    "# QEPC script-mixture model\n",
    "mae_qepc = mean_absolute_error(actual, pred_qepc)\n",
    "rmse_qepc = np.sqrt(mean_squared_error(actual, pred_qepc))\n",
    "\n",
    "# Baseline: constant league average\n",
    "mae_base = mean_absolute_error(actual, pred_base)\n",
    "rmse_base = np.sqrt(mean_squared_error(actual, pred_base))\n",
    "\n",
    "print(f\"QEPC script-mixture total model ({season})\")\n",
    "print(f\"  MAE  (QEPC)     : {mae_qepc:.3f}\")\n",
    "print(f\"  RMSE (QEPC)     : {rmse_qepc:.3f}\")\n",
    "print()\n",
    "print(\"Baseline: always predict league average total\")\n",
    "print(f\"  MAE  (baseline) : {mae_base:.3f}\")\n",
    "print(f\"  RMSE (baseline) : {rmse_base:.3f}\")\n",
    "print()\n",
    "\n",
    "improve_mae = mae_base - mae_qepc\n",
    "improve_rmse = rmse_base - rmse_qepc\n",
    "print(f\"Improvement in MAE  (baseline - QEPC): {improve_mae:.3f}\")\n",
    "print(f\"Improvement in RMSE (baseline - QEPC): {improve_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc64f25-4568-4b60-9734-775fcc7dd2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945732f-fd23-422c-9a00-71755c346078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ed530-cf79-457b-89ca-2c2f0547cd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d1a03-2825-4229-a545-c0bdeb51e950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921aeca-2b90-47c7-b3a1-171a5da64502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94649caf-a72d-4283-aa3e-39e741e4edb9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
