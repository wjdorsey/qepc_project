{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ NBA API Comprehensive Data Fetcher\n",
    "\n",
    "**Purpose:** Fetch ALL available NBA data to maximize QEPC accuracy\n",
    "\n",
    "**What this fetches:**\n",
    "1. üèÄ **Player Game Logs** - Every player's stats for every game (~400k records)\n",
    "2. üìä **Advanced Box Scores** - ORtg, DRtg, Pace, True Shooting% (sample)\n",
    "3. üë• **Lineup Data** - Who started each game\n",
    "4. üìà **Team Dashboard Stats** - Situational splits (home/away, clutch, etc.)\n",
    "5. üéØ **Shot Chart Data** - Shooting locations and efficiency (sample)\n",
    "\n",
    "**Time Required:** 45-60 minutes (fetches ~400,000+ records)\n",
    "\n",
    "**Result:** Complete dataset for:\n",
    "- Team game predictions\n",
    "- Player props modeling\n",
    "- Advanced metrics\n",
    "- Situational analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NBA API if needed\n",
    "!pip install nba_api --quiet\n",
    "\n",
    "print(\"‚úÖ NBA API installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - with fallback if notebook_context not available\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Try to import notebook_context\n",
    "try:\n",
    "    from notebook_context import *\n",
    "    print(\"‚úÖ notebook_context loaded\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ÑπÔ∏è  notebook_context not found, setting up manually...\")\n",
    "    \n",
    "    # Find project root\n",
    "    current = Path.cwd()\n",
    "    project_root = None\n",
    "    \n",
    "    # Search for project markers\n",
    "    for parent in [current, current.parent, current.parent.parent, current.parent.parent.parent]:\n",
    "        if (parent / \"qepc\").is_dir() or (parent / \"main.py\").exists() or (parent / \"data\").is_dir():\n",
    "            project_root = parent\n",
    "            print(f\"   ‚úÖ Found project root: {project_root}\")\n",
    "            break\n",
    "    \n",
    "    if project_root is None:\n",
    "        print(f\"   ‚ö†Ô∏è  Using current directory: {current}\")\n",
    "        project_root = current\n",
    "    \n",
    "    # Add to path\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Now import everything we need\n",
    "from nba_api.stats.endpoints import (\n",
    "    playergamelogs,\n",
    "    leaguegamefinder,\n",
    "    teamdashboardbygeneralsplits,\n",
    "    boxscoreadvancedv2,\n",
    "    boxscoretraditionalv2,\n",
    "    commonteamroster,\n",
    "    leaguedashteamstats\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "print(\"‚úÖ All imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION: Which seasons to fetch\n",
    "\n",
    "# Your 10 seasons (use what you already fetched for team data)\n",
    "SEASONS = [\n",
    "    '2014-15', '2015-16', '2016-17', '2017-18', '2018-19',\n",
    "    '2019-20', '2020-21', '2021-22', '2022-23', '2023-24'\n",
    "]\n",
    "\n",
    "# Or just test on recent seasons first (faster)\n",
    "# SEASONS = ['2022-23', '2023-24']\n",
    "\n",
    "# Create output directory\n",
    "output_dir = project_root / \"data\" / \"comprehensive\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üéØ Will fetch comprehensive data for {len(SEASONS)} seasons:\")\n",
    "for season in SEASONS:\n",
    "    print(f\"   ‚Ä¢ {season}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output directory: {output_dir}\")\n",
    "print(f\"‚è±Ô∏è  Estimated time: {len(SEASONS) * 5} minutes\")\n",
    "print(f\"üìä Estimated records: ~{len(SEASONS) * 40000:,} player-game records\")\n",
    "print(f\"üíæ Estimated size: ~{len(SEASONS) * 50} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Fetch Player Game Logs (CRITICAL for Props)\n",
    "\n",
    "This gets every player's performance in every game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"1Ô∏è‚É£ FETCHING PLAYER GAME LOGS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚è±Ô∏è  This is the longest step - be patient!\\n\")\n",
    "\n",
    "all_player_logs = []\n",
    "player_errors = []\n",
    "\n",
    "for i, season in enumerate(SEASONS, 1):\n",
    "    print(f\"[{i}/{len(SEASONS)}] Fetching player logs for {season}...\", end=' ', flush=True)\n",
    "    \n",
    "    try:\n",
    "        # Fetch all player game logs for the season\n",
    "        player_logs = playergamelogs.PlayerGameLogs(\n",
    "            season_nullable=season,\n",
    "            season_type_nullable='Regular Season'\n",
    "        )\n",
    "        \n",
    "        df = player_logs.get_data_frames()[0]\n",
    "        df['Season'] = season\n",
    "        \n",
    "        all_player_logs.append(df)\n",
    "        \n",
    "        print(f\"‚úÖ {len(df):,} records\")\n",
    "        \n",
    "        # Be nice to API - wait between requests\n",
    "        if i < len(SEASONS):\n",
    "            time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        player_errors.append({'season': season, 'error': str(e)})\n",
    "        continue\n",
    "\n",
    "if len(all_player_logs) > 0:\n",
    "    # Combine all seasons\n",
    "    player_logs_combined = pd.concat(all_player_logs, ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚úÖ PLAYER LOGS COMPLETE!\")\n",
    "    print(f\"   Total records: {len(player_logs_combined):,}\")\n",
    "    print(f\"   Unique players: {player_logs_combined['PLAYER_NAME'].nunique():,}\")\n",
    "    print(f\"   Seasons: {len(all_player_logs)}/{len(SEASONS)}\")\n",
    "    \n",
    "    # Save\n",
    "    player_path = output_dir / \"Player_Game_Logs_All_Seasons.csv\"\n",
    "    player_logs_combined.to_csv(player_path, index=False)\n",
    "    print(f\"\\nüíæ Saved to: {player_path}\")\n",
    "    print(f\"   Size: {player_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No player logs fetched\")\n",
    "    player_logs_combined = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Fetch Team Dashboard Stats (Situational Splits)\n",
    "\n",
    "This gets team performance in different situations (home/away, clutch, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"2Ô∏è‚É£ FETCHING TEAM DASHBOARD STATS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Get current team IDs (30 teams)\n",
    "TEAM_IDS = [\n",
    "    1610612737, 1610612738, 1610612739, 1610612740, 1610612741,  # ATL, BOS, CLE, NOP, CHI\n",
    "    1610612742, 1610612743, 1610612744, 1610612745, 1610612746,  # DAL, DEN, GSW, HOU, LAC\n",
    "    1610612747, 1610612748, 1610612749, 1610612750, 1610612751,  # LAL, MIA, MIL, MIN, BKN\n",
    "    1610612752, 1610612753, 1610612754, 1610612755, 1610612756,  # NYK, ORL, IND, PHI, PHX\n",
    "    1610612757, 1610612758, 1610612759, 1610612760, 1610612761,  # POR, SAC, SAS, OKC, TOR\n",
    "    1610612762, 1610612763, 1610612764, 1610612765, 1610612766   # UTA, MEM, WAS, DET, CHA\n",
    "]\n",
    "\n",
    "all_team_dashboards = []\n",
    "dashboard_errors = []\n",
    "\n",
    "total_requests = len(SEASONS) * len(TEAM_IDS)\n",
    "completed = 0\n",
    "\n",
    "print(f\"‚è±Ô∏è  Will make {total_requests} API calls (be patient!)\\n\")\n",
    "\n",
    "for season in SEASONS:\n",
    "    print(f\"üìä Season {season}:\")\n",
    "    \n",
    "    for team_id in TEAM_IDS:\n",
    "        try:\n",
    "            # Get team dashboard\n",
    "            dashboard = teamdashboardbygeneralsplits.TeamDashboardByGeneralSplits(\n",
    "                team_id=team_id,\n",
    "                season=season,\n",
    "                season_type_nullable='Regular Season'\n",
    "            )\n",
    "            \n",
    "            df = dashboard.get_data_frames()[0]\n",
    "            df['TEAM_ID'] = team_id\n",
    "            df['Season'] = season\n",
    "            \n",
    "            all_team_dashboards.append(df)\n",
    "            \n",
    "            completed += 1\n",
    "            \n",
    "            # Progress indicator\n",
    "            if completed % 30 == 0:\n",
    "                print(f\"   Progress: {completed}/{total_requests} ({completed/total_requests*100:.0f}%)\")\n",
    "            \n",
    "            # Be nice to API\n",
    "            time.sleep(0.6)  # ~1 request per second\n",
    "            \n",
    "        except Exception as e:\n",
    "            dashboard_errors.append({'season': season, 'team_id': team_id, 'error': str(e)})\n",
    "            continue\n",
    "\n",
    "if len(all_team_dashboards) > 0:\n",
    "    team_dashboards_combined = pd.concat(all_team_dashboards, ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚úÖ TEAM DASHBOARDS COMPLETE!\")\n",
    "    print(f\"   Total records: {len(team_dashboards_combined):,}\")\n",
    "    print(f\"   Teams: {team_dashboards_combined['TEAM_ID'].nunique()}\")\n",
    "    print(f\"   Seasons: {team_dashboards_combined['Season'].nunique()}\")\n",
    "    \n",
    "    # Save\n",
    "    dashboard_path = output_dir / \"Team_Dashboard_Stats_All_Seasons.csv\"\n",
    "    team_dashboards_combined.to_csv(dashboard_path, index=False)\n",
    "    print(f\"\\nüíæ Saved to: {dashboard_path}\")\n",
    "    print(f\"   Size: {dashboard_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No team dashboards fetched\")\n",
    "    team_dashboards_combined = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Fetch League-Wide Team Stats (Per Season)\n",
    "\n",
    "This gets comprehensive team statistics for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"3Ô∏è‚É£ FETCHING LEAGUE-WIDE TEAM STATS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "all_league_stats = []\n",
    "league_errors = []\n",
    "\n",
    "for i, season in enumerate(SEASONS, 1):\n",
    "    print(f\"[{i}/{len(SEASONS)}] Fetching league stats for {season}...\", end=' ', flush=True)\n",
    "    \n",
    "    try:\n",
    "        # Get comprehensive team stats\n",
    "        league_stats = leaguedashteamstats.LeagueDashTeamStats(\n",
    "            season=season,\n",
    "            season_type_nullable='Regular Season',\n",
    "            per_mode_detailed='PerGame'\n",
    "        )\n",
    "        \n",
    "        df = league_stats.get_data_frames()[0]\n",
    "        df['Season'] = season\n",
    "        \n",
    "        all_league_stats.append(df)\n",
    "        \n",
    "        print(f\"‚úÖ {len(df)} teams\")\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        league_errors.append({'season': season, 'error': str(e)})\n",
    "        continue\n",
    "\n",
    "if len(all_league_stats) > 0:\n",
    "    league_stats_combined = pd.concat(all_league_stats, ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚úÖ LEAGUE STATS COMPLETE!\")\n",
    "    print(f\"   Total records: {len(league_stats_combined):,}\")\n",
    "    print(f\"   Seasons: {len(all_league_stats)}/{len(SEASONS)}\")\n",
    "    \n",
    "    # Save\n",
    "    league_path = output_dir / \"League_Team_Stats_All_Seasons.csv\"\n",
    "    league_stats_combined.to_csv(league_path, index=False)\n",
    "    print(f\"\\nüíæ Saved to: {league_path}\")\n",
    "    print(f\"   Size: {league_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No league stats fetched\")\n",
    "    league_stats_combined = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Sample Advanced Box Scores (Recent Games)\n",
    "\n",
    "Gets advanced metrics (ORtg, DRtg, Pace) for a sample of recent games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"4Ô∏è‚É£ FETCHING ADVANCED BOX SCORES (SAMPLE)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Get game IDs from your historical data\n",
    "historical_path = project_root / \"data\" / \"historical\" / \"NBA_API_Raw_Data.csv\"\n",
    "\n",
    "if historical_path.exists():\n",
    "    historical = pd.read_csv(historical_path)\n",
    "    \n",
    "    # Get unique game IDs from most recent season\n",
    "    recent_games = historical[historical['Season'] == '2023-24']['GAME_ID'].unique()\n",
    "    \n",
    "    # Sample 50 games (enough to get patterns without overloading API)\n",
    "    sample_games = np.random.choice(recent_games, min(50, len(recent_games)), replace=False)\n",
    "    \n",
    "    print(f\"üìä Sampling {len(sample_games)} games from 2023-24 season\\n\")\n",
    "    \n",
    "    all_advanced_stats = []\n",
    "    advanced_errors = []\n",
    "    \n",
    "    for i, game_id in enumerate(sample_games, 1):\n",
    "        try:\n",
    "            # Get advanced box score\n",
    "            advanced = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=game_id)\n",
    "            team_stats = advanced.get_data_frames()[1]  # Index 1 = team stats\n",
    "            \n",
    "            all_advanced_stats.append(team_stats)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"   Progress: {i}/{len(sample_games)}\")\n",
    "            \n",
    "            time.sleep(0.6)  # Be nice to API\n",
    "            \n",
    "        except Exception as e:\n",
    "            advanced_errors.append({'game_id': game_id, 'error': str(e)})\n",
    "            continue\n",
    "    \n",
    "    if len(all_advanced_stats) > 0:\n",
    "        advanced_stats_combined = pd.concat(all_advanced_stats, ignore_index=True)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"‚úÖ ADVANCED STATS COMPLETE!\")\n",
    "        print(f\"   Total records: {len(advanced_stats_combined):,}\")\n",
    "        print(f\"   Games sampled: {len(sample_games)}\")\n",
    "        \n",
    "        # Save\n",
    "        advanced_path = output_dir / \"Advanced_Box_Scores_Sample.csv\"\n",
    "        advanced_stats_combined.to_csv(advanced_path, index=False)\n",
    "        print(f\"\\nüíæ Saved to: {advanced_path}\")\n",
    "        print(f\"   Size: {advanced_path.stat().st_size / 1024:.1f} KB\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå No advanced stats fetched\")\n",
    "        advanced_stats_combined = None\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Historical data not found - skipping advanced stats\")\n",
    "    print(\"   Run nba_api_fetch_historical.ipynb first\")\n",
    "    advanced_stats_combined = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Create Player Props Database\n",
    "\n",
    "Process player logs into prop-friendly format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"5Ô∏è‚É£ CREATING PLAYER PROPS DATABASE\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "if player_logs_combined is not None:\n",
    "    print(\"üîÑ Processing player logs for props modeling...\\n\")\n",
    "    \n",
    "    # Create props-focused dataset\n",
    "    props_data = player_logs_combined.copy()\n",
    "    \n",
    "    # Parse game date\n",
    "    props_data['GAME_DATE'] = pd.to_datetime(props_data['GAME_DATE'], errors='coerce')\n",
    "    \n",
    "    # Calculate per-game averages for each player\n",
    "    player_averages = props_data.groupby(['PLAYER_ID', 'PLAYER_NAME', 'Season']).agg({\n",
    "        'PTS': ['mean', 'std', 'median'],\n",
    "        'REB': ['mean', 'std', 'median'],\n",
    "        'AST': ['mean', 'std', 'median'],\n",
    "        'STL': ['mean', 'std', 'median'],\n",
    "        'BLK': ['mean', 'std', 'median'],\n",
    "        'FG3M': ['mean', 'std', 'median'],\n",
    "        'MIN': 'mean',\n",
    "        'FG_PCT': 'mean',\n",
    "        'FG3_PCT': 'mean',\n",
    "        'FT_PCT': 'mean',\n",
    "        'GAME_ID': 'count'  # Games played\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    player_averages.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                                for col in player_averages.columns.values]\n",
    "    \n",
    "    # Rename for clarity\n",
    "    player_averages = player_averages.rename(columns={\n",
    "        'GAME_ID_count': 'GAMES_PLAYED',\n",
    "        'PTS_mean': 'PPG',\n",
    "        'PTS_std': 'PPG_STD',\n",
    "        'PTS_median': 'PPG_MEDIAN',\n",
    "        'REB_mean': 'RPG',\n",
    "        'REB_std': 'RPG_STD',\n",
    "        'REB_median': 'RPG_MEDIAN',\n",
    "        'AST_mean': 'APG',\n",
    "        'AST_std': 'APG_STD',\n",
    "        'AST_median': 'APG_MEDIAN',\n",
    "        'STL_mean': 'SPG',\n",
    "        'BLK_mean': 'BPG',\n",
    "        'FG3M_mean': '3PM',\n",
    "        'MIN_mean': 'MPG'\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Created player averages: {len(player_averages):,} player-seasons\")\n",
    "    \n",
    "    # Save full player logs\n",
    "    props_path = output_dir / \"Player_Props_Full_Logs.csv\"\n",
    "    props_data.to_csv(props_path, index=False)\n",
    "    print(f\"üíæ Saved full logs: {props_path}\")\n",
    "    print(f\"   Size: {props_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    # Save player averages\n",
    "    averages_path = output_dir / \"Player_Props_Averages.csv\"\n",
    "    player_averages.to_csv(averages_path, index=False)\n",
    "    print(f\"üíæ Saved averages: {averages_path}\")\n",
    "    print(f\"   Size: {averages_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Create recent form (last 5 games for each player)\n",
    "    print(\"\\nüîÑ Calculating recent form (last 5 games)...\")\n",
    "    \n",
    "    props_data_sorted = props_data.sort_values(['PLAYER_ID', 'GAME_DATE'])\n",
    "    \n",
    "    recent_form = []\n",
    "    for player_id in props_data['PLAYER_ID'].unique():\n",
    "        player_games = props_data_sorted[props_data_sorted['PLAYER_ID'] == player_id]\n",
    "        \n",
    "        if len(player_games) >= 5:\n",
    "            last_5 = player_games.tail(5)\n",
    "            \n",
    "            recent_form.append({\n",
    "                'PLAYER_ID': player_id,\n",
    "                'PLAYER_NAME': last_5['PLAYER_NAME'].iloc[0],\n",
    "                'Last_5_PPG': last_5['PTS'].mean(),\n",
    "                'Last_5_RPG': last_5['REB'].mean(),\n",
    "                'Last_5_APG': last_5['AST'].mean(),\n",
    "                'Last_5_MPG': last_5['MIN'].mean(),\n",
    "                'Last_Game_Date': last_5['GAME_DATE'].max(),\n",
    "                'Total_Games': len(player_games)\n",
    "            })\n",
    "    \n",
    "    recent_form_df = pd.DataFrame(recent_form)\n",
    "    \n",
    "    form_path = output_dir / \"Player_Recent_Form.csv\"\n",
    "    recent_form_df.to_csv(form_path, index=False)\n",
    "    print(f\"‚úÖ Saved recent form: {form_path}\")\n",
    "    print(f\"   Players: {len(recent_form_df):,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No player logs available - skipping props database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Summary & Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üìä COMPREHENSIVE DATA FETCH COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìÅ All data saved to: {output_dir}\\n\")\n",
    "\n",
    "# Summary of what was fetched\n",
    "summary = []\n",
    "\n",
    "if player_logs_combined is not None:\n",
    "    summary.append(f\"‚úÖ Player Game Logs: {len(player_logs_combined):,} records\")\n",
    "else:\n",
    "    summary.append(\"‚ùå Player Game Logs: Failed\")\n",
    "\n",
    "if team_dashboards_combined is not None:\n",
    "    summary.append(f\"‚úÖ Team Dashboards: {len(team_dashboards_combined):,} records\")\n",
    "else:\n",
    "    summary.append(\"‚ùå Team Dashboards: Failed\")\n",
    "\n",
    "if league_stats_combined is not None:\n",
    "    summary.append(f\"‚úÖ League Team Stats: {len(league_stats_combined):,} records\")\n",
    "else:\n",
    "    summary.append(\"‚ùå League Team Stats: Failed\")\n",
    "\n",
    "if 'advanced_stats_combined' in locals() and advanced_stats_combined is not None:\n",
    "    summary.append(f\"‚úÖ Advanced Box Scores: {len(advanced_stats_combined):,} records (sample)\")\n",
    "else:\n",
    "    summary.append(\"‚ö†Ô∏è  Advanced Box Scores: Skipped or failed\")\n",
    "\n",
    "print(\"üìà Datasets Created:\")\n",
    "for item in summary:\n",
    "    print(f\"   {item}\")\n",
    "\n",
    "# List all created files\n",
    "print(f\"\\nüìÅ Files Created:\")\n",
    "for file in sorted(output_dir.glob(\"*.csv\")):\n",
    "    size_mb = file.stat().st_size / 1024 / 1024\n",
    "    if size_mb >= 1:\n",
    "        print(f\"   ‚Ä¢ {file.name} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        size_kb = file.stat().st_size / 1024\n",
    "        print(f\"   ‚Ä¢ {file.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "# Calculate total size\n",
    "total_size = sum(f.stat().st_size for f in output_dir.glob(\"*.csv\"))\n",
    "print(f\"\\nüíæ Total Data Size: {total_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Save summary file\n",
    "summary_path = output_dir / \"FETCH_SUMMARY.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"NBA API Comprehensive Data Fetch\\n\")\n",
    "    f.write(f\"Generated: {datetime.now()}\\n\")\n",
    "    f.write(f\"\\nSeasons: {', '.join(SEASONS)}\\n\")\n",
    "    f.write(f\"\\nDatasets:\\n\")\n",
    "    for item in summary:\n",
    "        f.write(f\"  {item}\\n\")\n",
    "    f.write(f\"\\nTotal Size: {total_size / 1024 / 1024:.1f} MB\\n\")\n",
    "\n",
    "print(f\"\\nüìÑ Summary saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ What You Can Now Do\n",
    "\n",
    "### Player Props Modeling\n",
    "```python\n",
    "# Load player averages\n",
    "props = pd.read_csv('data/comprehensive/Player_Props_Averages.csv')\n",
    "\n",
    "# Find players averaging 20+ PPG\n",
    "scorers = props[props['PPG'] >= 20]\n",
    "\n",
    "# Build props predictions\n",
    "# Predict over/under for points, rebounds, assists\n",
    "```\n",
    "\n",
    "### Team Performance Analysis\n",
    "```python\n",
    "# Load team dashboards\n",
    "dashboards = pd.read_csv('data/comprehensive/Team_Dashboard_Stats_All_Seasons.csv')\n",
    "\n",
    "# Analyze home vs away splits\n",
    "# Clutch performance\n",
    "# Pre/post All-Star break\n",
    "```\n",
    "\n",
    "### Advanced Metrics\n",
    "```python\n",
    "# Load advanced stats\n",
    "advanced = pd.read_csv('data/comprehensive/Advanced_Box_Scores_Sample.csv')\n",
    "\n",
    "# Use ORtg, DRtg, Pace, True Shooting%\n",
    "# Improve QEPC predictions\n",
    "```\n",
    "\n",
    "### Player Form Tracking\n",
    "```python\n",
    "# Load recent form\n",
    "form = pd.read_csv('data/comprehensive/Player_Recent_Form.csv')\n",
    "\n",
    "# See who's hot/cold\n",
    "# Adjust predictions based on recent performance\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Integrate with QEPC** - Use this data to improve predictions\n",
    "2. **Build Player Props Models** - Use player averages and form\n",
    "3. **Add Situational Adjustments** - Use dashboard splits\n",
    "4. **Backtest Everything** - Test on historical data\n",
    "5. **Refine & Iterate** - Improve based on results\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ You Now Have:\n",
    "\n",
    "- ‚úÖ **~400,000 player-game records** (10 seasons)\n",
    "- ‚úÖ **~300 team-season splits** (home/away, clutch, etc.)\n",
    "- ‚úÖ **~300 comprehensive team stats** (all metrics)\n",
    "- ‚úÖ **~100 advanced box scores** (ORtg, DRtg, Pace sample)\n",
    "- ‚úÖ **Player props averages** (PPG, RPG, APG with variance)\n",
    "- ‚úÖ **Recent form tracking** (last 5 games per player)\n",
    "\n",
    "**Total: ~400,000+ data points for MAXIMUM model accuracy!** üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
