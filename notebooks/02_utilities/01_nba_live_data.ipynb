{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb44b6-3bfe-45d7-b5c8-bd573c99485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# NBA API imports\n",
    "from nba_api.stats.endpoints import ScoreboardV2, LeagueDashTeamStats\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 0) Robustly find QEPC project root and attach it\n",
    "# --------------------------------------------------------------------\n",
    "project_root = Path.cwd()\n",
    "\n",
    "# Walk up until we find qepc_autoload.py or qepc/ package\n",
    "for _ in range(10):\n",
    "    if (project_root / \"qepc_autoload.py\").exists() or (project_root / \"qepc\").is_dir():\n",
    "        break\n",
    "    if project_root.parent == project_root:\n",
    "        break  # reached filesystem root\n",
    "    project_root = project_root.parent\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"[QEPC Live] Project root: {project_root}\")\n",
    "\n",
    "try:\n",
    "    import qepc_autoload  # side-effect: sets paths + prints banner\n",
    "    from qepc.autoload.paths import get_data_dir\n",
    "except ImportError as e:\n",
    "    print(\"âŒ Could not import qepc_autoload or qepc.autoload.paths.\")\n",
    "    print(\"   project_root used:\", project_root)\n",
    "    print(\"   sys.path[0]:\", sys.path[0])\n",
    "    raise e\n",
    "\n",
    "data_dir = get_data_dir()\n",
    "live_dir = data_dir / \"live\"\n",
    "live_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[QEPC Live] data_dir: {data_dir}\")\n",
    "print(f\"[QEPC Live] live_dir: {live_dir}\")\n",
    "\n",
    "\n",
    "# Helper: current NBA season string in NBA API format\n",
    "def current_season_str() -> str:\n",
    "    \"\"\"\n",
    "    Return current NBA season string like '2024-25'.\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timezone\n",
    "\n",
    "    today = datetime.now(timezone.utc)\n",
    "    year = today.year\n",
    "    # NBA season usually starts in Oct; if month < 7, we are in the tail of previous season\n",
    "    if today.month < 7:\n",
    "        start = year - 1\n",
    "        end = year\n",
    "    else:\n",
    "        start = year\n",
    "        end = year + 1\n",
    "    return f\"{start}-{str(end)[-2:]}\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1) Fetch today's games from NBA API (ScoreboardV2)\n",
    "# --------------------------------------------------------------------\n",
    "print(\"\\nðŸ“¡ Fetching today's games from NBA API (ScoreboardV2)...\")\n",
    "\n",
    "sb = ScoreboardV2()\n",
    "games_df = sb.game_header.get_data_frame()\n",
    "lines_df = sb.line_score.get_data_frame()\n",
    "\n",
    "print(f\"[Scoreboard] Games returned: {len(games_df)}\")\n",
    "print(f\"[Scoreboard] line_score columns: {list(lines_df.columns)}\")\n",
    "\n",
    "if len(games_df) == 0:\n",
    "    print(\"âš ï¸ No games found for today from ScoreboardV2.\")\n",
    "else:\n",
    "    # TEAM_NAME is always present; TEAM_NICKNAME may not be\n",
    "    team_name_col = \"TEAM_NICKNAME\" if \"TEAM_NICKNAME\" in lines_df.columns else \"TEAM_NAME\"\n",
    "\n",
    "    # Join line_score with game_header to get HOME_TEAM_ID / VISITOR_TEAM_ID\n",
    "    merged_ls = lines_df.merge(\n",
    "        games_df[[\"GAME_ID\", \"HOME_TEAM_ID\", \"VISITOR_TEAM_ID\"]],\n",
    "        on=\"GAME_ID\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Debug: show how IDs look\n",
    "    print(\"\\n[Debug] Sample merged line_score + header IDs:\")\n",
    "    print(\n",
    "        merged_ls[\n",
    "            [\"GAME_ID\", \"TEAM_ID\", \"HOME_TEAM_ID\", \"VISITOR_TEAM_ID\"]\n",
    "        ].head()\n",
    "    )\n",
    "\n",
    "    # Select the columns we care about\n",
    "    teams_df = merged_ls[\n",
    "        [\n",
    "            \"GAME_ID\",\n",
    "            \"TEAM_ID\",\n",
    "            \"TEAM_ABBREVIATION\" if \"TEAM_ABBREVIATION\" in merged_ls.columns else \"TEAM_ID\",\n",
    "            \"TEAM_CITY_NAME\",\n",
    "            team_name_col,\n",
    "            \"PTS\",\n",
    "            \"HOME_TEAM_ID\",\n",
    "            \"VISITOR_TEAM_ID\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    # Normalize column names\n",
    "    if \"TEAM_ABBREVIATION\" in teams_df.columns:\n",
    "        teams_df = teams_df.rename(columns={\"TEAM_ABBREVIATION\": \"TEAM_ABBREV\"})\n",
    "    else:\n",
    "        teams_df = teams_df.rename(columns={\"TEAM_ID\": \"TEAM_ABBREV\"})\n",
    "\n",
    "    teams_df = teams_df.rename(columns={team_name_col: \"TEAM_NAME\"})\n",
    "\n",
    "    # Make sure IDs are comparable (string-safe)\n",
    "    teams_df[\"TEAM_ID_str\"] = teams_df[\"TEAM_ID\"].astype(str)\n",
    "    teams_df[\"HOME_ID_str\"] = teams_df[\"HOME_TEAM_ID\"].astype(str)\n",
    "    teams_df[\"VIS_ID_str\"] = teams_df[\"VISITOR_TEAM_ID\"].astype(str)\n",
    "\n",
    "    teams_df[\"is_home\"] = teams_df[\"TEAM_ID_str\"] == teams_df[\"HOME_ID_str\"]\n",
    "\n",
    "    home_side = teams_df[teams_df[\"is_home\"]].copy()\n",
    "    away_side = teams_df[~teams_df[\"is_home\"]].copy()\n",
    "\n",
    "    print(f\"\\n[Scoreboard] home_side rows: {len(home_side)}, away_side rows: {len(away_side)}\")\n",
    "\n",
    "    # Fallback: if something went weird and we didn't detect home/away correctly,\n",
    "    # we can approximate by taking first team as home, second as away per game.\n",
    "    if home_side.empty or away_side.empty:\n",
    "        print(\"âš ï¸ Home/away detection via IDs failed; using fallback ordering.\")\n",
    "        # Sort by GAME_ID and TEAM_ID; first row per game = home, second = away\n",
    "        tmp = teams_df.sort_values([\"GAME_ID\", \"TEAM_ID_str\"]).copy()\n",
    "        tmp[\"rank\"] = tmp.groupby(\"GAME_ID\").cumcount()\n",
    "        home_side = tmp[tmp[\"rank\"] == 0].copy()\n",
    "        away_side = tmp[tmp[\"rank\"] == 1].copy()\n",
    "\n",
    "    # Merge into one row per game\n",
    "    merged = (\n",
    "        games_df[[\"GAME_ID\", \"GAME_DATE_EST\"]]\n",
    "        .merge(\n",
    "            home_side[\n",
    "                [\n",
    "                    \"GAME_ID\",\n",
    "                    \"TEAM_ID\",\n",
    "                    \"TEAM_ABBREV\",\n",
    "                    \"TEAM_CITY_NAME\",\n",
    "                    \"TEAM_NAME\",\n",
    "                    \"PTS\",\n",
    "                ]\n",
    "            ],\n",
    "            on=\"GAME_ID\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_home\"),\n",
    "        )\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"TEAM_ID\": \"HOME_TEAM_ID\",\n",
    "                \"TEAM_ABBREV\": \"HOME_TEAM_ABBREV\",\n",
    "                \"TEAM_CITY_NAME\": \"HOME_TEAM_CITY\",\n",
    "                \"TEAM_NAME\": \"HOME_TEAM_NAME\",\n",
    "                \"PTS\": \"HOME_PTS\",\n",
    "            }\n",
    "        )\n",
    "        .merge(\n",
    "            away_side[\n",
    "                [\n",
    "                    \"GAME_ID\",\n",
    "                    \"TEAM_ID\",\n",
    "                    \"TEAM_ABBREV\",\n",
    "                    \"TEAM_CITY_NAME\",\n",
    "                    \"TEAM_NAME\",\n",
    "                    \"PTS\",\n",
    "                ]\n",
    "            ],\n",
    "            on=\"GAME_ID\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_away\"),\n",
    "        )\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"TEAM_ID\": \"AWAY_TEAM_ID\",\n",
    "                \"TEAM_ABBREV\": \"AWAY_TEAM_ABBREV\",\n",
    "                \"TEAM_CITY_NAME\": \"AWAY_TEAM_CITY\",\n",
    "                \"TEAM_NAME\": \"AWAY_TEAM_NAME\",\n",
    "                \"PTS\": \"AWAY_PTS\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # QEPC-friendly names\n",
    "    merged[\"HOME_TEAM_QEPC\"] = merged[\"HOME_TEAM_CITY\"] + \" \" + merged[\"HOME_TEAM_NAME\"]\n",
    "    merged[\"AWAY_TEAM_QEPC\"] = merged[\"AWAY_TEAM_CITY\"] + \" \" + merged[\"AWAY_TEAM_NAME\"]\n",
    "\n",
    "    games_out = live_dir / \"games_today_nba_api.csv\"\n",
    "    merged.to_csv(games_out, index=False)\n",
    "    print(f\"\\nâœ… Saved today's games to {games_out}\")\n",
    "\n",
    "    display(\n",
    "        merged[\n",
    "            [\n",
    "                \"GAME_DATE_EST\",\n",
    "                \"HOME_TEAM_QEPC\",\n",
    "                \"AWAY_TEAM_QEPC\",\n",
    "                \"HOME_PTS\",\n",
    "                \"AWAY_PTS\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2) Fetch live team advanced stats for current season\n",
    "# --------------------------------------------------------------------\n",
    "season_str = current_season_str()\n",
    "print(f\"\\nðŸ“¡ Fetching LeagueDashTeamStats for season: {season_str}\")\n",
    "\n",
    "team_stats = LeagueDashTeamStats(\n",
    "    season=season_str,\n",
    "    measure_type_detailed_defense=\"Advanced\",  # OFF_RATING, DEF_RATING, NET_RATING, PACE, etc.\n",
    ")\n",
    "team_df = team_stats.get_data_frames()[0]\n",
    "print(f\"[LeagueDashTeamStats] Teams returned: {len(team_df)}\")\n",
    "print(\"[LeagueDashTeamStats] Columns:\", list(team_df.columns))\n",
    "\n",
    "# Required columns we expect from Advanced:\n",
    "required_cols = [\n",
    "    \"TEAM_ID\",\n",
    "    \"TEAM_NAME\",\n",
    "    \"OFF_RATING\",\n",
    "    \"DEF_RATING\",\n",
    "    \"NET_RATING\",\n",
    "    \"PACE\",\n",
    "]\n",
    "missing_required = [c for c in required_cols if c not in team_df.columns]\n",
    "if missing_required:\n",
    "    raise RuntimeError(f\"LeagueDashTeamStats missing required columns: {missing_required}\")\n",
    "\n",
    "# Optional columns we keep if present\n",
    "optional_cols = [c for c in [\"TEAM_ABBREVIATION\", \"W\", \"L\", \"GP\"] if c in team_df.columns]\n",
    "\n",
    "cols_keep = required_cols + optional_cols\n",
    "\n",
    "live_team_stats = team_df[cols_keep].copy()\n",
    "\n",
    "live_team_stats = live_team_stats.rename(\n",
    "    columns={\n",
    "        \"TEAM_NAME\": \"Team\",\n",
    "        \"OFF_RATING\": \"ORtg_live\",\n",
    "        \"DEF_RATING\": \"DRtg_live\",\n",
    "        \"NET_RATING\": \"NetRtg_live\",\n",
    "        \"PACE\": \"Pace_live\",\n",
    "        \"W\": \"Wins\" if \"W\" in live_team_stats.columns else \"Wins\",\n",
    "        \"L\": \"Losses\" if \"L\" in live_team_stats.columns else \"Losses\",\n",
    "        \"GP\": \"GamesPlayed\" if \"GP\" in live_team_stats.columns else \"GamesPlayed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "live_team_stats[\"Season\"] = season_str\n",
    "\n",
    "team_stats_out = live_dir / \"team_stats_live_nba_api.csv\"\n",
    "live_team_stats.to_csv(team_stats_out, index=False)\n",
    "print(f\"âœ… Saved live team stats to {team_stats_out}\")\n",
    "\n",
    "display(live_team_stats.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407fff3-5397-4353-b95f-75a898ec62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from pathlib import Path\n",
    "\n",
    "from qepc.autoload.paths import get_data_dir\n",
    "\n",
    "def fetch_espn_nba_scoreboard(target_date: date | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pull ESPN NBA scoreboard for a given date and normalize to:\n",
    "      gameDate, Home Team, Away Team, gameId\n",
    "    \"\"\"\n",
    "    if target_date is None:\n",
    "        target_date = date.today()\n",
    "\n",
    "    # ESPN NBA scoreboard endpoint (unofficial but widely used)\n",
    "    url = \"https://site.api.espn.com/apis/site/v2/sports/basketball/nba/scoreboard\"\n",
    "\n",
    "    # ESPN uses 'dates=YYYYMMDD' or omits it for \"today\"\n",
    "    params = {\"dates\": target_date.strftime(\"%Y%m%d\")}\n",
    "\n",
    "    resp = requests.get(url, params=params, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    events = data.get(\"events\", [])\n",
    "    rows = []\n",
    "\n",
    "    for ev in events:\n",
    "        game_id = ev.get(\"id\")\n",
    "        # event date\n",
    "        ev_date_raw = ev.get(\"date\")\n",
    "        game_dt = pd.to_datetime(ev_date_raw, errors=\"coerce\")\n",
    "\n",
    "        comps = ev.get(\"competitions\", [])\n",
    "        if not comps:\n",
    "            continue\n",
    "\n",
    "        comp = comps[0]\n",
    "        competitors = comp.get(\"competitors\", [])\n",
    "        if len(competitors) != 2:\n",
    "            continue\n",
    "\n",
    "        home_team_name = None\n",
    "        away_team_name = None\n",
    "\n",
    "        for c in competitors:\n",
    "            team_info = c.get(\"team\", {}) or {}\n",
    "            display_name = team_info.get(\"displayName\")  # \"Boston Celtics\"\n",
    "            if c.get(\"homeAway\") == \"home\":\n",
    "                home_team_name = display_name\n",
    "            elif c.get(\"homeAway\") == \"away\":\n",
    "                away_team_name = display_name\n",
    "\n",
    "        if not home_team_name or not away_team_name:\n",
    "            continue\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"gameDate\": game_dt,\n",
    "                \"Home Team\": home_team_name,\n",
    "                \"Away Team\": away_team_name,\n",
    "                \"gameId\": game_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# --- TEST + SAVE TO data/live/espn_scoreboard_today.csv ---\n",
    "data_dir = get_data_dir()\n",
    "live_dir = Path(data_dir) / \"live\"\n",
    "live_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "today_games_espn = fetch_espn_nba_scoreboard()\n",
    "print(today_games_espn.head())\n",
    "\n",
    "out_path = live_dir / \"espn_scoreboard_today.csv\"\n",
    "today_games_espn.to_csv(out_path, index=False)\n",
    "print(f\"Saved ESPN scoreboard to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332142d-0a2d-4fd5-a074-8d5c6b8e63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from qepc.autoload.paths import get_data_dir\n",
    "\n",
    "BALLDONTLIE_BASE = \"https://api.balldontlie.io/v1\"\n",
    "BALLDONTLIE_API_KEY = \"c5ae7df3-682e-450c-b47e-f7e91396379e\"  # or read from env\n",
    "\n",
    "def fetch_balldontlie_games_for_season(season: int, per_page: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all regular-season games for a given season from balldontlie.\n",
    "    Returns columns similar to your Games.csv:\n",
    "      Date, Time, Away Team, Home Team, Venue, Notes\n",
    "    \"\"\"\n",
    "    headers = {}\n",
    "    if BALLDONTLIE_API_KEY:\n",
    "        headers[\"Authorization\"] = f\"Bearer {BALLDONTLIE_API_KEY}\"\n",
    "\n",
    "    page = 1\n",
    "    all_rows = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"seasons[]\": season,\n",
    "            \"per_page\": per_page,\n",
    "            \"page\": page,\n",
    "            # you can filter type if needed; depends on their schema\n",
    "        }\n",
    "        resp = requests.get(f\"{BALLDONTLIE_BASE}/games\", params=params, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        games = data.get(\"data\", [])\n",
    "        if not games:\n",
    "            break\n",
    "\n",
    "        for g in games:\n",
    "            # balldontlie dates are usually ISO strings\n",
    "            dt = pd.to_datetime(g.get(\"date\"), errors=\"coerce\")\n",
    "\n",
    "            home_team = g.get(\"home_team\", {}) or {}\n",
    "            away_team = g.get(\"visitor_team\", {}) or {}\n",
    "\n",
    "            home_name = home_team.get(\"full_name\") or home_team.get(\"name\")\n",
    "            away_name = away_team.get(\"full_name\") or away_team.get(\"name\")\n",
    "\n",
    "            # You can refine Venue / Notes later if needed\n",
    "            all_rows.append(\n",
    "                {\n",
    "                    \"Date\": dt.date().isoformat() if pd.notna(dt) else None,\n",
    "                    \"Time\": dt.time().strftime(\"%I:%M %p\") if pd.notna(dt) else None,\n",
    "                    \"Away Team\": away_name,\n",
    "                    \"Home Team\": home_name,\n",
    "                    \"Venue\": \"\",\n",
    "                    \"Notes\": g.get(\"season\"),  # placeholder, often regular season\n",
    "                }\n",
    "            )\n",
    "\n",
    "        page += 1\n",
    "        if page > data.get(\"meta\", {}).get(\"total_pages\", page):\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "# --- TEST + SAVE ---\n",
    "data_dir = get_data_dir()\n",
    "raw_dir = Path(data_dir) / \"raw\"\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "games_2025 = fetch_balldontlie_games_for_season(2025)\n",
    "print(games_2025.head())\n",
    "\n",
    "out_path = raw_dir / \"Games_balldontlie_2025.csv\"\n",
    "games_2025.to_csv(out_path, index=False)\n",
    "print(f\"Saved balldontlie games to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f80853-5d07-4c22-b176-bfb6a2dc907b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
