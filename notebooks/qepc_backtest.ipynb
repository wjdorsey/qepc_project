{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9c713d-8d9c-4abe-9025-f8b8f48bc36c",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üìä QEPC NBA Backtest Notebook\n",
    "\n",
    "This notebook measures how well the QEPC NBA engine is performing over time.\n",
    "\n",
    "It focuses on:\n",
    "- üóìÔ∏è Defining a backtest date range\n",
    "- üßÆ Running `run_season_backtest(...)` to simulate all games in that range\n",
    "- üìà Summarizing accuracy & spread error\n",
    "- üß® Inspecting the worst misses\n",
    "- üßπ Filtering to NBA‚Äìvs‚ÄìNBA only (no exhibitions)\n",
    "- üåå (Optional) Script / total-error analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aafe66-976b-4071-8403-3aac9a7400db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28ab68-bb09-4a38-8501-be0364942fa5",
   "metadata": {},
   "source": [
    "## üß© 1. Environment & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5ab958-2b51-4107-ad76-a8cddf655d72",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T04:59:04.680028Z",
     "iopub.status.busy": "2025-11-27T04:59:04.679664Z",
     "iopub.status.idle": "2025-11-27T04:59:05.305629Z",
     "shell.execute_reply": "2025-11-27T04:59:05.304974Z",
     "shell.execute_reply.started": "2025-11-27T04:59:04.679998Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QEPC Paths] Project Root set: /home/2dbcc135-5358-4730-8441-82ada9ea8087/qepc_project\n",
      "[QEPC] Autoload complete.\n",
      "[QEPC] Root Shim Restored. Forwarding to qepc.autoload...\n",
      "Project root: /home/2dbcc135-5358-4730-8441-82ada9ea8087/qepc_project\n"
     ]
    }
   ],
   "source": [
    "# Universal QEPC header for this notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from notebook_context import *  # try direct import first\n",
    "except ModuleNotFoundError:\n",
    "    cwd = Path.cwd()\n",
    "    candidate_roots = [cwd, cwd.parent, cwd.parent.parent]\n",
    "\n",
    "    found_root = None\n",
    "    for root in candidate_roots:\n",
    "        if (root / \"notebook_context.py\").exists():\n",
    "            found_root = root\n",
    "            break\n",
    "\n",
    "    if found_root is None:\n",
    "        raise ModuleNotFoundError(\n",
    "            f\"Could not find notebook_context.py from {cwd}. \"\n",
    "            \"Try opening this notebook from inside your qepc_project folder.\"\n",
    "        )\n",
    "\n",
    "    sys.path.insert(0, str(found_root))\n",
    "    os.chdir(found_root)\n",
    "    from notebook_context import *\n",
    "\n",
    "# Fallback for project_root if notebook_context didn't define it\n",
    "try:\n",
    "    project_root\n",
    "except NameError:\n",
    "    project_root = Path.cwd()\n",
    "\n",
    "print(\"Project root:\", project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9726a-b00f-4eb2-832a-76a98c2a1852",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c12044-1e6b-484c-8dfd-fcb271ae7502",
   "metadata": {},
   "source": [
    "## üìÖ 2. Select Backtest Range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aababd5f-56e4-47b6-9490-0881364834f4",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-11-27T04:59:43.860464Z",
     "iopub.status.busy": "2025-11-27T04:59:43.860167Z",
     "iopub.status.idle": "2025-11-27T04:59:43.865005Z",
     "shell.execute_reply": "2025-11-27T04:59:43.864364Z",
     "shell.execute_reply.started": "2025-11-27T04:59:43.860443Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest date range: 2025-11-24 ‚Üí 2025-11-27\n"
     ]
    }
   ],
   "source": [
    "# 2. Backtest Date Range & Filters (Custom start ‚Üí today, no widgets)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# üëá Edit this line when you want a different start date\n",
    "BACKTEST_START_DATE = date(2025, 11, 24)\n",
    "\n",
    "# End date is always \"today\"\n",
    "BACKTEST_END_DATE = date.today()\n",
    "\n",
    "print(\"Backtest date range:\",\n",
    "      BACKTEST_START_DATE.isoformat(), \"‚Üí\", BACKTEST_END_DATE.isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f58ea-74fd-4e28-bae7-b6663206741b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ebeef-31d8-4bcd-a7a7-ae4dacf767e7",
   "metadata": {},
   "source": [
    "## üßÆ 3. Initiate Backtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593dabeb-12ab-4d23-bfa1-cdc48dd28d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T04:59:46.693306Z",
     "iopub.status.busy": "2025-11-27T04:59:46.692995Z",
     "iopub.status.idle": "2025-11-27T04:59:49.013272Z",
     "shell.execute_reply": "2025-11-27T04:59:49.012472Z",
     "shell.execute_reply.started": "2025-11-27T04:59:46.693286Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running QEPC backtest from 2025-11-24 to 2025-11-27\n",
      "\n",
      "üöÄ STARTING LONG-RANGE BACKTEST (2025-11-24 to 2025-11-27)\n",
      "Processing... (This will update in place)\n",
      "‚è≥ Processing Day 4/4: 2025-11-27\n",
      "‚ùå No games found in this date range.\n",
      "\n",
      "üìä Games simulated: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Run Backtest for Selected Range\n",
    "\n",
    "from qepc.backtest.backtest_engine import run_season_backtest\n",
    "\n",
    "# Convert date objects to ISO format strings (required by the engine)\n",
    "start_date_str = BACKTEST_START_DATE.isoformat()\n",
    "end_date_str = BACKTEST_END_DATE.isoformat()\n",
    "\n",
    "print(f\"üöÄ Running QEPC backtest from {start_date_str} to {end_date_str}\\n\")\n",
    "\n",
    "# The engine handles everything internally:\n",
    "#   - Loads game results from TeamStatistics.csv\n",
    "#   - Calculates team strengths for each day (time-travel)\n",
    "#   - Runs simulations and scores predictions\n",
    "backtest_long = run_season_backtest(start_date_str, end_date_str)\n",
    "\n",
    "print(f\"\\nüìä Games simulated: {len(backtest_long)}\")\n",
    "display(backtest_long.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba482be0-d876-4448-8735-ce6eb2bc002c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7653d-b0a0-4d37-975c-c928a8c3ce85",
   "metadata": {},
   "source": [
    "## üèÅ 4. Global Summary (All Games in Range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f9b19-86fd-4406-9736-06a02948d173",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 4. Global Summary (All Games in Selected Range)\n",
    "\n",
    "if \"backtest_long\" not in globals() or backtest_long.empty:\n",
    "    raise RuntimeError(\"Run Cell 3 (Run Backtest) first!\")\n",
    "\n",
    "total_games = len(backtest_long)\n",
    "accuracy_pct = backtest_long[\"Correct_Pick\"].mean() * 100\n",
    "spread_mae = backtest_long[\"Spread_Error\"].abs().mean()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"üèÜ QEPC BACKTEST SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìÖ Date Range: {BACKTEST_START_DATE} ‚Üí {BACKTEST_END_DATE}\")\n",
    "print(f\"üèÄ Games Simulated: {total_games}\")\n",
    "print(f\"‚úÖ Overall Accuracy: {accuracy_pct:.2f}%\")\n",
    "print(f\"üéØ Avg Spread Error (MAE): {spread_mae:.2f} points\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d68a33-3bc0-4bc5-ac1b-3e392599a469",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf3ce9-3d6c-4633-a7b1-23b9e6a4a7dd",
   "metadata": {},
   "source": [
    "## üßπ 5. Clean NBA-Only View (Filter Out Exhibitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aaf014-e5af-44f5-ba3d-f9a356f49325",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 5. Clean NBA-Only View (Filter Out Exhibitions)\n",
    "\n",
    "NBA_TEAMS = [\n",
    "    \"Atlanta Hawks\", \"Boston Celtics\", \"Brooklyn Nets\", \"Charlotte Hornets\",\n",
    "    \"Chicago Bulls\", \"Cleveland Cavaliers\", \"Dallas Mavericks\", \"Denver Nuggets\",\n",
    "    \"Detroit Pistons\", \"Golden State Warriors\", \"Houston Rockets\", \"Indiana Pacers\",\n",
    "    \"Los Angeles Clippers\", \"Los Angeles Lakers\", \"Memphis Grizzlies\", \"Miami Heat\",\n",
    "    \"Milwaukee Bucks\", \"Minnesota Timberwolves\", \"New Orleans Pelicans\", \"New York Knicks\",\n",
    "    \"Oklahoma City Thunder\", \"Orlando Magic\", \"Philadelphia 76ers\", \"Phoenix Suns\",\n",
    "    \"Portland Trail Blazers\", \"Sacramento Kings\", \"San Antonio Spurs\", \"Toronto Raptors\",\n",
    "    \"Utah Jazz\", \"Washington Wizards\",\n",
    "]\n",
    "\n",
    "backtest_clean = backtest_long[\n",
    "    backtest_long[\"Away Team\"].isin(NBA_TEAMS)\n",
    "    & backtest_long[\"Home Team\"].isin(NBA_TEAMS)\n",
    "].copy()\n",
    "\n",
    "print(f\"Original games: {len(backtest_long)}, After NBA-only filter: {len(backtest_clean)}\")\n",
    "\n",
    "if not backtest_clean.empty:\n",
    "    acc_clean = backtest_clean[\"Correct_Pick\"].mean() * 100\n",
    "    mae_clean = backtest_clean[\"Spread_Error\"].abs().mean()\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"üèÜ CLEAN NBA-ONLY BACKTEST\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üèÄ Games Simulated: {len(backtest_clean)}\")\n",
    "    print(f\"‚úÖ Overall Accuracy: {acc_clean:.2f}%\")\n",
    "    print(f\"üéØ Avg Spread Error: {mae_clean:.2f} points\")\n",
    "    print(\"=\" * 50)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No NBA-only games found in this range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162cdef3-9d2d-40eb-8f02-818c80a7ef1e",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dab5db-8478-497d-aee5-f2dc7d176b5b",
   "metadata": {},
   "source": [
    "## üß® 6. Biggest Misses (Spread Error Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0420bf-a220-47d7-a436-2677d888ae98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 6. Biggest Misses (Spread Error Analysis)\n",
    "\n",
    "# Use the cleaned NBA-only data if available, otherwise use all games\n",
    "df_to_analyze = backtest_clean if not backtest_clean.empty else backtest_long\n",
    "\n",
    "# Sort by absolute spread error (biggest misses first)\n",
    "df_to_analyze = df_to_analyze.copy()\n",
    "df_to_analyze[\"Abs_Spread_Error\"] = df_to_analyze[\"Spread_Error\"].abs()\n",
    "biggest_misses = df_to_analyze.nlargest(10, \"Abs_Spread_Error\")\n",
    "\n",
    "print(\"üß® TOP 10 BIGGEST MISSES (by Spread Error)\")\n",
    "print(\"=\" * 60)\n",
    "display(\n",
    "    biggest_misses[\n",
    "        [\"Date\", \"Away Team\", \"Home Team\", \"Expected_Spread\", \"Actual_Spread\", \"Spread_Error\"]\n",
    "    ].reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6553e5-73b6-4b21-a089-c55df8ce37f2",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af160f-918d-4589-a93d-2b898e15d46c",
   "metadata": {},
   "source": [
    "## üì¶ 7. Spread Error Buckets (How Often & How Bad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92e5bb-16c2-487d-a7de-90a1ff2e1ee3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 7. Brier Score Analysis\n",
    "# \n",
    "# Brier Score measures how well-calibrated your probabilities are.\n",
    "# Lower is better. Perfect = 0.0, Random guessing = 0.25\n",
    "\n",
    "df_brier = backtest_clean.copy() if not backtest_clean.empty else backtest_long.copy()\n",
    "\n",
    "# For each game, compare predicted probability to actual outcome (0 or 1)\n",
    "# Brier Score = mean((predicted_prob - actual_outcome)^2)\n",
    "\n",
    "# Home win probability vs actual home win (1 if home won, 0 if away won)\n",
    "df_brier[\"Actual_Home_Win\"] = (df_brier[\"Actual_Home_Score\"] > df_brier[\"Actual_Away_Score\"]).astype(int)\n",
    "df_brier[\"Brier_Score\"] = (df_brier[\"Home_Win_Prob\"] - df_brier[\"Actual_Home_Win\"]) ** 2\n",
    "\n",
    "avg_brier = df_brier[\"Brier_Score\"].mean()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"üìà BRIER SCORE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Average Brier Score: {avg_brier:.4f}\")\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"  ‚Ä¢ 0.00 = Perfect predictions\")\n",
    "print(\"  ‚Ä¢ 0.25 = Random coin flip\")\n",
    "print(\"  ‚Ä¢ Lower is better!\")\n",
    "print()\n",
    "\n",
    "if avg_brier < 0.20:\n",
    "    print(\"‚úÖ Excellent! Your model is well-calibrated.\")\n",
    "elif avg_brier < 0.22:\n",
    "    print(\"üëç Good. Your model beats random chance significantly.\")\n",
    "elif avg_brier < 0.25:\n",
    "    print(\"‚ö†Ô∏è Okay, but there's room for improvement.\")\n",
    "else:\n",
    "    print(\"‚ùå Model is performing at or below random chance.\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce39e99-8da8-4c52-b1c4-8a18e7f920ad",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5faac5-5b98-42e8-b92e-39c54172b782",
   "metadata": {},
   "source": [
    "## üåå 8. Optional: Total Error & Script Classification (GRIND / BASE / CHAOS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f3829-bf46-4863-b859-f25313deffd2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa26f6e-b590-4700-9fff-c058c03ddf31",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 8. Optional: Total Error & Script Classification (GRIND / BASE / CHAOS)\n",
    "\n",
    "df = backtest_clean.copy()\n",
    "\n",
    "# 8.1 Compute simulated and actual totals\n",
    "df[\"Sim_Total\"] = df[\"Sim_Home_Score\"] + df[\"Sim_Away_Score\"]\n",
    "df[\"Actual_Total\"] = df[\"Actual_Home_Score\"] + df[\"Actual_Away_Score\"]\n",
    "\n",
    "# Drop games where we effectively didn't simulate (Sim_Total == 0)\n",
    "before = len(df)\n",
    "df = df[df[\"Sim_Total\"] > 0]\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after} games with Sim_Total == 0.\")\n",
    "print(f\"Remaining games for script analysis: {after}\")\n",
    "\n",
    "# 8.2 Total error\n",
    "df[\"Total_Error\"] = df[\"Actual_Total\"] - df[\"Sim_Total\"]\n",
    "\n",
    "# Thresholds for GRIND / BASE / CHAOS (can be tuned)\n",
    "grind_thresh = -15   # 15+ pts under model total ‚Üí GRIND\n",
    "chaos_thresh = 15    # 15+ pts over model total ‚Üí CHAOS\n",
    "\n",
    "def classify_script(row):\n",
    "    if row[\"Total_Error\"] <= grind_thresh:\n",
    "        return \"GRIND\"\n",
    "    elif row[\"Total_Error\"] >= chaos_thresh:\n",
    "        return \"CHAOS\"\n",
    "    else:\n",
    "        return \"BASE\"\n",
    "\n",
    "df[\"Script_ExPost\"] = df.apply(classify_script, axis=1)\n",
    "\n",
    "print(\"\\nSample of script labels:\")\n",
    "display(\n",
    "    df[[\"Date\", \"Away Team\", \"Home Team\", \"Sim_Total\", \"Actual_Total\", \"Total_Error\", \"Script_ExPost\"]]\n",
    "    .head()\n",
    ")\n",
    "\n",
    "# 8.3 Script-level summary\n",
    "script_summary = df.groupby(\"Script_ExPost\").agg(\n",
    "    Games=(\"Total_Error\", \"count\"),\n",
    "    Avg_Total_Error=(\"Total_Error\", \"mean\"),\n",
    "    Avg_Abs_Total_Error=(\"Total_Error\", lambda x: x.abs().mean()),\n",
    "    Avg_Spread_Error=(\"Spread_Error\", \"mean\"),\n",
    "    Avg_Abs_Spread_Error=(\"Spread_Error\", lambda x: x.abs().mean()),\n",
    ")\n",
    "\n",
    "script_summary[\"Percent\"] = (script_summary[\"Games\"] / len(df) * 100).round(2)\n",
    "\n",
    "print(\"\\nEx-post script distribution (based on totals):\")\n",
    "display(script_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36091349-86a6-4eb9-9cfb-38867b2d3bed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scrollable"
    ]
   },
   "source": [
    "## Global Lambda Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209aa9c-c6e2-40d9-a650-831b57f0f550",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# === QEPC Global Lambda Calibration Export ===\n",
    "# Set this based on your backtest experiments.\n",
    "# For now you can leave it at 1.0; later you can change it to (for example) 0.97.\n",
    "\n",
    "scale_factor = 1.0  # üëà tweak this number when you want to shrink/boost totals\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "calibration = {\n",
    "    \"global_lambda_scale\": float(scale_factor),\n",
    "}\n",
    "\n",
    "calib_path = project_root / \"data\" / \"qepc_calibration.json\"\n",
    "calib_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(calib_path, \"w\") as f:\n",
    "    json.dump(calibration, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Saved calibration file to:\", calib_path)\n",
    "print(\"   Contents:\", calibration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
