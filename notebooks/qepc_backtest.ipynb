{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9c713d-8d9c-4abe-9025-f8b8f48bc36c",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# ðŸ“Š QEPC NBA Backtest Notebook\n",
    "\n",
    "This notebook measures how well the QEPC NBA engine is performing over time.\n",
    "\n",
    "It focuses on:\n",
    "- ðŸ—“ï¸ Defining a backtest date range\n",
    "- ðŸ§® Running `run_season_backtest(...)` to simulate all games in that range\n",
    "- ðŸ“ˆ Summarizing accuracy & spread error\n",
    "- ðŸ§¨ Inspecting the worst misses\n",
    "- ðŸ§¹ Filtering to NBAâ€“vsâ€“NBA only (no exhibitions)\n",
    "- ðŸŒŒ (Optional) Script / total-error analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aafe66-976b-4071-8403-3aac9a7400db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28ab68-bb09-4a38-8501-be0364942fa5",
   "metadata": {},
   "source": [
    "## ðŸ§© 1. Environment & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5ab958-2b51-4107-ad76-a8cddf655d72",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T04:05:15.769258Z",
     "iopub.status.busy": "2025-11-27T04:05:15.768921Z",
     "iopub.status.idle": "2025-11-27T04:05:16.355127Z",
     "shell.execute_reply": "2025-11-27T04:05:16.354486Z",
     "shell.execute_reply.started": "2025-11-27T04:05:15.769238Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QEPC Paths] Project Root set: /home/2dbcc135-5358-4730-8441-82ada9ea8087/qepc_project\n",
      "[QEPC] Autoload complete.\n",
      "[QEPC] Root Shim Restored. Forwarding to qepc.autoload...\n",
      "Project root: /home/2dbcc135-5358-4730-8441-82ada9ea8087/qepc_project\n"
     ]
    }
   ],
   "source": [
    "# Universal QEPC header for this notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from notebook_context import *  # try direct import first\n",
    "except ModuleNotFoundError:\n",
    "    cwd = Path.cwd()\n",
    "    candidate_roots = [cwd, cwd.parent, cwd.parent.parent]\n",
    "\n",
    "    found_root = None\n",
    "    for root in candidate_roots:\n",
    "        if (root / \"notebook_context.py\").exists():\n",
    "            found_root = root\n",
    "            break\n",
    "\n",
    "    if found_root is None:\n",
    "        raise ModuleNotFoundError(\n",
    "            f\"Could not find notebook_context.py from {cwd}. \"\n",
    "            \"Try opening this notebook from inside your qepc_project folder.\"\n",
    "        )\n",
    "\n",
    "    sys.path.insert(0, str(found_root))\n",
    "    os.chdir(found_root)\n",
    "    from notebook_context import *\n",
    "\n",
    "# Fallback for project_root if notebook_context didn't define it\n",
    "try:\n",
    "    project_root\n",
    "except NameError:\n",
    "    project_root = Path.cwd()\n",
    "\n",
    "print(\"Project root:\", project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9726a-b00f-4eb2-832a-76a98c2a1852",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c12044-1e6b-484c-8dfd-fcb271ae7502",
   "metadata": {},
   "source": [
    "## ðŸ“… 2. Select Backtest Range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aababd5f-56e4-47b6-9490-0881364834f4",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-11-27T04:05:18.216271Z",
     "iopub.status.busy": "2025-11-27T04:05:18.215650Z",
     "iopub.status.idle": "2025-11-27T04:05:18.220400Z",
     "shell.execute_reply": "2025-11-27T04:05:18.219736Z",
     "shell.execute_reply.started": "2025-11-27T04:05:18.216237Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest date range: 2024-11-24 â†’ 2025-11-27\n"
     ]
    }
   ],
   "source": [
    "# 2. Backtest Date Range & Filters (Custom start â†’ today, no widgets)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# ðŸ‘‡ Edit this line when you want a different start date\n",
    "BACKTEST_START_DATE = date(2024, 11, 24)\n",
    "\n",
    "# End date is always \"today\"\n",
    "BACKTEST_END_DATE = date.today()\n",
    "\n",
    "print(\"Backtest date range:\",\n",
    "      BACKTEST_START_DATE.isoformat(), \"â†’\", BACKTEST_END_DATE.isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f58ea-74fd-4e28-bae7-b6663206741b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ebeef-31d8-4bcd-a7a7-ae4dacf767e7",
   "metadata": {},
   "source": [
    "## ðŸ§® 3. Initiate Backtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593dabeb-12ab-4d23-bfa1-cdc48dd28d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T04:05:20.605293Z",
     "iopub.status.busy": "2025-11-27T04:05:20.604950Z",
     "iopub.status.idle": "2025-11-27T04:05:21.646984Z",
     "shell.execute_reply": "2025-11-27T04:05:21.646243Z",
     "shell.execute_reply.started": "2025-11-27T04:05:20.605270Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ 'schedule' not found; loading from qa.load_nba_schedule() ...\n",
      "[QEPC NBA Sim] Successfully loaded and parsed 771 games from original format.\n",
      "   Loaded schedule with 771 games.\n",
      "â„¹ï¸ 'team_strengths_for_lambda' not found; building from strengths_v2...\n",
      "Built advanced team strengths from Team_Stats.csv\n",
      "  Teams: 48\n",
      "  ORtg range: 85.7 â€“ 111.9\n",
      "  DRtg range: 95.2 â€“ 131.7\n",
      "  Pace range: 85.7 â€“ 111.9\n",
      "  Volatility range: 8.00 â€“ 14.00\n",
      "   Base strengths rows: 48\n",
      "   No usable injury master found; using base strengths only.\n",
      "â„¹ï¸ GLOBAL_LAMBDA_SCALE not found; defaulting to 1.0\n",
      "\n",
      "Running QEPC backtest from 2024-11-24 to 2025-11-27\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_season_backtest() takes 2 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m end_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(BACKTEST_END_DATE)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning QEPC backtest from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m backtest_long \u001b[38;5;241m=\u001b[39m run_season_backtest(\n\u001b[1;32m     66\u001b[0m     schedule,\n\u001b[1;32m     67\u001b[0m     team_strengths_for_lambda,\n\u001b[1;32m     68\u001b[0m     start_date,\n\u001b[1;32m     69\u001b[0m     end_date,\n\u001b[1;32m     70\u001b[0m     GLOBAL_LAMBDA_SCALE,\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGames simulated in this range:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(backtest_long))\n\u001b[1;32m     74\u001b[0m display(backtest_long\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mTypeError\u001b[0m: run_season_backtest() takes 2 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "# 3. Run Backtest for Selected Range (start â†’ today)\n",
    "\n",
    "import pandas as pd\n",
    "import qepc_autoload as qa\n",
    "from pathlib import Path\n",
    "from qepc.backtest.backtest_engine import run_season_backtest\n",
    "\n",
    "# 3.1 Make sure we have a schedule DataFrame\n",
    "try:\n",
    "    schedule\n",
    "    print(\"âœ… Using existing 'schedule' from memory.\")\n",
    "except NameError:\n",
    "    print(\"â„¹ï¸ 'schedule' not found; loading from qa.load_nba_schedule() ...\")\n",
    "    schedule = qa.load_nba_schedule()\n",
    "    print(\"   Loaded schedule with\", len(schedule), \"games.\")\n",
    "\n",
    "# 3.2 Make sure we have team_strengths_for_lambda\n",
    "try:\n",
    "    team_strengths_for_lambda\n",
    "    print(\"âœ… Using existing 'team_strengths_for_lambda'.\")\n",
    "except NameError:\n",
    "    print(\"â„¹ï¸ 'team_strengths_for_lambda' not found; building from strengths_v2...\")\n",
    "\n",
    "    from qepc.sports.nba.strengths_v2 import calculate_advanced_strengths\n",
    "    try:\n",
    "        from qepc.sports.nba.strengths_v2 import apply_injury_overrides\n",
    "    except ImportError:\n",
    "        apply_injury_overrides = None\n",
    "\n",
    "    # Base strengths (no injuries yet)\n",
    "    base_strengths = calculate_advanced_strengths()\n",
    "    print(\"   Base strengths rows:\", len(base_strengths))\n",
    "\n",
    "    # Try to apply your merged injury overrides if they exist\n",
    "    injuries_master_path = project_root / \"data\" / \"Injury_Overrides_MASTER.csv\"\n",
    "\n",
    "    if apply_injury_overrides and injuries_master_path.exists():\n",
    "        try:\n",
    "            injuries_master = pd.read_csv(injuries_master_path)\n",
    "            print(\"   Loaded injuries master with\", len(injuries_master), \"rows.\")\n",
    "            team_strengths_for_lambda = apply_injury_overrides(base_strengths, injuries_master)\n",
    "            print(\"   Applied injury overrides.\")\n",
    "        except Exception as e:\n",
    "            print(\"   âš ï¸ Could not apply injury overrides, using base strengths instead.\")\n",
    "            print(\"   Reason:\", e)\n",
    "            team_strengths_for_lambda = base_strengths\n",
    "    else:\n",
    "        print(\"   No usable injury master found; using base strengths only.\")\n",
    "        team_strengths_for_lambda = base_strengths\n",
    "\n",
    "# 3.3 Make sure we have GLOBAL_LAMBDA_SCALE\n",
    "try:\n",
    "    GLOBAL_LAMBDA_SCALE\n",
    "    print(\"âœ… Using existing GLOBAL_LAMBDA_SCALE:\", GLOBAL_LAMBDA_SCALE)\n",
    "except NameError:\n",
    "    GLOBAL_LAMBDA_SCALE = 1.0\n",
    "    print(\"â„¹ï¸ GLOBAL_LAMBDA_SCALE not found; defaulting to 1.0\")\n",
    "\n",
    "# 3.4 Convert date range and run the backtest\n",
    "start_date = pd.to_datetime(BACKTEST_START_DATE)\n",
    "end_date = pd.to_datetime(BACKTEST_END_DATE)\n",
    "\n",
    "print(f\"\\nRunning QEPC backtest from {start_date.date()} to {end_date.date()}\")\n",
    "\n",
    "backtest_long = run_season_backtest(\n",
    "    schedule,\n",
    "    team_strengths_for_lambda,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    GLOBAL_LAMBDA_SCALE,\n",
    ")\n",
    "\n",
    "print(\"Games simulated in this range:\", len(backtest_long))\n",
    "display(backtest_long.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba482be0-d876-4448-8735-ce6eb2bc002c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7653d-b0a0-4d37-975c-c928a8c3ce85",
   "metadata": {},
   "source": [
    "## ðŸ 4. Global Summary (All Games in Range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f9b19-86fd-4406-9736-06a02948d173",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 4. Global Summary (All Games in Selected Range)\n",
    "\n",
    "if \"backtest_long\" not in globals():\n",
    "    raise RuntimeError(\"Run Cell 3 (Run Backtest) before the summary.\")\n",
    "\n",
    "total_games = len(backtest_long)\n",
    "accuracy_pct = backtest_long[\"Correct_Pick\"].mean() * 100\n",
    "spread_mae = backtest_long[\"Spread_Error\"].abs().mean()\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"ðŸ† QEPC BACKTEST SUMMARY\")\n",
    "print(\"========================================\")\n",
    "print(f\"ðŸ“… Date Range: {start_date.date()} â†’ {end_date.date()}\")\n",
    "print(f\"ðŸ€ Games Simulated: {total_games}\")\n",
    "print(f\"âœ… Overall Accuracy: {accuracy_pct:.2f}%\")\n",
    "print(f\"ðŸŽ¯ Avg Spread Error (MAE): {spread_mae:.2f} points\")\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d68a33-3bc0-4bc5-ac1b-3e392599a469",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf3ce9-3d6c-4633-a7b1-23b9e6a4a7dd",
   "metadata": {},
   "source": [
    "## ðŸ§¹ 5. Clean NBA-Only View (Filter Out Exhibitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aaf014-e5af-44f5-ba3d-f9a356f49325",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 5. Clean NBA-Only View (Filter Out Exhibitions)\n",
    "\n",
    "NBA_TEAMS = [\n",
    "    \"Atlanta Hawks\", \"Boston Celtics\", \"Brooklyn Nets\", \"Charlotte Hornets\",\n",
    "    \"Chicago Bulls\", \"Cleveland Cavaliers\", \"Dallas Mavericks\", \"Denver Nuggets\",\n",
    "    \"Detroit Pistons\", \"Golden State Warriors\", \"Houston Rockets\", \"Indiana Pacers\",\n",
    "    \"Los Angeles Clippers\", \"Los Angeles Lakers\", \"Memphis Grizzlies\", \"Miami Heat\",\n",
    "    \"Milwaukee Bucks\", \"Minnesota Timberwolves\", \"New Orleans Pelicans\", \"New York Knicks\",\n",
    "    \"Oklahoma City Thunder\", \"Orlando Magic\", \"Philadelphia 76ers\", \"Phoenix Suns\",\n",
    "    \"Portland Trail Blazers\", \"Sacramento Kings\", \"San Antonio Spurs\", \"Toronto Raptors\",\n",
    "    \"Utah Jazz\", \"Washington Wizards\",\n",
    "]\n",
    "\n",
    "backtest_clean = backtest_long[\n",
    "    backtest_long[\"Away Team\"].isin(NBA_TEAMS)\n",
    "    & backtest_long[\"Home Team\"].isin(NBA_TEAMS)\n",
    "].copy()\n",
    "\n",
    "print(f\"Original games: {len(backtest_long)}, After NBA-only filter: {len(backtest_clean)}\")\n",
    "\n",
    "acc_clean = backtest_clean[\"Correct_Pick\"].mean() * 100\n",
    "mae_clean = backtest_clean[\"Spread_Error\"].abs().mean()\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"ðŸ† CLEAN NBA-ONLY BACKTEST\")\n",
    "print(\"========================================\")\n",
    "print(f\"ðŸ€ Games Simulated: {len(backtest_clean)}\")\n",
    "print(f\"âœ… Overall Accuracy: {acc_clean:.2f}%\")\n",
    "print(f\"ðŸŽ¯ Avg Spread Error: {mae_clean:.2f} points\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162cdef3-9d2d-40eb-8f02-818c80a7ef1e",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dab5db-8478-497d-aee5-f2dc7d176b5b",
   "metadata": {},
   "source": [
    "## ðŸ§¨ 6. Biggest Misses (Spread Error Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0420bf-a220-47d7-a436-2677d888ae98",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 6. Biggest Misses (Spread Error Analysis)\n",
    "\n",
    "worst = backtest_clean.reindex(\n",
    "    backtest_clean[\"Spread_Error\"].abs().sort_values(ascending=False).index\n",
    ")\n",
    "\n",
    "cols = [\n",
    "    \"Date\",\n",
    "    \"Away Team\", \"Home Team\",\n",
    "    \"Expected_Spread\", \"Actual_Spread\", \"Spread_Error\",\n",
    "    \"Away_Win_Prob\", \"Home_Win_Prob\",\n",
    "    \"Sim_Away_Score\", \"Actual_Away_Score\",\n",
    "    \"Sim_Home_Score\", \"Actual_Home_Score\",\n",
    "    \"Correct_Pick\",\n",
    "]\n",
    "cols = [c for c in cols if c in worst.columns]\n",
    "\n",
    "print(\"Top 15 biggest spread misses (NBA vs NBA only):\")\n",
    "display(worst[cols].head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6553e5-73b6-4b21-a089-c55df8ce37f2",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af160f-918d-4589-a93d-2b898e15d46c",
   "metadata": {},
   "source": [
    "## ðŸ“¦ 7. Spread Error Buckets (How Often & How Bad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92e5bb-16c2-487d-a7de-90a1ff2e1ee3",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 7. Spread Error Buckets (How Often & How Bad)\n",
    "\n",
    "abs_err = backtest_clean[\"Spread_Error\"].abs()\n",
    "\n",
    "bins = [0, 5, 10, 15, 20, np.inf]\n",
    "labels = [\"0â€“5\", \"5â€“10\", \"10â€“15\", \"15â€“20\", \"20+\"]\n",
    "\n",
    "backtest_clean[\"Spread_Error_Bucket\"] = pd.cut(\n",
    "    abs_err, bins=bins, labels=labels, right=False\n",
    ")\n",
    "\n",
    "bucket_counts = backtest_clean[\"Spread_Error_Bucket\"].value_counts().sort_index()\n",
    "bucket_pct = (bucket_counts / len(backtest_clean) * 100).round(2)\n",
    "\n",
    "spread_bucket_summary = pd.DataFrame({\n",
    "    \"Games\": bucket_counts,\n",
    "    \"Percent\": bucket_pct\n",
    "})\n",
    "\n",
    "print(\"Spread error distribution (absolute error in points):\")\n",
    "display(spread_bucket_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce39e99-8da8-4c52-b1c4-8a18e7f920ad",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5faac5-5b98-42e8-b92e-39c54172b782",
   "metadata": {},
   "source": [
    "## ðŸŒŒ 8. Optional: Total Error & Script Classification (GRIND / BASE / CHAOS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f3829-bf46-4863-b859-f25313deffd2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa26f6e-b590-4700-9fff-c058c03ddf31",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# 8. Optional: Total Error & Script Classification (GRIND / BASE / CHAOS)\n",
    "\n",
    "df = backtest_clean.copy()\n",
    "\n",
    "# 8.1 Compute simulated and actual totals\n",
    "df[\"Sim_Total\"] = df[\"Sim_Home_Score\"] + df[\"Sim_Away_Score\"]\n",
    "df[\"Actual_Total\"] = df[\"Actual_Home_Score\"] + df[\"Actual_Away_Score\"]\n",
    "\n",
    "# Drop games where we effectively didn't simulate (Sim_Total == 0)\n",
    "before = len(df)\n",
    "df = df[df[\"Sim_Total\"] > 0]\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after} games with Sim_Total == 0.\")\n",
    "print(f\"Remaining games for script analysis: {after}\")\n",
    "\n",
    "# 8.2 Total error\n",
    "df[\"Total_Error\"] = df[\"Actual_Total\"] - df[\"Sim_Total\"]\n",
    "\n",
    "# Thresholds for GRIND / BASE / CHAOS (can be tuned)\n",
    "grind_thresh = -15   # 15+ pts under model total â†’ GRIND\n",
    "chaos_thresh = 15    # 15+ pts over model total â†’ CHAOS\n",
    "\n",
    "def classify_script(row):\n",
    "    if row[\"Total_Error\"] <= grind_thresh:\n",
    "        return \"GRIND\"\n",
    "    elif row[\"Total_Error\"] >= chaos_thresh:\n",
    "        return \"CHAOS\"\n",
    "    else:\n",
    "        return \"BASE\"\n",
    "\n",
    "df[\"Script_ExPost\"] = df.apply(classify_script, axis=1)\n",
    "\n",
    "print(\"\\nSample of script labels:\")\n",
    "display(\n",
    "    df[[\"Date\", \"Away Team\", \"Home Team\", \"Sim_Total\", \"Actual_Total\", \"Total_Error\", \"Script_ExPost\"]]\n",
    "    .head()\n",
    ")\n",
    "\n",
    "# 8.3 Script-level summary\n",
    "script_summary = df.groupby(\"Script_ExPost\").agg(\n",
    "    Games=(\"Total_Error\", \"count\"),\n",
    "    Avg_Total_Error=(\"Total_Error\", \"mean\"),\n",
    "    Avg_Abs_Total_Error=(\"Total_Error\", lambda x: x.abs().mean()),\n",
    "    Avg_Spread_Error=(\"Spread_Error\", \"mean\"),\n",
    "    Avg_Abs_Spread_Error=(\"Spread_Error\", lambda x: x.abs().mean()),\n",
    ")\n",
    "\n",
    "script_summary[\"Percent\"] = (script_summary[\"Games\"] / len(df) * 100).round(2)\n",
    "\n",
    "print(\"\\nEx-post script distribution (based on totals):\")\n",
    "display(script_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36091349-86a6-4eb9-9cfb-38867b2d3bed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scrollable"
    ]
   },
   "source": [
    "## Global Lambda Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209aa9c-c6e2-40d9-a650-831b57f0f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === QEPC Global Lambda Calibration Export ===\n",
    "# Set this based on your backtest experiments.\n",
    "# For now you can leave it at 1.0; later you can change it to (for example) 0.97.\n",
    "\n",
    "scale_factor = 1.0  # ðŸ‘ˆ tweak this number when you want to shrink/boost totals\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "calibration = {\n",
    "    \"global_lambda_scale\": float(scale_factor),\n",
    "}\n",
    "\n",
    "calib_path = project_root / \"data\" / \"qepc_calibration.json\"\n",
    "calib_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(calib_path, \"w\") as f:\n",
    "    json.dump(calibration, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved calibration file to:\", calib_path)\n",
    "print(\"   Contents:\", calibration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
