{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a33604-84cf-4b5a-8fd5-1cee72c22a49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 0. QEPC Injury Data Fetch – Setup & Helpers\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError\n",
    "from datetime import datetime\n",
    "\n",
    "# Try to get project_root from notebook_context\n",
    "try:\n",
    "    from notebook_context import *\n",
    "    print(\"✅ notebook_context imported.\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"ℹ️ notebook_context not found on sys.path; using CWD as project_root.\")\n",
    "    project_root = Path.cwd()\n",
    "\n",
    "# Make sure project_root is defined\n",
    "try:\n",
    "    project_root\n",
    "except NameError:\n",
    "    project_root = Path.cwd()\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"data_dir:\", data_dir)\n",
    "\n",
    "\n",
    "def status_to_impact(status: str) -> float:\n",
    "    \"\"\"\n",
    "    Map live injury status text -> QEPC Impact factor.\n",
    "    1.00 = no impact, lower = worse.\n",
    "    \"\"\"\n",
    "    if not isinstance(status, str):\n",
    "        return 0.95\n",
    "\n",
    "    s = status.lower()\n",
    "\n",
    "    if \"out\" in s:\n",
    "        return 0.70   # big impact\n",
    "    if \"doubtful\" in s:\n",
    "        return 0.85\n",
    "    if \"questionable\" in s:\n",
    "        return 0.90\n",
    "    if \"probable\" in s:\n",
    "        return 0.95\n",
    "    if \"available\" in s or \"cleared\" in s or \"active\" in s:\n",
    "        return 1.00\n",
    "\n",
    "    return 0.95  # default mild discount\n",
    "\n",
    "\n",
    "def _save_source(df: pd.DataFrame, filename: str, source_label: str) -> Path:\n",
    "    \"\"\"\n",
    "    Normalize columns and save a single-source injury file.\n",
    "    Expected columns coming in (at minimum): Team, PlayerName, Status, Injury, EstReturn.\n",
    "\n",
    "    Adds Impact + Source and writes to data_dir/filename.\n",
    "    \"\"\"\n",
    "    required = [\"Team\", \"PlayerName\", \"Status\", \"Injury\", \"EstReturn\"]\n",
    "    for col in required:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Source {source_label} missing required column: {col}\")\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"Impact\"] = out[\"Status\"].apply(status_to_impact)\n",
    "    out[\"Source\"] = source_label\n",
    "\n",
    "    path = data_dir / filename\n",
    "    out.to_csv(path, index=False)\n",
    "    print(f\"✅ Saved {source_label} injuries to:\", path, \"rows:\", len(out))\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7787d04-55cf-4b06-abec-80c65aa8ecd8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. Official NBA injury report (nbainjuries)\n",
    "\n",
    "try:\n",
    "    from nbainjuries import injury\n",
    "except ImportError:\n",
    "    print(\"❌ nbainjuries is not installed in this environment.\")\n",
    "    print(\"   pip install nbainjuries  (and make sure Java/JVM is installed).\")\n",
    "    official_df = None\n",
    "else:\n",
    "    ts = datetime.now()\n",
    "    print(\"Requesting official injury report for:\", ts)\n",
    "\n",
    "    # NOTE: Use the same logic you already had working here.\n",
    "    # I'm assuming it returns a pandas DataFrame called inj_raw_df.\n",
    "\n",
    "    # --- BEGIN: your existing nbainjuries fetch pattern ---\n",
    "    # This is a template; if it doesn't match exactly, paste in the version\n",
    "    # that you already used successfully.\n",
    "    rep = injury.InjuryReport()        # may differ in your code\n",
    "    inj_raw_df = rep.to_pandas()       # or whatever method you used\n",
    "    # --- END: your existing nbainjuries fetch pattern ---\n",
    "\n",
    "    print(\"Rows in raw official injury report:\", len(inj_raw_df))\n",
    "    display(inj_raw_df.head(10))\n",
    "\n",
    "    # Normalize to QEPC schema (Team, PlayerName, Status, Injury, EstReturn)\n",
    "    official_df = pd.DataFrame({\n",
    "        \"Team\": inj_raw_df[\"Team\"],\n",
    "        \"PlayerName\": inj_raw_df[\"Player Name\"],\n",
    "        \"Status\": inj_raw_df[\"Current Status\"],\n",
    "        \"Injury\": inj_raw_df[\"Reason\"],\n",
    "        \"EstReturn\": \"\",  # official reports are per-game, no long ETA text\n",
    "    })\n",
    "\n",
    "    _save_source(official_df,\n",
    "                 filename=\"Injury_Overrides_live_official.csv\",\n",
    "                 source_label=\"NBA_official_nbainjuries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf45f0d-0124-4303-8000-dd6aca2cb6a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 2. ESPN injuries API (optional)\n",
    "\n",
    "import requests\n",
    "\n",
    "espn_df = None\n",
    "\n",
    "try:\n",
    "    url = \"https://site.api.espn.com/apis/site/v2/sports/basketball/nba/injuries\"\n",
    "    resp = requests.get(url, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    print(\"Top-level ESPN keys:\", list(data.keys()))\n",
    "except Exception as e:\n",
    "    print(\"❌ Error fetching ESPN injuries:\", e)\n",
    "else:\n",
    "    # This part is very dependent on ESPN's current JSON structure.\n",
    "    # Often it's something like data[\"injuries\"] -> list of team blocks.\n",
    "    injuries_blocks = data.get(\"injuries\", [])\n",
    "    records = []\n",
    "\n",
    "    for team_block in injuries_blocks:\n",
    "        team_name = team_block.get(\"team\", {}).get(\"displayName\", \"\")\n",
    "        for item in team_block.get(\"injuries\", []):\n",
    "            player_name = item.get(\"athlete\", {}).get(\"displayName\", \"\")\n",
    "            status = item.get(\"status\", \"\")\n",
    "            detail = item.get(\"detail\", \"\")\n",
    "            est_return = \"\"  # ESPN rarely gives precise dates here\n",
    "\n",
    "            records.append({\n",
    "                \"Team\": team_name,\n",
    "                \"PlayerName\": player_name,\n",
    "                \"Status\": status,\n",
    "                \"Injury\": detail,\n",
    "                \"EstReturn\": est_return,\n",
    "            })\n",
    "\n",
    "    if records:\n",
    "        espn_df = pd.DataFrame(records)\n",
    "        display(espn_df.head(20))\n",
    "        _save_source(espn_df,\n",
    "                     filename=\"Injury_Overrides_live_espn.csv\",\n",
    "                     source_label=\"ESPN\")\n",
    "    else:\n",
    "        print(\"ℹ️ No ESPN injury records parsed; skipping save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f355630-2ab4-4af1-9262-aa2d5ce57dca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 3. Balldontlie injuries API (optional)\n",
    "\n",
    "import requests\n",
    "\n",
    "BALLDONTLIE_API_KEY = \"c5ae7df3-682e-450c-b47e-f7e91396379e\"  # <- replace with your actual key\n",
    "\n",
    "def _bdl_headers():\n",
    "    return {\n",
    "        \"Authorization\": f\"Bearer {BALLDONTLIE_API_KEY}\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "bdl_df = None\n",
    "\n",
    "try:\n",
    "    url = \"https://api.balldontlie.io/v1/player_injuries\"\n",
    "    params = {\"per_page\": 100}\n",
    "    resp = requests.get(url, headers=_bdl_headers(), params=params, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    js = resp.json()\n",
    "    print(\"Balldontlie keys:\", list(js.keys()))\n",
    "except Exception as e:\n",
    "    print(\"❌ Error fetching Balldontlie injuries:\", e)\n",
    "else:\n",
    "    data = js.get(\"data\", [])\n",
    "    records = []\n",
    "    for item in data:\n",
    "        player = item.get(\"player\", {})\n",
    "        team = player.get(\"team\", {})\n",
    "        records.append({\n",
    "            \"Team\": team.get(\"full_name\", \"\"),\n",
    "            \"PlayerName\": player.get(\"full_name\", \"\"),\n",
    "            \"Status\": item.get(\"status\", \"\"),\n",
    "            \"Injury\": item.get(\"description\", \"\"),\n",
    "            \"EstReturn\": item.get(\"return_date\", \"\") or \"\",\n",
    "        })\n",
    "\n",
    "    if records:\n",
    "        bdl_df = pd.DataFrame(records)\n",
    "        display(bdl_df.head(20))\n",
    "        _save_source(bdl_df,\n",
    "                     filename=\"Injury_Overrides_live_balldontlie.csv\",\n",
    "                     source_label=\"Balldontlie\")\n",
    "    else:\n",
    "        print(\"ℹ️ No Balldontlie injury records parsed; skipping save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5ecb8-ad6d-4ae1-8e1e-1b1b1ac56f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build master injury file from all sources\n",
    "\n",
    "sources = [\n",
    "    (\"NBA_official_nbainjuries\", data_dir / \"Injury_Overrides_live_official.csv\"),\n",
    "    (\"Balldontlie\",              data_dir / \"Injury_Overrides_live_balldontlie.csv\"),\n",
    "    (\"ESPN\",                     data_dir / \"Injury_Overrides_live_espn.csv\"),\n",
    "    (\"DataDriven\",               data_dir / \"Injury_Overrides_data_driven.csv\"),\n",
    "    (\"Manual\",                   data_dir / \"Injury_Overrides.csv\"),\n",
    "]\n",
    "\n",
    "frames = []\n",
    "for label, path in sources:\n",
    "    if not path.exists() or path.stat().st_size == 0:\n",
    "        print(f\"⚠️ Skipping {label}: file missing or empty at {path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except EmptyDataError:\n",
    "        print(f\"⚠️ Skipping {label}: EmptyDataError in {path.name}\")\n",
    "        continue\n",
    "\n",
    "    if \"Team\" not in df.columns:\n",
    "        print(f\"⚠️ {label}: missing 'Team' column, skipping.\")\n",
    "        continue\n",
    "\n",
    "    if \"PlayerName\" not in df.columns:\n",
    "        if \"Player\" in df.columns:\n",
    "            df[\"PlayerName\"] = df[\"Player\"]\n",
    "        else:\n",
    "            print(f\"⚠️ {label}: missing 'PlayerName'/'Player', skipping.\")\n",
    "            continue\n",
    "\n",
    "    for col, default in [\n",
    "        (\"Status\", \"\"),\n",
    "        (\"Injury\", \"\"),\n",
    "        (\"EstReturn\", \"\"),\n",
    "        (\"Impact\", 1.0),\n",
    "    ]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = default\n",
    "\n",
    "    df[\"Source\"] = label\n",
    "    frames.append(df[[\"Team\", \"PlayerName\", \"Status\", \"Injury\",\n",
    "                      \"EstReturn\", \"Impact\", \"Source\"]])\n",
    "\n",
    "if not frames:\n",
    "    print(\"❌ No usable injury data found in any source; master file will NOT be updated.\")\n",
    "else:\n",
    "    all_inj = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Priority for conflicts: later in this list wins\n",
    "    priority_order = [\"Manual\", \"DataDriven\", \"NBA_official_nbainjuries\", \"Balldontlie\", \"ESPN\"]\n",
    "    priority_map = {name: rank for rank, name in enumerate(priority_order, start=1)}\n",
    "\n",
    "    all_inj[\"priority\"] = all_inj[\"Source\"].map(priority_map).fillna(0)\n",
    "\n",
    "    all_inj = (\n",
    "        all_inj.sort_values([\"Team\", \"PlayerName\", \"priority\"], ascending=[True, True, False])\n",
    "        .drop_duplicates(subset=[\"Team\", \"PlayerName\"], keep=\"first\")\n",
    "        .drop(columns=[\"priority\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    master_path = data_dir / \"Injury_Overrides_MASTER.csv\"\n",
    "    all_inj.to_csv(master_path, index=False)\n",
    "\n",
    "    print(\"✅ Master injury file built.\")\n",
    "    print(\"   Rows in master:\", len(all_inj))\n",
    "    print(\"   Saved to:\", master_path)\n",
    "    display(all_inj.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
