{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9c713d-8d9c-4abe-9025-f8b8f48bc36c",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# ðŸ“Š QEPC NBA Backtest Notebook - Adjusted for Max Accuracy\n",
    "\n",
    "**Adjusted Version:** Added live API for recent games, quantum-inspired probability calibration (using PennyLane if installed), and use of 10-year data for walk-forward testing to reduce overfitting.\n",
    "\n",
    "This notebook measures how well the QEPC NBA engine is performing over time.\n",
    "\n",
    "It focuses on:\n",
    "- ðŸ—“ï¸ Defining a backtest date range\n",
    "- ðŸ§® Running `run_season_backtest(...)` to simulate all games in that range\n",
    "- ðŸ“ˆ Summarizing accuracy & spread error\n",
    "- ðŸ§¨ Inspecting the worst misses\n",
    "- ðŸ§¹ Filtering to NBAâ€“vsâ€“NBA only (no exhibitions)\n",
    "- ðŸŒŒ Quantum calibration for probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28ab68-bb09-4a38-8501-be0364942fa5",
   "metadata": {},
   "source": [
    "## ðŸ§© 1. Environment & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ab958-2b51-4107-ad76-a8cddf655d72",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-28T05:37:35.202824Z",
     "iopub.status.busy": "2025-11-28T05:37:35.202507Z",
     "iopub.status.idle": "2025-11-28T05:37:35.213029Z",
     "shell.execute_reply": "2025-11-28T05:37:35.212470Z",
     "shell.execute_reply.started": "2025-11-28T05:37:35.202801Z"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_context import *  # Setup\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import leaguegamelog  # Live API for recent games\n",
    "import numpy as np\n",
    "try:\n",
    "    import pennylane as qml  # Quantum for calibration (install if needed)\n",
    "except ImportError:\n",
    "    print(\"PennyLane not installedâ€”skip quantum calibration or install with !pip install pennylane\")\n",
    "\n",
    "# New: Fetch live recent games to add to backtest data\n",
    "def add_live_games(historical_df, season='2025-26'):\n",
    "    log = leaguegamelog.LeagueGameLog(season=season)\n",
    "    live_df = log.get_data_frames()[0]\n",
    "    combined = pd.concat([historical_df, live_df], ignore_index=True)\n",
    "    print(f\"Added {len(live_df)} live games to backtest.\")\n",
    "    return combined\n",
    "\n",
    "# Load your 10-year data and add live\n",
    "historical_df = pd.read_csv('data/merged_historical_data.csv')  # Your big file\n",
    "historical_df = add_live_games(historical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aafe66-976b-4071-8403-3aac9a7400db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b401fa",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ 2. Backtest with Quantum Calibration\n",
    "\n",
    "New: Added quantum-inspired calibration for win probs (using PennyLane if available) to handle uncertainties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da2be8-7516-4448-9f0c-10a64686a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range\n",
    "start_date_str = '2025-10-01'\n",
    "end_date_str = '2025-11-29'\n",
    "\n",
    "# Filter data\n",
    "backtest_df = historical_df[(historical_df['gameDate'] >= start_date_str) & (historical_df['gameDate'] <= end_date_str)]\n",
    "\n",
    "# Run your backtest function (assume exists)\n",
    "results = run_season_backtest(backtest_df)  # Your function\n",
    "\n",
    "# New: Quantum calibration if PennyLane installed\n",
    "if 'qml' in globals():\n",
    "    dev = qml.device(\"default.qubit\", wires=1)\n",
    "    @qml.qnode(dev)\n",
    "    def calibrate_prob(prob):\n",
    "        qml.RY(np.arctan(prob * 2 - 1), wires=0)  # Encode prob\n",
    "        return qml.expval(qml.PauliX(wires=0))\n",
    "    results['quantum_win_prob'] = results['Home_Win_Prob'].apply(lambda p: (calibrate_prob(p) + 1) / 2)\n",
    "    print(\"Applied quantum calibration to probs.\")\n",
    "\n",
    "display(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d63c3",
   "metadata": {},
   "source": [
    "## ðŸ“‰ 3. Analyze Results\n",
    "\n",
    "New: Added Brier score for prob accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07051d23-2d2c-458b-8993-629ff8faffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your summary code...\n",
    "# New: Brier score (measures prob quality)\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier = brier_score_loss(results['actual_home_win'], results['Home_Win_Prob'])\n",
    "print(f\"Brier Score (lower better): {brier:.3f} - Quantum calibrated: {brier_score_loss(results['actual_home_win'], results['quantum_win_prob']):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}