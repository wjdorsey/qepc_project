{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## QEPC NBA ‚Äì Quantum Backtest Notebook\n",
    "\n",
    "**Identity**\n",
    "\n",
    "- QEPC (Quantum Entangled Poisson Cascade) is a **quantum-inspired sports engine**.\n",
    "- It thinks in **multiverses of game outcomes**, not single-point predictions.\n",
    "- Each game exists in a **superposition of scripts** (Grind / Balanced / Chaos / etc.) until ‚Äúcollapse,‚Äù and QEPC‚Äôs job is to find the most probable collapse.\n",
    "- Team and player stats are treated as **entangled variables**: pace, usage, injuries, volatility and matchup context all interact, not just add up.\n",
    "\n",
    "**Core Objective**\n",
    "\n",
    "1. Build the **most accurate real sports prediction model** we can, starting with NBA totals, spreads, and win probabilities.\n",
    "2. Let **data and backtests** decide what survives:\n",
    "   - Verifiable statistics > narrative.\n",
    "   - No vibes, no astrology, no ‚Äúrevenge game‚Äù fluff.\n",
    "3. Use this notebook as a **truth table**:\n",
    "   - Measure QEPC‚Äôs raw performance.\n",
    "   - Add calibration layers.\n",
    "   - Track improvements over time (Win%, MAE, and out-of-sample results).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Robust bootstrap to load notebook_header.py no matter where Jupyter started ---\n",
    "\n",
    "import sys\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Find the project root: the folder that contains notebook_header.py\n",
    "cur = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "for _ in range(6):  # walk up a few levels just in case\n",
    "    if (cur / \"notebook_header.py\").exists():\n",
    "        project_root = cur\n",
    "        break\n",
    "    cur = cur.parent\n",
    "\n",
    "if project_root is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find notebook_header.py in the current directory or its parents.\"\n",
    "    )\n",
    "\n",
    "# 2) Make sure project root is on sys.path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# 3) Load notebook_header.py as a proper module\n",
    "header_path = project_root / \"notebook_header.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"notebook_header\", header_path)\n",
    "notebook_header = importlib.util.module_from_spec(spec)\n",
    "\n",
    "# IMPORTANT: register it in sys.modules so @dataclass doesn't break\n",
    "sys.modules[spec.name] = notebook_header\n",
    "\n",
    "spec.loader.exec_module(notebook_header)\n",
    "\n",
    "# 4) Now call qepc_notebook_setup from that module\n",
    "env = notebook_header.qepc_notebook_setup(run_diagnostics=False)\n",
    "data_dir = env.data_dir\n",
    "raw_dir = env.raw_dir\n",
    "\n",
    "from qepc_autoload import qepc_step\n",
    "\n",
    "print(\"‚úÖ QEPC environment initialized\")\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"data_dir:\", data_dir)\n",
    "print(\"raw_dir:\", raw_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CELL 2: Load 10-year team game logs (NBA_API_QEPC_Format)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Point this to wherever you put the file:\n",
    "# Example: data/raw/NBA_API_QEPC_Format.csv\n",
    "team_stats_path = data_dir / \"raw\" / \"NBA_API_QEPC_Format.csv\"  # or .xls, both ok with read_csv\n",
    "\n",
    "if not team_stats_path.exists():\n",
    "    raise FileNotFoundError(f\"NBA_API_QEPC_Format file not found at {team_stats_path}\")\n",
    "\n",
    "qepc_step(f\"Loading 10-year team game logs from {team_stats_path}\")\n",
    "\n",
    "team_stats = pd.read_csv(team_stats_path)\n",
    "\n",
    "# Make sure we have a usable date column\n",
    "if \"gameDate\" not in team_stats.columns:\n",
    "    raise ValueError(f\"'gameDate' column not found. Columns: {list(team_stats.columns)[:15]}\")\n",
    "\n",
    "team_stats[\"gameDate\"] = pd.to_datetime(team_stats[\"gameDate\"], errors=\"coerce\")\n",
    "\n",
    "invalid = team_stats[\"gameDate\"].isna().sum()\n",
    "if invalid > 0:\n",
    "    print(f\"‚ö†Ô∏è Dropped {invalid} rows with invalid dates\")\n",
    "    team_stats = team_stats[team_stats[\"gameDate\"].notna()].copy()\n",
    "\n",
    "if len(team_stats) == 0:\n",
    "    raise RuntimeError(\"After dropping invalid dates, no rows remain in team_stats.\")\n",
    "\n",
    "print(f\"‚úÖ Loaded team_stats: {len(team_stats):,} rows\")\n",
    "print(f\"üìÖ Date range: {team_stats['gameDate'].min().date()} to {team_stats['gameDate'].max().date()}\")\n",
    "print(\"üìã Columns:\", list(team_stats.columns)[:12], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: Build backtest_games = one row per game from 10-year log\n",
    "\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIG ---\n",
    "LOOKBACK_MODE  = \"all\"    # \"days\", \"years\", or \"all\"\n",
    "# LOOKBACK_DAYS  = 30       # used if LOOKBACK_MODE == \"days\"\n",
    "# LOOKBACK_YEARS = 3        # used if LOOKBACK_MODE == \"years\"\n",
    "\n",
    "latest_date = team_stats[\"gameDate\"].max()\n",
    "earliest_date = team_stats[\"gameDate\"].min()\n",
    "\n",
    "if LOOKBACK_MODE == \"days\":\n",
    "    BACKTEST_START = latest_date - timedelta(days=int(LOOKBACK_DAYS))\n",
    "elif LOOKBACK_MODE == \"years\":\n",
    "    BACKTEST_START = latest_date - timedelta(days=365 * int(LOOKBACK_YEARS))\n",
    "elif LOOKBACK_MODE == \"all\":\n",
    "    BACKTEST_START = earliest_date\n",
    "else:\n",
    "    raise ValueError(f\"Unknown LOOKBACK_MODE: {LOOKBACK_MODE}\")\n",
    "\n",
    "BACKTEST_END = latest_date\n",
    "\n",
    "print(\"üéØ Backtest Configuration\")\n",
    "print(f\"   Mode:  {LOOKBACK_MODE}\")\n",
    "print(f\"   Start: {BACKTEST_START.date()}\")\n",
    "print(f\"   End:   {BACKTEST_END.date()}\")\n",
    "print(f\"   Span:  {(BACKTEST_END - BACKTEST_START).days} days\")\n",
    "\n",
    "# Filter to window\n",
    "mask = (team_stats[\"gameDate\"] >= BACKTEST_START) & (team_stats[\"gameDate\"] <= BACKTEST_END)\n",
    "window_stats = team_stats[mask].copy()\n",
    "\n",
    "print(f\"\\nüßπ Filtered to {len(window_stats)} rows in window.\")\n",
    "\n",
    "# --- NEW PART: build one row per game using gameId + home flag ---\n",
    "\n",
    "if \"gameId\" not in window_stats.columns or \"home\" not in window_stats.columns:\n",
    "    raise RuntimeError(\"Expected 'gameId' and 'home' columns in team_stats for game grouping.\")\n",
    "\n",
    "games_rows = []\n",
    "\n",
    "for gid, group in window_stats.groupby(\"gameId\"):\n",
    "    # try to identify home/away rows\n",
    "    home_rows = group[group[\"home\"] == 1]\n",
    "    away_rows = group[group[\"home\"] == 0]\n",
    "\n",
    "    if len(home_rows) == 0 or len(away_rows) == 0:\n",
    "        # skip weird/incomplete games\n",
    "        continue\n",
    "\n",
    "    home_row = home_rows.iloc[0]\n",
    "    away_row = away_rows.iloc[0]\n",
    "\n",
    "    # Build nice names, coerce to string\n",
    "    home_city  = str(home_row.get(\"teamCity\", \"\") or \"\")\n",
    "    home_name  = str(home_row.get(\"teamName\", \"\") or \"\")\n",
    "    away_city  = str(away_row.get(\"teamCity\", \"\") or \"\")\n",
    "    away_name  = str(away_row.get(\"teamName\", \"\") or \"\")\n",
    "\n",
    "    home_full = (home_city + \" \" + home_name).strip()\n",
    "    away_full = (away_city + \" \" + away_name).strip()\n",
    "\n",
    "    # Scores: use the teamScore columns from each row\n",
    "    home_score = home_row.get(\"teamScore\", 0)\n",
    "    away_score = away_row.get(\"teamScore\", 0)\n",
    "\n",
    "    games_rows.append({\n",
    "        \"gameId\": gid,\n",
    "        \"gameDate\": home_row[\"gameDate\"],  # same for both rows\n",
    "        \"Home_Team_Full\": home_full,\n",
    "        \"Away_Team_Full\": away_full,\n",
    "        \"Home_Score\": home_score,\n",
    "        \"Away_Score\": away_score,\n",
    "        \"Home_Short\": home_name,\n",
    "        \"Away_Short\": away_name,\n",
    "    })\n",
    "\n",
    "backtest_games = pd.DataFrame(games_rows)\n",
    "\n",
    "print(f\"üèÄ Built backtest_games with {len(backtest_games)} games (one row per game)\")\n",
    "\n",
    "print(\"\\nüîç Sample of backtest_games:\")\n",
    "display(\n",
    "    backtest_games[\n",
    "        [\"gameDate\", \"Home_Team_Full\", \"Away_Team_Full\", \"Home_Score\", \"Away_Score\"]\n",
    "    ].head()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CELL 4: Compute team strengths table (ORtg/DRtg/Pace/Volatility)\n",
    "\n",
    "from qepc.sports.nba.strengths_v2 import calculate_advanced_strengths\n",
    "\n",
    "print(\"‚ßâ QEPC: Calculating team strengths...\")\n",
    "\n",
    "# Let strengths_v2 load from the canonical CSVs it expects\n",
    "strengths_df = calculate_advanced_strengths(\n",
    "    verbose=True,    # show one-time logs\n",
    ")\n",
    "\n",
    "if strengths_df is None or strengths_df.empty:\n",
    "    raise RuntimeError(\"Strengths table is empty - cannot continue backtest.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Calculated strengths for {len(strengths_df)} teams.\")\n",
    "print(strengths_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CELL 5: Build schedule and compute raw lambdas for all backtest games\n",
    "\n",
    "from qepc.core.lambda_engine import compute_lambda\n",
    "import pandas as pd\n",
    "\n",
    "if \"backtest_games\" not in globals() or len(backtest_games) == 0:\n",
    "    raise RuntimeError(\"backtest_games is empty or not defined. Run Cell 3 first.\")\n",
    "\n",
    "# Filter to games where both teams exist in strengths_df\n",
    "known_teams = set(str(t) for t in strengths_df[\"Team\"].unique())\n",
    "\n",
    "mask_known = (\n",
    "    backtest_games[\"Home_Short\"].isin(known_teams)\n",
    "    & backtest_games[\"Away_Short\"].isin(known_teams)\n",
    ")\n",
    "games_for_sim = backtest_games[mask_known].reset_index(drop=True)\n",
    "\n",
    "skipped_unknown = len(backtest_games) - len(games_for_sim)\n",
    "print(f\"üß™ Using {len(games_for_sim)} games with known strengths (skipped {skipped_unknown}).\")\n",
    "\n",
    "if len(games_for_sim) == 0:\n",
    "    raise RuntimeError(\"No games with matching team strengths - check naming alignment.\")\n",
    "\n",
    "# Build schedule DataFrame for lambda engine\n",
    "schedule_df = pd.DataFrame({\n",
    "    \"Home Team\": games_for_sim[\"Home_Short\"],\n",
    "    \"Away Team\": games_for_sim[\"Away_Short\"],\n",
    "})\n",
    "\n",
    "print(\"\\n‚ßâ QEPC: Computing raw lambdas for backtest schedule...\")\n",
    "lambda_df = compute_lambda(schedule_df, strengths_df)\n",
    "\n",
    "print(f\"‚úÖ Lambda table shape: {lambda_df.shape}\")\n",
    "display(lambda_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CELL 6: Patch vol_home / vol_away to use strengths_df Volatility\n",
    "\n",
    "# Drop any existing vol_* columns from lambda_df\n",
    "for col in [\"vol_home\", \"vol_away\"]:\n",
    "    if col in lambda_df.columns:\n",
    "        lambda_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Map team -> volatility from strengths_df\n",
    "vol_map = strengths_df.set_index(\"Team\")[\"Volatility\"]\n",
    "\n",
    "lambda_df[\"vol_home\"] = lambda_df[\"Home Team\"].map(vol_map).astype(float)\n",
    "lambda_df[\"vol_away\"] = lambda_df[\"Away Team\"].map(vol_map).astype(float)\n",
    "\n",
    "print(\"Sample of lambda_df with patched vol columns:\")\n",
    "display(lambda_df[[\"Home Team\", \"Away Team\", \"lambda_home\", \"lambda_away\", \"vol_home\", \"vol_away\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CELL 7: Run QEPC simulation on all games\n",
    "\n",
    "from qepc.core.simulator import run_qepc_simulation\n",
    "\n",
    "print(\"‚ßâ QEPC: Running QEPC simulation across backtest games...\")\n",
    "sim_df = run_qepc_simulation(lambda_df, num_trials=5000)\n",
    "\n",
    "if sim_df is None or sim_df.empty:\n",
    "    raise RuntimeError(\"Simulation returned no data.\")\n",
    "\n",
    "print(f\"‚úÖ Simulation complete for {len(sim_df)} games\")\n",
    "display(sim_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CELL 8: Combine predictions with actual results\n",
    "\n",
    "# Align indices\n",
    "sim_df = sim_df.reset_index(drop=True)\n",
    "games_for_sim = games_for_sim.reset_index(drop=True)\n",
    "\n",
    "if len(sim_df) != len(games_for_sim):\n",
    "    raise RuntimeError(\"Mismatch between sim_df and games_for_sim lengths.\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Date\":             games_for_sim[\"gameDate\"],\n",
    "    \"Home_Team\":        games_for_sim[\"Home_Team_Full\"],\n",
    "    \"Away_Team\":        games_for_sim[\"Away_Team_Full\"],\n",
    "    \"Home_Short\":       games_for_sim[\"Home_Short\"],\n",
    "    \"Away_Short\":       games_for_sim[\"Away_Short\"],\n",
    "    \"Pred_Home_Score\":  sim_df[\"Sim_Home_Score\"],\n",
    "    \"Pred_Away_Score\":  sim_df[\"Sim_Away_Score\"],\n",
    "})\n",
    "\n",
    "results_df[\"Pred_Total\"]   = results_df[\"Pred_Home_Score\"] + results_df[\"Pred_Away_Score\"]\n",
    "results_df[\"Pred_Spread\"]  = results_df[\"Pred_Home_Score\"] - results_df[\"Pred_Away_Score\"]\n",
    "\n",
    "# Win prob if present\n",
    "results_df[\"Home_Win_Prob\"] = sim_df.get(\"Home_Win_Prob\", 0.5)\n",
    "\n",
    "# Actuals from games_for_sim\n",
    "results_df[\"Actual_Home_Score\"] = games_for_sim[\"Home_Score\"]\n",
    "results_df[\"Actual_Away_Score\"] = games_for_sim[\"Away_Score\"]\n",
    "results_df[\"Actual_Total\"]      = results_df[\"Actual_Home_Score\"] + results_df[\"Actual_Away_Score\"]\n",
    "results_df[\"Actual_Spread\"]     = results_df[\"Actual_Home_Score\"] - results_df[\"Actual_Away_Score\"]\n",
    "\n",
    "# Winner correctness\n",
    "results_df[\"Winner_Correct\"] = (\n",
    "    (results_df[\"Actual_Home_Score\"] > results_df[\"Actual_Away_Score\"]) ==\n",
    "    (results_df[\"Home_Win_Prob\"] > 0.5)\n",
    ")\n",
    "\n",
    "# Errors\n",
    "results_df[\"Error_Total\"]  = (results_df[\"Pred_Total\"]  - results_df[\"Actual_Total\"]).abs()\n",
    "results_df[\"Error_Spread\"] = (results_df[\"Pred_Spread\"] - results_df[\"Actual_Spread\"]).abs()\n",
    "\n",
    "print(f\"‚úÖ Built results_df with {len(results_df)} games\")\n",
    "display(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CELL 9: Backtest summary metrics\n",
    "\n",
    "if len(results_df) == 0:\n",
    "    print(\"‚ùå No results to summarize.\")\n",
    "else:\n",
    "    n_games = len(results_df)\n",
    "    win_acc = results_df[\"Winner_Correct\"].mean()\n",
    "    mae_total = results_df[\"Error_Total\"].mean()\n",
    "    mae_spread = results_df[\"Error_Spread\"].mean()\n",
    "\n",
    "    print(\"üìä BACKTEST RESULTS\")\n",
    "    print(\"==================================================\")\n",
    "    print(f\"Games Analyzed:  {n_games}\")\n",
    "    print(f\"Win Accuracy:    {win_acc * 100:.1f}%\")\n",
    "    print(f\"Avg Total Error: {mae_total:.1f} pts\")\n",
    "    print(f\"Avg Spread Error:{mae_spread:.1f} pts\")\n",
    "    print(\"==================================================\\n\")\n",
    "\n",
    "    # Best / worst by total error\n",
    "    best = results_df.nsmallest(5, \"Error_Total\")\n",
    "    worst = results_df.nlargest(5, \"Error_Total\")\n",
    "\n",
    "    print(\"üèÜ Best predictions (by total error):\")\n",
    "    for _, row in best.iterrows():\n",
    "        print(\n",
    "            f\"   {row['Away_Team']} @ {row['Home_Team']} \"\n",
    "            f\"| Pred {row['Pred_Total']:.1f}, Actual {row['Actual_Total']:.1f} \"\n",
    "            f\"| Error: {row['Error_Total']:.1f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n‚ö†Ô∏è Worst predictions (by total error):\")\n",
    "    for _, row in worst.iterrows():\n",
    "        print(\n",
    "            f\"   {row['Away_Team']} @ {row['Home_Team']} \"\n",
    "            f\"| Pred {row['Pred_Total']:.1f}, Actual {row['Actual_Total']:.1f} \"\n",
    "            f\"| Error: {row['Error_Total']:.1f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Train/Test split for total calibration (out-of-sample)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if \"results_df\" not in globals() or results_df.empty:\n",
    "    raise RuntimeError(\"results_df is empty ‚Äì run the main backtest cells first.\")\n",
    "\n",
    "# 1) Sort by date to simulate \"time passing\"\n",
    "results_sorted = results_df.sort_values(\"Date\").reset_index(drop=True)\n",
    "n = len(results_sorted)\n",
    "split_idx = int(n * 0.6)  # 60% train, 40% test\n",
    "\n",
    "train = results_sorted.iloc[:split_idx].copy()\n",
    "test  = results_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Total games: {n}\")\n",
    "print(f\"Train games: {len(train)}\")\n",
    "print(f\"Test games:  {len(test)}\")\n",
    "\n",
    "# 2) Fit calibration on TRAIN: Actual ‚âà a + b * Pred_Total\n",
    "x_train = train[\"Pred_Total\"].values\n",
    "y_train = train[\"Actual_Total\"].values\n",
    "\n",
    "A = np.vstack([x_train, np.ones_like(x_train)]).T\n",
    "b_slope, a_intercept = np.linalg.lstsq(A, y_train, rcond=None)[0]\n",
    "\n",
    "print(f\"\\nüìê Calibration fit on TRAIN:\")\n",
    "print(f\"   Actual ‚âà {a_intercept:.2f} + {b_slope:.3f} * Pred_Total\")\n",
    "\n",
    "# 3) Apply calibration to TEST\n",
    "test = test.copy()\n",
    "test[\"Pred_Total_raw\"] = test[\"Pred_Total\"]\n",
    "test[\"Pred_Total_cal\"] = a_intercept + b_slope * test[\"Pred_Total_raw\"]\n",
    "\n",
    "test[\"Error_Total_raw\"] = (test[\"Pred_Total_raw\"] - test[\"Actual_Total\"]).abs()\n",
    "test[\"Error_Total_cal\"] = (test[\"Pred_Total_cal\"] - test[\"Actual_Total\"]).abs()\n",
    "\n",
    "mae_raw = test[\"Error_Total_raw\"].mean()\n",
    "mae_cal = test[\"Error_Total_cal\"].mean()\n",
    "\n",
    "# 4) Win% is unaffected by total calibration (we still use Home_Win_Prob),\n",
    "#    but we can report it for the TEST window for reference.\n",
    "win_acc_test = test[\"Winner_Correct\"].mean() if \"Winner_Correct\" in test.columns else np.nan\n",
    "\n",
    "print(\"\\nüìä OUT-OF-SAMPLE TEST RESULTS\")\n",
    "print(\"==================================================\")\n",
    "print(f\"Games in TEST:          {len(test)}\")\n",
    "print(f\"Win Accuracy (TEST):    {win_acc_test * 100:.1f}%\")\n",
    "print(f\"Avg Total Error (raw):  {mae_raw:.2f} pts\")\n",
    "print(f\"Avg Total Error (cal):  {mae_cal:.2f} pts\")\n",
    "print(\"==================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Falling back to cwd as project root\n",
      "Project root: C:\\Users\\wdors\\qepc_project\\notebooks\\01_core\n",
      "\n",
      "================================================================================\n",
      "üìÑ TeamStatistics (team game logs)\n",
      "Looking for filename: TeamStatistics.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Team_Stats (team season stats)\n",
      "Looking for filename: Team_Stats.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ PlayerStatistics (player logs)\n",
      "Looking for filename: PlayerStatistics.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Canonical Games (schedule)\n",
      "Looking for filename: Games.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ GameResults_2025 (results)\n",
      "Looking for filename: GameResults_2025.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Schedule_with_Rest\n",
      "Looking for filename: Schedule_with_Rest.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ TeamForm\n",
      "Looking for filename: TeamForm.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Players\n",
      "Looking for filename: Players.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Players_Processed\n",
      "Looking for filename: Players_Processed.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Injury_Overrides\n",
      "Looking for filename: Injury_Overrides.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Injury_Overrides_MASTER\n",
      "Looking for filename: Injury_Overrides_MASTER.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Injury_Overrides_live_espn\n",
      "Looking for filename: Injury_Overrides_live_espn.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Player_Season_Averages\n",
      "Looking for filename: Player_Season_Averages.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Player_Averages_With_CI\n",
      "Looking for filename: Player_Averages_With_CI.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Player_Recent_Form_L5\n",
      "Looking for filename: Player_Recent_Form_L5.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Player_Recent_Form_L10\n",
      "Looking for filename: Player_Recent_Form_L10.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Player_Recent_Form_L15\n",
      "Looking for filename: Player_Recent_Form_L15.csv\n",
      "‚ö†Ô∏è No matches found in project.\n",
      "\n",
      "================================================================================\n",
      "üìÑ Player_Home_Away_Splits\n",
      "Looking for filename: Player_Home_Away_Splits.csv\n",
      "‚ö†Ô∏è No matches found in project.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to get the true project root from QEPC's autoload paths module\n",
    "try:\n",
    "    from qepc.autoload.paths import get_project_root\n",
    "    project_root = get_project_root()\n",
    "except Exception:\n",
    "    # Fallback if that import fails for some reason\n",
    "    project_root = Path.cwd()\n",
    "    print(\"‚ö†Ô∏è Falling back to cwd as project root\")\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "# Helper: pick the \"best\" match for a file name among many\n",
    "def pick_best_match(matches):\n",
    "    if not matches:\n",
    "        return None\n",
    "    # Prefer paths that live under a 'data' folder and NOT under 'notebooks'\n",
    "    scored = []\n",
    "    for p in matches:\n",
    "        score = 0\n",
    "        parts = [str(part).lower() for part in p.parts]\n",
    "        if \"data\" in parts:\n",
    "            score += 2\n",
    "        if \"raw\" in parts:\n",
    "            score += 1\n",
    "        if \"props\" in parts:\n",
    "            score += 1\n",
    "        if \"results\" in parts:\n",
    "            score += 1\n",
    "        if \"notebooks\" in parts:\n",
    "            score -= 2\n",
    "        if \".ipynb_checkpoints\" in str(p):\n",
    "            score -= 5\n",
    "        scored.append((score, p))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return scored[0][1]\n",
    "\n",
    "# (label, filename)\n",
    "targets = [\n",
    "    # Core game/team data\n",
    "    (\"TeamStatistics (team game logs)\",      \"TeamStatistics.csv\"),\n",
    "    (\"Team_Stats (team season stats)\",       \"Team_Stats.csv\"),\n",
    "    (\"PlayerStatistics (player logs)\",       \"PlayerStatistics.csv\"),\n",
    "    (\"Canonical Games (schedule)\",           \"Games.csv\"),\n",
    "    (\"GameResults_2025 (results)\",           \"GameResults_2025.csv\"),\n",
    "    (\"Schedule_with_Rest\",                   \"Schedule_with_Rest.csv\"),\n",
    "    (\"TeamForm\",                             \"TeamForm.csv\"),\n",
    "\n",
    "    # Roster / players\n",
    "    (\"Players\",                              \"Players.csv\"),\n",
    "    (\"Players_Processed\",                    \"Players_Processed.csv\"),\n",
    "\n",
    "    # Injuries\n",
    "    (\"Injury_Overrides\",                     \"Injury_Overrides.csv\"),\n",
    "    (\"Injury_Overrides_MASTER\",              \"Injury_Overrides_MASTER.csv\"),\n",
    "    (\"Injury_Overrides_live_espn\",           \"Injury_Overrides_live_espn.csv\"),\n",
    "\n",
    "    # Props / aggregates\n",
    "    (\"Player_Season_Averages\",               \"Player_Season_Averages.csv\"),\n",
    "    (\"Player_Averages_With_CI\",              \"Player_Averages_With_CI.csv\"),\n",
    "    (\"Player_Recent_Form_L5\",                \"Player_Recent_Form_L5.csv\"),\n",
    "    (\"Player_Recent_Form_L10\",               \"Player_Recent_Form_L10.csv\"),\n",
    "    (\"Player_Recent_Form_L15\",               \"Player_Recent_Form_L15.csv\"),\n",
    "    (\"Player_Home_Away_Splits\",              \"Player_Home_Away_Splits.csv\"),\n",
    "]\n",
    "\n",
    "def preview_by_filename(label: str, filename: str, n: int = 3):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"üìÑ {label}\")\n",
    "    print(f\"Looking for filename: {filename}\")\n",
    "\n",
    "    # Find all matches anywhere under project_root\n",
    "    matches = [p for p in project_root.rglob(filename)]\n",
    "    if not matches:\n",
    "        print(\"‚ö†Ô∏è No matches found in project.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found matches:\")\n",
    "    for m in matches:\n",
    "        try:\n",
    "            rel = m.relative_to(project_root)\n",
    "        except ValueError:\n",
    "            rel = m\n",
    "        print(\"   ‚Ä¢\", rel)\n",
    "\n",
    "    best = pick_best_match(matches)\n",
    "    if best is None:\n",
    "        print(\"‚ö†Ô∏è Could not choose a best match.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        rel_best = best.relative_to(project_root)\n",
    "    except ValueError:\n",
    "        rel_best = best\n",
    "\n",
    "    print(f\"\\n‚úÖ Using best match: {rel_best}\")\n",
    "\n",
    "    # Load a small sample (nrows=3) to avoid pulling full 300MB files\n",
    "    try:\n",
    "        df_sample = pd.read_csv(best, nrows=n)\n",
    "        print(f\"Sample shape: {df_sample.shape}\")\n",
    "        print(\"Columns:\", list(df_sample.columns))\n",
    "        print(\"\\nSample rows:\")\n",
    "        display(df_sample)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading CSV sample: {e}\")\n",
    "\n",
    "for label, filename in targets:\n",
    "    preview_by_filename(label, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
