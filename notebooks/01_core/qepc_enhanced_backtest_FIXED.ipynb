{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üî¨ QEPC Enhanced Backtest - FIXED\n",
    "\n",
    "This notebook:\n",
    "1. Uses **actual game results** from your data files\n",
    "2. Compares QEPC predictions to real outcomes\n",
    "3. Calculates detailed accuracy metrics\n",
    "4. Generates visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Project root: C:\\Users\\wdors\\qepc_project\n",
      "‚úÖ Matplotlib loaded\n",
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "from qepc.notebook_header import qepc_notebook_setup\n",
    "\n",
    "env = qepc_notebook_setup(run_diagnostics=False)\n",
    "data_dir = env.data_dir\n",
    "raw_dir = env.raw_dir\n",
    "\n",
    "print(\"‚úÖ QEPC environment initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Load Actual Game Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP: Resolve data_dir and raw_dir using QEPC path helpers\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    # Preferred: use autoload helpers (with get_raw_data_dir if available)\n",
    "    from qepc.autoload.paths import get_data_dir, get_raw_data_dir\n",
    "\n",
    "    data_dir = get_data_dir()\n",
    "    raw_dir = get_raw_data_dir()\n",
    "except ImportError:\n",
    "    # Fallback: only get_data_dir exists\n",
    "    from qepc.autoload.paths import get_data_dir\n",
    "\n",
    "    data_dir = get_data_dir()\n",
    "    raw_dir = data_dir / \"raw\"\n",
    "except Exception:\n",
    "    # Last-resort fallback (shouldn't normally be needed)\n",
    "    print(\"‚ö†Ô∏è Could not import qepc.autoload.paths cleanly, falling back to cwd-based paths.\")\n",
    "    project_root = Path.cwd().parents[0]\n",
    "    data_dir = project_root / \"data\"\n",
    "    raw_dir = data_dir / \"raw\"\n",
    "\n",
    "print(\"data_dir:\", data_dir)\n",
    "print(\"raw_dir:\", raw_dir)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP: Load raw game-level team stats from best available CSV\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nüìä Looking for game data...\")\n",
    "\n",
    "possible_paths = [\n",
    "    raw_dir / \"TeamStatistics.csv\",\n",
    "    data_dir / \"TeamStatistics.csv\",\n",
    "    data_dir / \"GameResults_2025.csv\",\n",
    "    data_dir / \"Games.csv\",\n",
    "]\n",
    "\n",
    "team_stats = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            team_stats = pd.read_csv(path)\n",
    "            print(f\"‚úÖ Loaded: {path.name} ({len(team_stats):,} rows)\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error reading {path}: {e}\")\n",
    "\n",
    "if team_stats is None:\n",
    "    print(\"‚ùå No game data found!\")\n",
    "    print(\"   Searched:\", [str(p) for p in possible_paths])\n",
    "else:\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP: Robust date parsing (2-pass, all tz-aware -> tz-naive)\n",
    "    # ---------------------------------------------------------\n",
    "    date_col = None\n",
    "    for col in [\"gameDate\", \"Date\", \"date\", \"GAME_DATE\"]:\n",
    "        if col in team_stats.columns:\n",
    "            date_col = col\n",
    "            break\n",
    "\n",
    "    if not date_col:\n",
    "        print(\"‚ö†Ô∏è No date column found in team_stats!\")\n",
    "    else:\n",
    "        print(f\"\\nüìå Using date column: {date_col}\")\n",
    "\n",
    "        # Keep raw values for debugging\n",
    "        team_stats[\"gameDate_raw\"] = team_stats[date_col].astype(str)\n",
    "\n",
    "        # --- Pass 1: generic parser, force UTC (tz-aware) ---\n",
    "        parsed = pd.to_datetime(\n",
    "            team_stats[date_col],\n",
    "            errors=\"coerce\",   # unparseable -> NaT\n",
    "            utc=True,          # everything tz-aware\n",
    "        )\n",
    "        invalid_mask = parsed.isna()\n",
    "        invalid_count = int(invalid_mask.sum())\n",
    "        print(f\"‚ö†Ô∏è NaT after generic parse: {invalid_count}\")\n",
    "\n",
    "        # --- Pass 2: explicit format for older rows like '11/3/1995 20:00' ---\n",
    "        if invalid_count > 0:\n",
    "            alt_parsed = pd.to_datetime(\n",
    "                team_stats.loc[invalid_mask, date_col],\n",
    "                format=\"%m/%d/%Y %H:%M\",\n",
    "                errors=\"coerce\",\n",
    "                utc=True,  # also tz-aware\n",
    "            )\n",
    "            parsed.loc[invalid_mask] = alt_parsed\n",
    "\n",
    "            # Recompute invalids\n",
    "            invalid_mask = parsed.isna()\n",
    "            invalid_count = int(invalid_mask.sum())\n",
    "            print(f\"‚ö†Ô∏è Remaining NaT after m/d/Y H:M parse: {invalid_count}\")\n",
    "\n",
    "            if invalid_count > 0:\n",
    "                print(\"\\nüîç Sample of still-invalid 'gameDate_raw' values:\")\n",
    "                sample = (\n",
    "                    team_stats.loc[invalid_mask, \"gameDate_raw\"]\n",
    "                    .value_counts()\n",
    "                    .head(10)\n",
    "                )\n",
    "                print(sample)\n",
    "\n",
    "        # Now parsed is entirely tz-aware (where not NaT). Strip timezone -> tz-naive\n",
    "        parsed = parsed.dt.tz_convert(\"UTC\").dt.tz_localize(None)\n",
    "\n",
    "        # Attach parsed dates\n",
    "        team_stats[\"gameDate\"] = parsed\n",
    "\n",
    "        # Drop truly invalid rows\n",
    "        valid_dates = team_stats[\"gameDate\"].notna()\n",
    "        dropped = int((~valid_dates).sum())\n",
    "        if dropped > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è Dropping {dropped} rows with unparseable dates after both passes.\")\n",
    "        team_stats = team_stats[valid_dates].copy()\n",
    "\n",
    "        if len(team_stats) > 0:\n",
    "            # sort by date now that everything is tz-naive\n",
    "            team_stats = team_stats.sort_values(\"gameDate\").reset_index(drop=True)\n",
    "\n",
    "            print(f\"\\n‚úÖ Remaining rows: {len(team_stats):,}\")\n",
    "            print(\n",
    "                \"üìÖ Date range:\",\n",
    "                team_stats[\"gameDate\"].min().date(),\n",
    "                \"to\",\n",
    "                team_stats[\"gameDate\"].max().date(),\n",
    "            )\n",
    "        else:\n",
    "            print(\"‚ùå No valid dates in data after parsing!\")\n",
    "\n",
    "    print(f\"\\nüìã Columns available: {list(team_stats.columns)[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Set Backtest Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if team_stats is not None and 'gameDate' in team_stats.columns:\n",
    "    # Auto-detect date range from data\n",
    "    latest_date = team_stats['gameDate'].max()\n",
    "    earliest_date = team_stats['gameDate'].min()\n",
    "    \n",
    "    # Default: last 30 days of available data\n",
    "    BACKTEST_START = latest_date - timedelta(days=180)\n",
    "    BACKTEST_END = latest_date\n",
    "    \n",
    "    print(f\"üéØ Backtest Configuration:\")\n",
    "    print(f\"   Start: {BACKTEST_START.date()}\")\n",
    "    print(f\"   End:   {BACKTEST_END.date()}\")\n",
    "    print(f\"   Days:  {(BACKTEST_END - BACKTEST_START).days}\")\n",
    "    \n",
    "    # Filter to backtest window\n",
    "    backtest_data = team_stats[\n",
    "        (team_stats['gameDate'] >= BACKTEST_START) &\n",
    "        (team_stats['gameDate'] <= BACKTEST_END)\n",
    "    ].copy()\n",
    "    \n",
    "    # Get home games only (avoid duplicates)\n",
    "    if 'home' in backtest_data.columns:\n",
    "        backtest_games = backtest_data[backtest_data['home'] == 1].copy()\n",
    "    else:\n",
    "        backtest_games = backtest_data.copy()\n",
    "    \n",
    "    print(f\"\\nüìä Games in backtest window: {len(backtest_games)}\")\n",
    "    \n",
    "    # Create standardized team name columns\n",
    "    if 'teamName' in backtest_games.columns:\n",
    "        backtest_games['Home_Team'] = (backtest_games.get('teamCity', '') + ' ' + backtest_games['teamName']).str.strip()\n",
    "        backtest_games['Away_Team'] = (backtest_games.get('opponentTeamCity', '') + ' ' + backtest_games.get('opponentTeamName', '')).str.strip()\n",
    "    \n",
    "    # Create score columns\n",
    "    for src, dst in [('teamScore', 'Home_Score'), ('opponentScore', 'Away_Score')]:\n",
    "        if src in backtest_games.columns:\n",
    "            backtest_games[dst] = backtest_games[src]\n",
    "    \n",
    "    if len(backtest_games) > 0:\n",
    "        print(\"‚úÖ Ready to backtest!\")\n",
    "    else:\n",
    "        print(\"‚ùå No games found in date range\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot set parameters - no data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üöÄ Run QEPC Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÆ Running QEPC predictions...\\n\")\n",
    "\n",
    "results = []\n",
    "errors_log = []\n",
    "\n",
    "if 'backtest_games' in dir() and len(backtest_games) > 0:\n",
    "    total_games = len(backtest_games)\n",
    "    \n",
    "    for i, (idx, game) in enumerate(backtest_games.iterrows()):\n",
    "        # Progress indicator\n",
    "        if (i + 1) % 10 == 0 or i == 0:\n",
    "            print(f\"‚è≥ Processing game {i+1}/{total_games}...\", end=\"\\r\")\n",
    "        \n",
    "        try:\n",
    "            home_team = game.get('Home_Team', game.get('teamName', 'Home'))\n",
    "            away_team = game.get('Away_Team', game.get('opponentTeamName', 'Away'))\n",
    "            \n",
    "            # Get team strengths\n",
    "            strengths = calculate_advanced_strengths(verbose=False)\n",
    "            \n",
    "            if strengths.empty:\n",
    "                errors_log.append(f\"Game {i}: No strength data\")\n",
    "                continue\n",
    "            \n",
    "            # Build schedule\n",
    "            schedule = pd.DataFrame([{\n",
    "                'Home Team': home_team,\n",
    "                'Away Team': away_team\n",
    "            }])\n",
    "            \n",
    "            # Compute lambdas\n",
    "            schedule_with_lambda = compute_lambda(schedule, strengths)\n",
    "            \n",
    "            # Run simulation\n",
    "            predictions = run_qepc_simulation(schedule_with_lambda, num_trials=5000)\n",
    "            \n",
    "            if len(predictions) == 0:\n",
    "                continue\n",
    "            \n",
    "            pred = predictions.iloc[0]\n",
    "            \n",
    "            # Get predictions\n",
    "            pred_home = pred.get('Sim_Home_Score', pred.get('lambda_home', 110))\n",
    "            pred_away = pred.get('Sim_Away_Score', pred.get('lambda_away', 108))\n",
    "            home_win_prob = pred.get('Home_Win_Prob', 0.5)\n",
    "            \n",
    "            # Get actuals\n",
    "            actual_home = game.get('Home_Score', game.get('teamScore', 0))\n",
    "            actual_away = game.get('Away_Score', game.get('opponentScore', 0))\n",
    "            \n",
    "            # Calculate outcomes\n",
    "            actual_home_won = actual_home > actual_away\n",
    "            pred_home_won = home_win_prob > 0.5\n",
    "            \n",
    "            results.append({\n",
    "                'Date': game['gameDate'],\n",
    "                'Home_Team': home_team,\n",
    "                'Away_Team': away_team,\n",
    "                'Pred_Home_Score': round(pred_home, 1),\n",
    "                'Pred_Away_Score': round(pred_away, 1),\n",
    "                'Pred_Total': round(pred_home + pred_away, 1),\n",
    "                'Pred_Spread': round(pred_home - pred_away, 1),\n",
    "                'Home_Win_Prob': round(home_win_prob, 3),\n",
    "                'Actual_Home_Score': actual_home,\n",
    "                'Actual_Away_Score': actual_away,\n",
    "                'Actual_Total': actual_home + actual_away,\n",
    "                'Actual_Spread': actual_home - actual_away,\n",
    "                'Winner_Correct': actual_home_won == pred_home_won,\n",
    "                'Error_Total': abs((pred_home + pred_away) - (actual_home + actual_away)),\n",
    "                'Error_Spread': abs((pred_home - pred_away) - (actual_home - actual_away)),\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors_log.append(f\"Game {i}: {str(e)[:40]}\")\n",
    "    \n",
    "    print(\"\\n\")  # Clear progress line\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"‚úÖ Backtest complete!\")\n",
    "    print(f\"   Games analyzed: {len(results_df)}\")\n",
    "    print(f\"   Errors skipped: {len(errors_log)}\")\n",
    "else:\n",
    "    print(\"‚ùå No games to backtest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results_df' in dir() and len(results_df) > 0:\n",
    "    # Calculate metrics\n",
    "    win_accuracy = results_df['Winner_Correct'].mean()\n",
    "    avg_total_error = results_df['Error_Total'].mean()\n",
    "    avg_spread_error = results_df['Error_Spread'].mean()\n",
    "    median_total_error = results_df['Error_Total'].median()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä BACKTEST RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              PERFORMANCE SUMMARY                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Games Analyzed:     {len(results_df):>6}                    ‚îÇ\n",
    "‚îÇ  Win Accuracy:       {win_accuracy:>6.1%}                    ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Avg Total Error:    {avg_total_error:>6.1f} pts               ‚îÇ\n",
    "‚îÇ  Median Total Error: {median_total_error:>6.1f} pts               ‚îÇ\n",
    "‚îÇ  Avg Spread Error:   {avg_spread_error:>6.1f} pts               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    \"\"\")\n",
    "    \n",
    "    # High confidence analysis\n",
    "    results_df['Confidence'] = abs(results_df['Pred_Spread'])\n",
    "    high_conf = results_df[results_df['Confidence'] > 5]\n",
    "    \n",
    "    if len(high_conf) > 0:\n",
    "        print(f\"\\nüéØ High Confidence Games (|spread| > 5):\")\n",
    "        print(f\"   Count: {len(high_conf)}\")\n",
    "        print(f\"   Accuracy: {high_conf['Winner_Correct'].mean():.1%}\")\n",
    "    \n",
    "    # Best predictions\n",
    "    print(f\"\\nüèÜ Best Predictions (smallest error):\")\n",
    "    best = results_df.nsmallest(5, 'Error_Total')\n",
    "    for _, row in best.iterrows():\n",
    "        date = pd.Timestamp(row['Date']).strftime('%m-%d')\n",
    "        print(f\"   {date}: {row['Away_Team'][:18]:18} @ {row['Home_Team'][:18]:18} | Error: {row['Error_Total']:.1f}\")\n",
    "    \n",
    "    # Worst predictions\n",
    "    print(f\"\\n‚ö†Ô∏è Worst Predictions (largest error):\")\n",
    "    worst = results_df.nlargest(5, 'Error_Total')\n",
    "    for _, row in worst.iterrows():\n",
    "        date = pd.Timestamp(row['Date']).strftime('%m-%d')\n",
    "        print(f\"   {date}: {row['Away_Team'][:18]:18} @ {row['Home_Team'][:18]:18} | Error: {row['Error_Total']:.1f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"‚ùå No results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_PLOTS and 'results_df' in dir() and len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Predicted vs Actual Total\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.scatter(results_df['Actual_Total'], results_df['Pred_Total'], alpha=0.6, s=50)\n",
    "    min_val = min(results_df['Actual_Total'].min(), results_df['Pred_Total'].min()) - 10\n",
    "    max_val = max(results_df['Actual_Total'].max(), results_df['Pred_Total'].max()) + 10\n",
    "    ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect')\n",
    "    ax1.set_xlabel('Actual Total', fontsize=12)\n",
    "    ax1.set_ylabel('Predicted Total', fontsize=12)\n",
    "    ax1.set_title('Predicted vs Actual Total Score', fontsize=14)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Error Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(results_df['Error_Total'], bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax2.axvline(results_df['Error_Total'].mean(), color='r', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {avg_total_error:.1f}')\n",
    "    ax2.axvline(results_df['Error_Total'].median(), color='orange', linestyle='--', linewidth=2,\n",
    "                label=f'Median: {median_total_error:.1f}')\n",
    "    ax2.set_xlabel('Total Error (points)', fontsize=12)\n",
    "    ax2.set_ylabel('Frequency', fontsize=12)\n",
    "    ax2.set_title('Distribution of Total Score Error', fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Error Over Time\n",
    "    ax3 = axes[1, 0]\n",
    "    results_sorted = results_df.sort_values('Date')\n",
    "    ax3.plot(range(len(results_sorted)), results_sorted['Error_Total'], \n",
    "             marker='o', alpha=0.6, markersize=5, linewidth=1)\n",
    "    ax3.axhline(avg_total_error, color='r', linestyle='--', linewidth=2, label='Mean Error')\n",
    "    ax3.set_xlabel('Game Number', fontsize=12)\n",
    "    ax3.set_ylabel('Total Error (points)', fontsize=12)\n",
    "    ax3.set_title('Prediction Error Over Time', fontsize=14)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Win Accuracy by Confidence\n",
    "    ax4 = axes[1, 1]\n",
    "    bins = [0, 3, 6, 10, 100]\n",
    "    labels = ['0-3', '3-6', '6-10', '10+']\n",
    "    results_df['Conf_Bin'] = pd.cut(results_df['Confidence'], bins=bins, labels=labels)\n",
    "    \n",
    "    accuracy_by_conf = results_df.groupby('Conf_Bin', observed=True)['Winner_Correct'].agg(['mean', 'count'])\n",
    "    \n",
    "    bars = ax4.bar(range(len(accuracy_by_conf)), accuracy_by_conf['mean'], color='steelblue')\n",
    "    ax4.axhline(0.5, color='r', linestyle='--', linewidth=2, label='50% (coin flip)')\n",
    "    ax4.axhline(win_accuracy, color='green', linestyle='--', linewidth=2, label=f'Overall: {win_accuracy:.1%}')\n",
    "    ax4.set_xticks(range(len(accuracy_by_conf)))\n",
    "    ax4.set_xticklabels(labels)\n",
    "    ax4.set_xlabel('Predicted Spread (confidence)', fontsize=12)\n",
    "    ax4.set_ylabel('Win Accuracy', fontsize=12)\n",
    "    ax4.set_title('Win Accuracy by Confidence Level', fontsize=14)\n",
    "    ax4.set_ylim(0, 1)\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, accuracy_by_conf['count'])):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                 f'n={int(count)}', ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualizations complete\")\n",
    "elif not HAS_PLOTS:\n",
    "    print(\"‚ö†Ô∏è Matplotlib not available - skipping visualizations\")\n",
    "else:\n",
    "    print(\"‚ùå No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results_df' in dir() and len(results_df) > 0:\n",
    "    # Save detailed results\n",
    "    output_dir = project_root / \"data\" / \"results\" / \"backtests\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"Enhanced_Backtest_{timestamp}.csv\"\n",
    "    output_path = output_dir / filename\n",
    "    \n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"üíæ Saved results to: {output_path}\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(f\"\"\"\n",
    "üìã FINAL SUMMARY\n",
    "================\n",
    "Period:       {BACKTEST_START.date()} to {BACKTEST_END.date()}\n",
    "Games:        {len(results_df)}\n",
    "Win Accuracy: {win_accuracy:.1%}\n",
    "Avg Error:    {avg_total_error:.1f} pts\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"‚ùå No results to save\")\n",
    "\n",
    "print(\"üèÅ Backtest complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Next Steps\n",
    "\n",
    "### Based on your results:\n",
    "\n",
    "**If Win Accuracy < 55%:**\n",
    "- Add recency weighting to team strengths\n",
    "- Include rest day adjustments\n",
    "- Consider injuries impact\n",
    "\n",
    "**If Total Error > 15 points:**\n",
    "- Calibrate lambda calculations\n",
    "- Add pace adjustments\n",
    "- Review team volatility modeling\n",
    "\n",
    "**If High Confidence games underperform:**\n",
    "- Add upset probability (quantum tunneling)\n",
    "- Consider travel factors\n",
    "- Review matchup-specific adjustments\n",
    "\n",
    "---\n",
    "\n",
    "**Use these insights to improve QEPC!** üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to get the true project root from QEPC's autoload paths module\n",
    "try:\n",
    "    from qepc.autoload.paths import get_project_root\n",
    "    project_root = get_project_root()\n",
    "except Exception:\n",
    "    # Fallback if that import fails for some reason\n",
    "    project_root = Path.cwd()\n",
    "    print(\"‚ö†Ô∏è Falling back to cwd as project root\")\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "# Helper: pick the \"best\" match for a file name among many\n",
    "def pick_best_match(matches):\n",
    "    if not matches:\n",
    "        return None\n",
    "    # Prefer paths that live under a 'data' folder and NOT under 'notebooks'\n",
    "    scored = []\n",
    "    for p in matches:\n",
    "        score = 0\n",
    "        parts = [str(part).lower() for part in p.parts]\n",
    "        if \"data\" in parts:\n",
    "            score += 2\n",
    "        if \"raw\" in parts:\n",
    "            score += 1\n",
    "        if \"props\" in parts:\n",
    "            score += 1\n",
    "        if \"results\" in parts:\n",
    "            score += 1\n",
    "        if \"notebooks\" in parts:\n",
    "            score -= 2\n",
    "        if \".ipynb_checkpoints\" in str(p):\n",
    "            score -= 5\n",
    "        scored.append((score, p))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return scored[0][1]\n",
    "\n",
    "# (label, filename)\n",
    "targets = [\n",
    "    # Core game/team data\n",
    "    (\"TeamStatistics (team game logs)\",      \"TeamStatistics.csv\"),\n",
    "    (\"Team_Stats (team season stats)\",       \"Team_Stats.csv\"),\n",
    "    (\"PlayerStatistics (player logs)\",       \"PlayerStatistics.csv\"),\n",
    "    (\"Canonical Games (schedule)\",           \"Games.csv\"),\n",
    "    (\"GameResults_2025 (results)\",           \"GameResults_2025.csv\"),\n",
    "    (\"Schedule_with_Rest\",                   \"Schedule_with_Rest.csv\"),\n",
    "    (\"TeamForm\",                             \"TeamForm.csv\"),\n",
    "\n",
    "    # Roster / players\n",
    "    (\"Players\",                              \"Players.csv\"),\n",
    "    (\"Players_Processed\",                    \"Players_Processed.csv\"),\n",
    "\n",
    "    # Injuries\n",
    "    (\"Injury_Overrides\",                     \"Injury_Overrides.csv\"),\n",
    "    (\"Injury_Overrides_MASTER\",              \"Injury_Overrides_MASTER.csv\"),\n",
    "    (\"Injury_Overrides_live_espn\",           \"Injury_Overrides_live_espn.csv\"),\n",
    "\n",
    "    # Props / aggregates\n",
    "    (\"Player_Season_Averages\",               \"Player_Season_Averages.csv\"),\n",
    "    (\"Player_Averages_With_CI\",              \"Player_Averages_With_CI.csv\"),\n",
    "    (\"Player_Recent_Form_L5\",                \"Player_Recent_Form_L5.csv\"),\n",
    "    (\"Player_Recent_Form_L10\",               \"Player_Recent_Form_L10.csv\"),\n",
    "    (\"Player_Recent_Form_L15\",               \"Player_Recent_Form_L15.csv\"),\n",
    "    (\"Player_Home_Away_Splits\",              \"Player_Home_Away_Splits.csv\"),\n",
    "]\n",
    "\n",
    "def preview_by_filename(label: str, filename: str, n: int = 3):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"üìÑ {label}\")\n",
    "    print(f\"Looking for filename: {filename}\")\n",
    "\n",
    "    # Find all matches anywhere under project_root\n",
    "    matches = [p for p in project_root.rglob(filename)]\n",
    "    if not matches:\n",
    "        print(\"‚ö†Ô∏è No matches found in project.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found matches:\")\n",
    "    for m in matches:\n",
    "        try:\n",
    "            rel = m.relative_to(project_root)\n",
    "        except ValueError:\n",
    "            rel = m\n",
    "        print(\"   ‚Ä¢\", rel)\n",
    "\n",
    "    best = pick_best_match(matches)\n",
    "    if best is None:\n",
    "        print(\"‚ö†Ô∏è Could not choose a best match.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        rel_best = best.relative_to(project_root)\n",
    "    except ValueError:\n",
    "        rel_best = best\n",
    "\n",
    "    print(f\"\\n‚úÖ Using best match: {rel_best}\")\n",
    "\n",
    "    # Load a small sample (nrows=3) to avoid pulling full 300MB files\n",
    "    try:\n",
    "        df_sample = pd.read_csv(best, nrows=n)\n",
    "        print(f\"Sample shape: {df_sample.shape}\")\n",
    "        print(\"Columns:\", list(df_sample.columns))\n",
    "        print(\"\\nSample rows:\")\n",
    "        display(df_sample)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading CSV sample: {e}\")\n",
    "\n",
    "for label, filename in targets:\n",
    "    preview_by_filename(label, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QEPC Paths] Project Root set: C:\\Users\\wdors\\qepc_project\n",
      "[QEPC] data_dir: C:\\Users\\wdors\\qepc_project\\data\n",
      "[QEPC] raw_dir: C:\\Users\\wdors\\qepc_project\\data\\raw\n",
      "\n",
      "üìä Loading team game logs from: C:\\Users\\wdors\\qepc_project\\data\\raw\\TeamStatistics.csv\n",
      "‚úÖ Loaded TeamStatistics: 144,314 rows, 48 columns\n",
      "üìå Using date column: gameDate\n",
      "‚ö†Ô∏è NaT after generic parse: 143758\n",
      "‚ö†Ô∏è Remaining NaT after m/d/Y H:M parse: 0\n",
      "\n",
      "‚úÖ Final TeamStatistics rows: 144,314\n",
      "üìÖ Date range: 1946-11-26 to 2025-11-17\n",
      "\n",
      "üïí Recent games since 2024-10-01: 3,326 team-rows\n",
      "üéØ Unique game-rows for evaluation (calibration): 1,663\n",
      "\n",
      "‚ßâ QEPC: Computing team strengths (calculate_advanced_strengths)...\n",
      "[Strengths] Processing 144314 game records...\n",
      "[Strengths] Calculated ratings for 39 teams\n",
      "Computed real lambdas for 1663 games.\n",
      "Computed lambdas for 1,663 games.\n",
      "\n",
      "‚ßâ QEPC: Running QEPC simulation on calibration sample...\n",
      "\n",
      "üìä MINI BACKTEST SUMMARY (CALIBRATION SAMPLE)\n",
      "============================================================\n",
      "Games Evaluated:       1663\n",
      "Home-Win Accuracy:      44.7%  (NOTE: 'home' label here is synthetic)\n",
      "Mean Total Error:       18.3 pts\n",
      "Median Total Error:     15.0 pts\n",
      "Mean Spread Error:      15.8 pts\n",
      "\n",
      "üéØ CALIBRATION FACTOR\n",
      "============================================================\n",
      "Mean actual total:     227.49\n",
      "Mean predicted total:  227.40\n",
      "Suggested LAMBDA_TOTAL_SCALE: 1.0004\n",
      "\n",
      "üîé Sample rows (Actual vs Pred totals):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameDate</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Away Team</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>Actual_Total</th>\n",
       "      <th>Pred_Total</th>\n",
       "      <th>Total_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-04 12:00:00</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Nuggets</td>\n",
       "      <td>107</td>\n",
       "      <td>103</td>\n",
       "      <td>210</td>\n",
       "      <td>232.317096</td>\n",
       "      <td>22.317096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-04 22:30:00</td>\n",
       "      <td>Lakers</td>\n",
       "      <td>Timberwolves</td>\n",
       "      <td>107</td>\n",
       "      <td>124</td>\n",
       "      <td>231</td>\n",
       "      <td>229.090540</td>\n",
       "      <td>1.909460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-05 19:00:00</td>\n",
       "      <td>Clippers</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>181</td>\n",
       "      <td>221.788554</td>\n",
       "      <td>40.788554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-06 10:00:00</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Nuggets</td>\n",
       "      <td>130</td>\n",
       "      <td>104</td>\n",
       "      <td>234</td>\n",
       "      <td>238.650867</td>\n",
       "      <td>4.650867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-06 17:00:00</td>\n",
       "      <td>Hornets</td>\n",
       "      <td>Knicks</td>\n",
       "      <td>109</td>\n",
       "      <td>111</td>\n",
       "      <td>220</td>\n",
       "      <td>231.214183</td>\n",
       "      <td>11.214183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-10-06 19:30:00</td>\n",
       "      <td>Raptors</td>\n",
       "      <td>Wizards</td>\n",
       "      <td>125</td>\n",
       "      <td>98</td>\n",
       "      <td>223</td>\n",
       "      <td>223.878198</td>\n",
       "      <td>0.878198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-10-06 20:00:00</td>\n",
       "      <td>Bucks</td>\n",
       "      <td>Pistons</td>\n",
       "      <td>87</td>\n",
       "      <td>120</td>\n",
       "      <td>207</td>\n",
       "      <td>225.220887</td>\n",
       "      <td>18.220887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-10-06 21:30:00</td>\n",
       "      <td>Lakers</td>\n",
       "      <td>Suns</td>\n",
       "      <td>114</td>\n",
       "      <td>118</td>\n",
       "      <td>232</td>\n",
       "      <td>228.885618</td>\n",
       "      <td>3.114382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-10-07 13:30:00</td>\n",
       "      <td>Magic</td>\n",
       "      <td>Pelicans</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>210</td>\n",
       "      <td>217.736703</td>\n",
       "      <td>7.736703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-10-07 20:00:00</td>\n",
       "      <td>Grizzlies</td>\n",
       "      <td>Mavericks</td>\n",
       "      <td>121</td>\n",
       "      <td>116</td>\n",
       "      <td>237</td>\n",
       "      <td>211.871917</td>\n",
       "      <td>25.128083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gameDate  Home Team     Away Team  Home_Score  Away_Score  \\\n",
       "0 2024-10-04 12:00:00    Celtics       Nuggets         107         103   \n",
       "1 2024-10-04 22:30:00     Lakers  Timberwolves         107         124   \n",
       "2 2024-10-05 19:00:00   Clippers      Warriors          90          91   \n",
       "3 2024-10-06 10:00:00    Celtics       Nuggets         130         104   \n",
       "4 2024-10-06 17:00:00    Hornets        Knicks         109         111   \n",
       "5 2024-10-06 19:30:00    Raptors       Wizards         125          98   \n",
       "6 2024-10-06 20:00:00      Bucks       Pistons          87         120   \n",
       "7 2024-10-06 21:30:00     Lakers          Suns         114         118   \n",
       "8 2024-10-07 13:30:00      Magic      Pelicans         104         106   \n",
       "9 2024-10-07 20:00:00  Grizzlies     Mavericks         121         116   \n",
       "\n",
       "   Actual_Total  Pred_Total  Total_Error  \n",
       "0           210  232.317096    22.317096  \n",
       "1           231  229.090540     1.909460  \n",
       "2           181  221.788554    40.788554  \n",
       "3           234  238.650867     4.650867  \n",
       "4           220  231.214183    11.214183  \n",
       "5           223  223.878198     0.878198  \n",
       "6           207  225.220887    18.220887  \n",
       "7           232  228.885618     3.114382  \n",
       "8           210  217.736703     7.736703  \n",
       "9           237  211.871917    25.128083  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# QEPC imports\n",
    "from qepc.sports.nba.strengths_v2 import calculate_advanced_strengths\n",
    "from qepc.core.lambda_engine import compute_lambda\n",
    "from qepc.core.simulator import run_qepc_simulation\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 0) Resolve data paths (project_root / data / raw)\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    from qepc.autoload.paths import get_data_dir, get_raw_data_dir\n",
    "\n",
    "    data_dir = get_data_dir()\n",
    "    raw_dir = get_raw_data_dir()\n",
    "except ImportError:\n",
    "    # Fallback if get_raw_data_dir doesn't exist\n",
    "    from qepc.autoload.paths import get_data_dir\n",
    "\n",
    "    data_dir = get_data_dir()\n",
    "    raw_dir = data_dir / \"raw\"\n",
    "except Exception:\n",
    "    # Last-resort fallback\n",
    "    project_root = Path.cwd().parents[0]\n",
    "    data_dir = project_root / \"data\"\n",
    "    raw_dir = data_dir / \"raw\"\n",
    "\n",
    "print(\"[QEPC] data_dir:\", data_dir)\n",
    "print(\"[QEPC] raw_dir:\", raw_dir)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) Load TeamStatistics.csv and parse gameDate robustly\n",
    "# ---------------------------------------------------------\n",
    "team_stats_path = raw_dir / \"TeamStatistics.csv\"\n",
    "print(\"\\nüìä Loading team game logs from:\", team_stats_path)\n",
    "\n",
    "if not team_stats_path.exists():\n",
    "    raise FileNotFoundError(f\"TeamStatistics.csv not found at {team_stats_path}\")\n",
    "\n",
    "team_stats_raw = pd.read_csv(team_stats_path)\n",
    "print(f\"‚úÖ Loaded TeamStatistics: {len(team_stats_raw):,} rows, {len(team_stats_raw.columns)} columns\")\n",
    "\n",
    "# Detect date column\n",
    "date_col = None\n",
    "for col in [\"gameDate\", \"Date\", \"date\", \"GAME_DATE\"]:\n",
    "    if col in team_stats_raw.columns:\n",
    "        date_col = col\n",
    "        break\n",
    "\n",
    "if date_col is None:\n",
    "    raise RuntimeError(\"No date-like column found in TeamStatistics.csv\")\n",
    "\n",
    "print(f\"üìå Using date column: {date_col}\")\n",
    "\n",
    "team_stats = team_stats_raw.copy()\n",
    "team_stats[\"gameDate_raw\"] = team_stats[date_col].astype(str)\n",
    "\n",
    "# Pass 1: generic parser, tz-aware\n",
    "parsed = pd.to_datetime(\n",
    "    team_stats[date_col],\n",
    "    errors=\"coerce\",\n",
    "    utc=True,\n",
    ")\n",
    "invalid_mask = parsed.isna()\n",
    "invalid_count = int(invalid_mask.sum())\n",
    "print(f\"‚ö†Ô∏è NaT after generic parse: {invalid_count}\")\n",
    "\n",
    "# Pass 2: explicit \"%m/%d/%Y %H:%M\" for old records (also tz-aware)\n",
    "if invalid_count > 0:\n",
    "    alt_parsed = pd.to_datetime(\n",
    "        team_stats.loc[invalid_mask, date_col],\n",
    "        format=\"%m/%d/%Y %H:%M\",\n",
    "        errors=\"coerce\",\n",
    "        utc=True,\n",
    "    )\n",
    "    parsed.loc[invalid_mask] = alt_parsed\n",
    "    invalid_mask = parsed.isna()\n",
    "    invalid_count = int(invalid_mask.sum())\n",
    "    print(f\"‚ö†Ô∏è Remaining NaT after m/d/Y H:M parse: {invalid_count}\")\n",
    "\n",
    "    if invalid_count > 0:\n",
    "        print(\"\\nüîç Sample of still-invalid 'gameDate_raw' values:\")\n",
    "        sample = (\n",
    "            team_stats.loc[invalid_mask, \"gameDate_raw\"]\n",
    "            .value_counts()\n",
    "            .head(10)\n",
    "        )\n",
    "        print(sample)\n",
    "\n",
    "# Strip timezone ‚Üí tz-naive\n",
    "parsed = parsed.dt.tz_convert(\"UTC\").dt.tz_localize(None)\n",
    "team_stats[\"gameDate\"] = parsed\n",
    "\n",
    "# Drop rows with no valid date\n",
    "valid_dates = team_stats[\"gameDate\"].notna()\n",
    "dropped = int((~valid_dates).sum())\n",
    "if dropped > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Dropping {dropped} rows with unparseable dates after both passes.\")\n",
    "team_stats = team_stats[valid_dates].copy()\n",
    "\n",
    "# Sort by date\n",
    "team_stats = team_stats.sort_values(\"gameDate\").reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Final TeamStatistics rows: {len(team_stats):,}\")\n",
    "print(\n",
    "    \"üìÖ Date range:\",\n",
    "    team_stats[\"gameDate\"].min().date(),\n",
    "    \"to\",\n",
    "    team_stats[\"gameDate\"].max().date(),\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) Build recent evaluation set (one row per game)\n",
    "# ---------------------------------------------------------\n",
    "recent_cutoff = pd.Timestamp(\"2024-10-01\")\n",
    "recent_games = team_stats[team_stats[\"gameDate\"] >= recent_cutoff].copy()\n",
    "\n",
    "print(f\"\\nüïí Recent games since {recent_cutoff.date()}: {len(recent_games):,} team-rows\")\n",
    "\n",
    "# Collapse to one row per game by keeping one of the pair.\n",
    "# NOTE: This uses a deterministic rule (teamName < opponentTeamName)\n",
    "# just to avoid duplicates. For totals calibration, home/away doesn't matter.\n",
    "mask_keep = recent_games[\"teamName\"] < recent_games[\"opponentTeamName\"]\n",
    "games_eval = recent_games[mask_keep].copy()\n",
    "\n",
    "games_eval = games_eval.rename(\n",
    "    columns={\n",
    "        \"teamName\": \"Home Team\",          # label only; not true home\n",
    "        \"opponentTeamName\": \"Away Team\",  # label only; not true away\n",
    "        \"teamScore\": \"Home_Score\",\n",
    "        \"opponentScore\": \"Away_Score\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"üéØ Unique game-rows for evaluation (calibration): {len(games_eval):,}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Compute team strengths from full game log\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n‚ßâ QEPC: Computing team strengths (calculate_advanced_strengths)...\")\n",
    "strengths_df = calculate_advanced_strengths(\n",
    "    game_data=team_stats,\n",
    "    cutoff_date=None,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "if strengths_df is None or strengths_df.empty:\n",
    "    raise RuntimeError(\"strengths_df is empty. Check strengths_v2 configuration.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4) Build schedule df and compute lambdas\n",
    "# ---------------------------------------------------------\n",
    "schedule_df = games_eval[[\"Home Team\", \"Away Team\"]].reset_index(drop=True)\n",
    "\n",
    "lambda_df = compute_lambda(\n",
    "    schedule_df=schedule_df,\n",
    "    team_stats_df=strengths_df,\n",
    "    include_situational=False,  # keep it clean for calibration\n",
    ")\n",
    "\n",
    "print(f\"Computed lambdas for {len(lambda_df):,} games.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5) Run QEPC simulation on these lambdas\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n‚ßâ QEPC: Running QEPC simulation on calibration sample...\")\n",
    "sim_results = run_qepc_simulation(\n",
    "    df=lambda_df,\n",
    "    num_trials=3000,\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6) Assemble eval_df: actual vs predicted totals & margins\n",
    "# ---------------------------------------------------------\n",
    "eval_df = games_eval.reset_index(drop=True).copy()\n",
    "\n",
    "# Attach lambdas & sim outputs\n",
    "eval_df[\"lambda_home\"] = lambda_df[\"lambda_home\"].values\n",
    "eval_df[\"lambda_away\"] = lambda_df[\"lambda_away\"].values\n",
    "eval_df[\"Sim_Home_Score\"] = sim_results[\"Sim_Home_Score\"].values\n",
    "eval_df[\"Sim_Away_Score\"] = sim_results[\"Sim_Away_Score\"].values\n",
    "eval_df[\"Home_Win_Prob\"] = sim_results[\"Home_Win_Prob\"].values\n",
    "eval_df[\"Expected_Score_Total\"] = sim_results[\"Expected_Score_Total\"].values\n",
    "\n",
    "# Actual totals / margins\n",
    "eval_df[\"Actual_Total\"] = eval_df[\"Home_Score\"] + eval_df[\"Away_Score\"]\n",
    "eval_df[\"Actual_Margin\"] = eval_df[\"Home_Score\"] - eval_df[\"Away_Score\"]\n",
    "\n",
    "# Predicted totals / margins\n",
    "eval_df[\"Pred_Total\"] = eval_df[\"Expected_Score_Total\"]\n",
    "eval_df[\"Pred_Margin\"] = eval_df[\"Sim_Home_Score\"] - eval_df[\"Sim_Away_Score\"]\n",
    "\n",
    "# Binary outcome (based on fake \"home\" label; totals calibration doesn't care)\n",
    "eval_df[\"Actual_Home_Win\"] = (eval_df[\"Home_Score\"] > eval_df[\"Away_Score\"]).astype(int)\n",
    "eval_df[\"Pred_Home_Win\"] = (eval_df[\"Home_Win_Prob\"] >= 0.5).astype(int)\n",
    "\n",
    "# Errors\n",
    "eval_df[\"Total_Error\"] = (eval_df[\"Pred_Total\"] - eval_df[\"Actual_Total\"]).abs()\n",
    "eval_df[\"Spread_Error\"] = (eval_df[\"Pred_Margin\"] - eval_df[\"Actual_Margin\"]).abs()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7) Summary metrics\n",
    "# ---------------------------------------------------------\n",
    "n_games = len(eval_df)\n",
    "win_acc = (eval_df[\"Pred_Home_Win\"] == eval_df[\"Actual_Home_Win\"]).mean() * 100.0\n",
    "mae_total = eval_df[\"Total_Error\"].mean()\n",
    "med_total = eval_df[\"Total_Error\"].median()\n",
    "mae_spread = eval_df[\"Spread_Error\"].mean()\n",
    "\n",
    "print(\"\\nüìä MINI BACKTEST SUMMARY (CALIBRATION SAMPLE)\")\n",
    "print(\"============================================================\")\n",
    "print(f\"Games Evaluated:       {n_games}\")\n",
    "print(f\"Home-Win Accuracy:     {win_acc:5.1f}%  (NOTE: 'home' label here is synthetic)\")\n",
    "print(f\"Mean Total Error:      {mae_total:5.1f} pts\")\n",
    "print(f\"Median Total Error:    {med_total:5.1f} pts\")\n",
    "print(f\"Mean Spread Error:     {mae_spread:5.1f} pts\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8) Compute calibration factor for Œª totals\n",
    "# ---------------------------------------------------------\n",
    "mean_actual_total = eval_df[\"Actual_Total\"].mean()\n",
    "mean_pred_total = eval_df[\"Pred_Total\"].mean()\n",
    "calib_factor = mean_actual_total / mean_pred_total\n",
    "\n",
    "print(\"\\nüéØ CALIBRATION FACTOR\")\n",
    "print(\"============================================================\")\n",
    "print(f\"Mean actual total:     {mean_actual_total:.2f}\")\n",
    "print(f\"Mean predicted total:  {mean_pred_total:.2f}\")\n",
    "print(f\"Suggested LAMBDA_TOTAL_SCALE: {calib_factor:.4f}\")\n",
    "\n",
    "print(\"\\nüîé Sample rows (Actual vs Pred totals):\")\n",
    "display(\n",
    "    eval_df[\n",
    "        [\n",
    "            \"gameDate\",\n",
    "            \"Home Team\",\n",
    "            \"Away Team\",\n",
    "            \"Home_Score\",\n",
    "            \"Away_Score\",\n",
    "            \"Actual_Total\",\n",
    "            \"Pred_Total\",\n",
    "            \"Total_Error\",\n",
    "        ]\n",
    "    ].head(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
