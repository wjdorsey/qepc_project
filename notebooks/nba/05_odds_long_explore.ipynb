{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c50be-4f86-4f18-be1e-165bd85290d6",
   "metadata": {
    "deletable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 1 – AUTO-DETECT PROJECT ROOT & IMPORTS\n",
    "# ==========================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Auto-detect project root by looking for \"qepc\" package above CWD\n",
    "here = Path.cwd().resolve()\n",
    "print(\"Current working directory:\", here)\n",
    "\n",
    "PROJECT_ROOT = None\n",
    "for p in [here, *here.parents]:\n",
    "    if (p / \"qepc\").is_dir():\n",
    "        PROJECT_ROOT = p\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find a 'qepc' package above this notebook.\\n\"\n",
    "        f\"Started search from: {here}\\n\"\n",
    "        \"Make sure this notebook lives somewhere inside your qepc_project folder.\"\n",
    "    )\n",
    "\n",
    "print(\"Detected PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "    print(\"Added PROJECT_ROOT to sys.path\")\n",
    "\n",
    "# (Nothing from qepc imported yet; this notebook is mostly external data exploration.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184e198-7f4b-4416-acbb-ed2249b5229a",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 2 – DOWNLOAD NBA BETTING DATA FROM KAGGLE\n",
    "# ==========================================\n",
    "import kagglehub\n",
    "\n",
    "# This is the dataset we picked:\n",
    "# \"NBA Betting Data | October 2007 to June 2024\"\n",
    "DATASET_ID = \"cviaxmiwnptr/nba-betting-data-october-2007-to-june-2024\"\n",
    "\n",
    "odds_path_str = kagglehub.dataset_download(DATASET_ID)\n",
    "odds_path = Path(odds_path_str).resolve()\n",
    "\n",
    "print(\"Path to NBA betting dataset files:\", odds_path)\n",
    "\n",
    "# List CSVs so we can see what's inside\n",
    "csv_files = list(odds_path.rglob(\"*.csv\"))\n",
    "print(\"CSV files found:\", len(csv_files))\n",
    "for f in csv_files:\n",
    "    print(\" -\", f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c0dfb-0a20-4cd5-bb37-15ef1a3d0a14",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 3 – LOAD RAW ODDS CSV & INSPECT\n",
    "# ==========================================\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found under {odds_path}\")\n",
    "\n",
    "# For now, just grab the first CSV (this dataset should only have one)\n",
    "raw_csv = csv_files[0]\n",
    "print(\"Using CSV:\", raw_csv)\n",
    "\n",
    "odds_raw = pd.read_csv(raw_csv)\n",
    "print(\"odds_raw shape:\", odds_raw.shape)\n",
    "\n",
    "print(\"Columns:\")\n",
    "for c in odds_raw.columns:\n",
    "    print(\" -\", c)\n",
    "\n",
    "display(odds_raw.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860a760-ce1b-4684-a242-89174d04926a",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 4 – NORMALIZE NBA ODDS TABLE\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "\n",
    "odds = odds_raw.copy()\n",
    "\n",
    "# 1) Normalize date + team codes\n",
    "odds[\"game_date\"] = pd.to_datetime(odds[\"date\"]).dt.date\n",
    "odds[\"home_code\"] = odds[\"home\"].str.upper()\n",
    "odds[\"away_code\"] = odds[\"away\"].str.upper()\n",
    "\n",
    "# 2) Compute home/away spreads from \"whos_favored\" + \"spread\"\n",
    "def compute_home_away_spreads(row):\n",
    "    fav = row[\"whos_favored\"]\n",
    "    s = row[\"spread\"]\n",
    "    if pd.isna(s) or fav not in (\"home\", \"away\"):\n",
    "        return np.nan, np.nan\n",
    "    if fav == \"home\":\n",
    "        # Home is -spread, away is +spread\n",
    "        return -float(s), float(s)\n",
    "    else:\n",
    "        # Away is -spread, home is +spread\n",
    "        return float(s), -float(s)\n",
    "\n",
    "home_spreads = []\n",
    "away_spreads = []\n",
    "\n",
    "for _, r in odds.iterrows():\n",
    "    h_s, a_s = compute_home_away_spreads(r)\n",
    "    home_spreads.append(h_s)\n",
    "    away_spreads.append(a_s)\n",
    "\n",
    "odds[\"spread_home\"] = home_spreads\n",
    "odds[\"spread_away\"] = away_spreads\n",
    "\n",
    "# 3) Keep total as-is (full-game total points)\n",
    "odds[\"total_points\"] = odds[\"total\"]\n",
    "\n",
    "# 4) Convert American moneyline to implied probability\n",
    "def american_to_prob(odds_american):\n",
    "    \"\"\"\n",
    "    Convert American odds to implied probability (before removing vig).\n",
    "    Example: -140 -> ~0.58, +200 -> ~0.333\n",
    "    \"\"\"\n",
    "    if pd.isna(odds_american):\n",
    "        return np.nan\n",
    "    o = float(odds_american)\n",
    "    if o < 0:\n",
    "        return (-o) / ((-o) + 100.0)\n",
    "    else:\n",
    "        return 100.0 / (o + 100.0)\n",
    "\n",
    "odds[\"p_home_raw\"] = odds[\"moneyline_home\"].apply(american_to_prob)\n",
    "odds[\"p_away_raw\"] = odds[\"moneyline_away\"].apply(american_to_prob)\n",
    "\n",
    "# Remove vig by normalizing\n",
    "sum_raw = odds[\"p_home_raw\"] + odds[\"p_away_raw\"]\n",
    "odds[\"p_home\"] = odds[\"p_home_raw\"] / sum_raw\n",
    "odds[\"p_away\"] = odds[\"p_away_raw\"] / sum_raw\n",
    "\n",
    "# 5) Build a simple \"game_key\" to help with matching later\n",
    "odds[\"game_key\"] = (\n",
    "    odds[\"game_date\"].astype(str)\n",
    "    + \"_\"\n",
    "    + odds[\"away_code\"]\n",
    "    + \"_\"\n",
    "    + odds[\"home_code\"]\n",
    ")\n",
    "\n",
    "# 6) Select a tidy subset of columns\n",
    "odds_tidy = odds[[\n",
    "    \"season\",\n",
    "    \"game_date\",\n",
    "    \"game_key\",\n",
    "    \"away_code\",\n",
    "    \"home_code\",\n",
    "    \"score_away\",\n",
    "    \"score_home\",\n",
    "    \"spread_home\",\n",
    "    \"spread_away\",\n",
    "    \"total_points\",\n",
    "    \"moneyline_away\",\n",
    "    \"moneyline_home\",\n",
    "    \"p_away\",\n",
    "    \"p_home\",\n",
    "    \"regular\",\n",
    "    \"playoffs\",\n",
    "]]\n",
    "\n",
    "print(\"odds_tidy shape:\", odds_tidy.shape)\n",
    "odds_tidy.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481550a7-c3d3-4f81-bf30-3d997aa71535",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 5 – MARKET VS ACTUAL TOTALS\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "\n",
    "totals_df = odds_tidy.copy()\n",
    "\n",
    "# Actual total points scored\n",
    "totals_df[\"actual_total\"] = totals_df[\"score_home\"] + totals_df[\"score_away\"]\n",
    "\n",
    "# Error from the *market* point of view:\n",
    "# positive = game went over the closing total\n",
    "totals_df[\"total_error\"] = totals_df[\"actual_total\"] - totals_df[\"total_points\"]\n",
    "\n",
    "mae_total = totals_df[\"total_error\"].abs().mean()\n",
    "rmse_total = np.sqrt((totals_df[\"total_error\"] ** 2).mean())\n",
    "mean_error_total = totals_df[\"total_error\"].mean()\n",
    "\n",
    "print(f\"Total line MAE:  {mae_total:.2f} points\")\n",
    "print(f\"Total line RMSE: {rmse_total:.2f} points\")\n",
    "print(f\"Total line bias (actual - line): {mean_error_total:+.2f} points\")\n",
    "\n",
    "# Show a few examples\n",
    "display(\n",
    "    totals_df[[\n",
    "        \"season\",\n",
    "        \"game_date\",\n",
    "        \"away_code\",\n",
    "        \"home_code\",\n",
    "        \"score_away\",\n",
    "        \"score_home\",\n",
    "        \"total_points\",\n",
    "        \"actual_total\",\n",
    "        \"total_error\",\n",
    "    ]].head(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4739f79-7df2-4a49-8d02-7d67db185037",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 6 – MARKET VS ACTUAL SPREADS (HOME) – FIXED\n",
    "# ==========================================\n",
    "spreads_df = odds_tidy.copy()\n",
    "\n",
    "# Actual margin from home POV: positive = home wins by that many\n",
    "spreads_df[\"home_margin\"] = spreads_df[\"score_home\"] - spreads_df[\"score_away\"]\n",
    "\n",
    "# Remember: spread_home is negative if home is favored, positive if home is dog.\n",
    "# Expected home margin = -spread_home\n",
    "# So error (actual - line) = home_margin - expected = home_margin + spread_home\n",
    "spreads_df[\"spread_error_home\"] = spreads_df[\"home_margin\"] + spreads_df[\"spread_home\"]\n",
    "\n",
    "mae_spread = spreads_df[\"spread_error_home\"].abs().mean()\n",
    "rmse_spread = np.sqrt((spreads_df[\"spread_error_home\"] ** 2).mean())\n",
    "mean_error_spread = spreads_df[\"spread_error_home\"].mean()\n",
    "\n",
    "print(f\"Home spread MAE:  {mae_spread:.2f} points\")\n",
    "print(f\"Home spread RMSE: {rmse_spread:.2f} points\")\n",
    "print(f\"Home spread bias (actual margin - line): {mean_error_spread:+.2f} points\")\n",
    "\n",
    "display(\n",
    "    spreads_df[[\n",
    "        \"season\",\n",
    "        \"game_date\",\n",
    "        \"away_code\",\n",
    "        \"home_code\",\n",
    "        \"score_away\",\n",
    "        \"score_home\",\n",
    "        \"spread_home\",\n",
    "        \"home_margin\",\n",
    "        \"spread_error_home\",\n",
    "    ]].head(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f1679-528b-4c0f-a262-77d73dd8e759",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 7 – LOAD EOIN TEAM HISTORIES\n",
    "# ==========================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "RAW_EOIN = PROJECT_ROOT / \"data\" / \"raw\" / \"nba\" / \"eoin\"\n",
    "team_hist_path = RAW_EOIN / \"TeamHistories.csv\"\n",
    "\n",
    "print(\"TeamHistories path:\", team_hist_path)\n",
    "if not team_hist_path.exists():\n",
    "    raise FileNotFoundError(f\"TeamHistories.csv not found at {team_hist_path}\")\n",
    "\n",
    "team_hist = pd.read_csv(team_hist_path)\n",
    "print(\"team_hist shape:\", team_hist.shape)\n",
    "print(\"Columns:\")\n",
    "for c in team_hist.columns:\n",
    "    print(\" -\", c)\n",
    "\n",
    "team_hist.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f892940-b226-463a-98be-2b745a02666f",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 8 – BUILD TEAM CODE → ID/NAME MAPPING\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "\n",
    "df = team_hist.copy()\n",
    "\n",
    "# Try to auto-detect likely code + id + name columns\n",
    "code_candidates = [\n",
    "    c for c in df.columns\n",
    "    if any(k in c.lower() for k in [\"abbr\", \"code\"])\n",
    "]\n",
    "id_candidates = [\n",
    "    c for c in df.columns\n",
    "    if \"team\" in c.lower() and \"id\" in c.lower()\n",
    "]\n",
    "name_candidates = [\n",
    "    c for c in df.columns\n",
    "    if \"name\" in c.lower() and \"team\" in c.lower()\n",
    "]\n",
    "\n",
    "print(\"Code candidates:\", code_candidates)\n",
    "print(\"ID candidates:\", id_candidates)\n",
    "print(\"Name candidates:\", name_candidates)\n",
    "\n",
    "if not code_candidates:\n",
    "    raise ValueError(\n",
    "        \"Could not auto-detect a team code/abbreviation column.\\n\"\n",
    "        \"Check team_hist.columns above and pick one manually.\"\n",
    "    )\n",
    "if not id_candidates:\n",
    "    raise ValueError(\n",
    "        \"Could not auto-detect a team id column.\\n\"\n",
    "        \"Check team_hist.columns above and pick one manually.\"\n",
    "    )\n",
    "\n",
    "code_col = code_candidates[0]\n",
    "id_col = id_candidates[0]\n",
    "name_col = name_candidates[0] if name_candidates else None\n",
    "\n",
    "print(f\"Using code_col='{code_col}', id_col='{id_col}', name_col='{name_col}'\")\n",
    "\n",
    "df[\"code\"] = df[code_col].astype(str).str.upper()\n",
    "df[\"team_id\"] = df[id_col].astype(int)\n",
    "\n",
    "if name_col is not None:\n",
    "    df[\"team_name\"] = df[name_col].astype(str)\n",
    "else:\n",
    "    # Fallback: try to build a name from city + nickname if they exist\n",
    "    city_cols = [c for c in df.columns if \"city\" in c.lower()]\n",
    "    nick_cols = [c for c in df.columns if \"nickname\" in c.lower() or \"name\" in c.lower()]\n",
    "\n",
    "    if city_cols and nick_cols:\n",
    "        df[\"team_name\"] = (\n",
    "            df[city_cols[0]].astype(str) + \" \" + df[nick_cols[0]].astype(str)\n",
    "        )\n",
    "    else:\n",
    "        df[\"team_name\"] = df[\"code\"]  # worst-case fallback\n",
    "\n",
    "team_codes = (\n",
    "    df[[\"code\", \"team_id\", \"team_name\"]]\n",
    "    .drop_duplicates(\"code\")\n",
    "    .sort_values(\"code\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"team_codes shape:\", team_codes.shape)\n",
    "team_codes.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13962e05-d6dd-4089-9411-2ddc1a05f9e6",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 9 – CHECK CODE COVERAGE: ODDS VS EOIN\n",
    "# ==========================================\n",
    "odds_codes = set(odds_long[\"home_code\"]) | set(odds_long[\"away_code\"])\n",
    "eoin_codes = set(team_codes[\"code\"])\n",
    "\n",
    "missing_in_eoin = sorted(odds_codes - eoin_codes)\n",
    "missing_in_odds = sorted(eoin_codes - odds_codes)\n",
    "\n",
    "print(\"Unique odds codes:\", len(odds_codes))\n",
    "print(\"Unique Eoin codes:\", len(eoin_codes))\n",
    "print(\"Codes in odds but NOT in Eoin mapping:\", missing_in_eoin[:50])\n",
    "print(\"Codes in Eoin mapping but NOT in odds:\", missing_in_odds[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d86c3-95b3-4657-b79d-53c39aa87c4e",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad8658-7afd-4f48-8c4f-0a9669cf1358",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d0d32-9be5-44b6-9ea3-e84a7063b618",
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
