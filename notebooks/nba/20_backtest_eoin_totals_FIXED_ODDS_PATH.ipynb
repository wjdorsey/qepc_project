{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d64816a",
   "metadata": {},
   "source": [
    "# QEPC NBA — Leakage‑free Eoin totals backtest + optional Odds baseline\n",
    "\n",
    "This notebook is designed to be **portable across machines** (no hardcoded `C:\\Users\\...` paths) and **leakage‑free** (rolling features use only past games).\n",
    "\n",
    "It:\n",
    "- Loads Eoin games parquet from `cache/imports/eoin_games_qepc.parquet`\n",
    "- Builds simple team rolling offense/defense priors (cumulative PPG since a cutoff)\n",
    "- Predicts home/away points and totals, then reports MAE\n",
    "- Adds an **environment drift** correction (two-window blend) to reduce league-wide scoring drift\n",
    "- Optionally attaches Kaggle “long odds” and reports a Vegas baseline MAE when the CSV exists\n",
    "\n",
    "If the odds CSV is not present on this machine, the odds section will **skip gracefully**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Robust project-root bootstrap (portable; no hardcoded paths) ---\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Detect repo root by walking up until we find qepc/__init__.py\n",
    "_cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = None\n",
    "for p in [_cwd] + list(_cwd.parents):\n",
    "    if (p / \"qepc\" / \"__init__.py\").exists():\n",
    "        PROJECT_ROOT = p\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise RuntimeError(\n",
    "        f\"Could not find PROJECT_ROOT above {_cwd}. Expected qepc/__init__.py to exist.\"\n",
    "    )\n",
    "\n",
    "# Ensure imports come from this repo first (avoids accidentally importing another copy)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import qepc\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"qepc imported from:\", Path(qepc.__file__).resolve())\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"cwd:\", _cwd)\n",
    "\n",
    "CONFIG = {\n",
    "    # Start building priors from this date forward (keeps things \"modern\")\n",
    "    \"modern_cutoff\": dt.date(2022, 10, 1),\n",
    "\n",
    "    # Scoring window. If None, defaults to modern_cutoff → min(games_max, odds_max if odds exist)\n",
    "    \"backtest_start\": None,\n",
    "    \"backtest_end\": None,\n",
    "\n",
    "    # Minimum prior games per team required before we emit a scored row\n",
    "    \"min_games_per_team\": 5,\n",
    "\n",
    "    # Simple adjustments (tune later)\n",
    "    \"home_bonus\": 1.5,\n",
    "    \"away_penalty\": 0.5,\n",
    "    \"b2b_penalty\": 1.5,\n",
    "\n",
    "    # Optional: walk-forward linear calibration on (raw_pred → actual) for home/away separately\n",
    "    \"use_calibration\": True,\n",
    "    \"min_calibration_rows\": 200,\n",
    "}\n",
    "print(\"CONFIG:\", CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: Load Eoin games parquet (no hardcoded paths) ---\n",
    "from pathlib import Path\n",
    "\n",
    "games_path = Path(PROJECT_ROOT) / \"cache\" / \"imports\" / \"eoin_games_qepc.parquet\"\n",
    "if not games_path.exists():\n",
    "    # fallback search (helps if someone moved cache/)\n",
    "    matches = list(Path(PROJECT_ROOT).rglob(\"eoin_games_qepc.parquet\"))\n",
    "    if matches:\n",
    "        games_path = matches[0]\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find eoin_games_qepc.parquet under {PROJECT_ROOT}.\\n\"\n",
    "            \"Expected at: cache/imports/eoin_games_qepc.parquet\\n\"\n",
    "            \"Run your Eoin fetch/build notebook on this machine first.\"\n",
    "        )\n",
    "\n",
    "games = pd.read_parquet(games_path).copy()\n",
    "\n",
    "# Normalize / coerce key columns\n",
    "if \"game_date\" not in games.columns:\n",
    "    raise KeyError(\"Expected 'game_date' in games parquet.\")\n",
    "\n",
    "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"], errors=\"coerce\").dt.date\n",
    "\n",
    "# Score columns\n",
    "HOME_COL = \"home_score\" if \"home_score\" in games.columns else None\n",
    "AWAY_COL = \"away_score\" if \"away_score\" in games.columns else None\n",
    "if HOME_COL is None or AWAY_COL is None:\n",
    "    raise KeyError(\"Expected 'home_score' and 'away_score' columns in Eoin games table.\")\n",
    "\n",
    "# IDs\n",
    "for col in [\"game_id\", \"home_team_id\", \"away_team_id\"]:\n",
    "    if col not in games.columns:\n",
    "        raise KeyError(f\"Expected '{col}' in games parquet.\")\n",
    "\n",
    "games = games.sort_values([\"game_date\", \"game_id\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"games rows:\", len(games))\n",
    "print(\"games date range:\", games[\"game_date\"].min(), \"→\", games[\"game_date\"].max())\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f356c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Try to load odds (optional). If missing, we continue without odds. ---\n",
    "from pathlib import Path\n",
    "\n",
    "HAS_ODDS = False\n",
    "odds = None\n",
    "odds_max_date = None\n",
    "\n",
    "try:\n",
    "    from qepc.nba.odds_long_loader import load_long_odds, attach_odds_to_games\n",
    "\n",
    "    odds_path = Path(PROJECT_ROOT) / \"data\" / \"raw\" / \"nba\" / \"odds_long\" / \"nba_2008-2025.csv\"\n",
    "    if not odds_path.exists():\n",
    "        matches = list(Path(PROJECT_ROOT).rglob(\"nba_2008-2025.csv\"))\n",
    "        if matches:\n",
    "            odds_path = matches[0]\n",
    "\n",
    "    if odds_path.exists():\n",
    "        odds = load_long_odds(odds_path)\n",
    "        HAS_ODDS = True\n",
    "        odds_max_date = pd.to_datetime(odds[\"game_date\"], errors=\"coerce\").max().date()\n",
    "        print(\"[odds] loaded:\", odds_path)\n",
    "        print(\"[odds] date range:\", odds[\"game_date\"].min(), \"→\", odds[\"game_date\"].max(), \"rows:\", len(odds))\n",
    "    else:\n",
    "        print(\"[odds] csv not found under repo; skipping odds attach.\")\n",
    "        HAS_ODDS = False\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[odds] failed to load odds; skipping. Error:\", repr(e))\n",
    "    HAS_ODDS = False\n",
    "\n",
    "HAS_ODDS, odds_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1488344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 4: Backtest builder (leakage-free) ---\n",
    "# Rolling priors use games strictly BEFORE each game:\n",
    "# - off_ppg_prev = avg points scored so far\n",
    "# - def_ppg_prev = avg points allowed so far\n",
    "#\n",
    "# Predict:\n",
    "#   raw_home = (home_off_ppg_prev + away_def_ppg_prev)/2 + home_bonus - b2b_penalty*(home_is_b2b)\n",
    "#   raw_away = (away_off_ppg_prev + home_def_ppg_prev)/2 - away_penalty - b2b_penalty*(away_is_b2b)\n",
    "#\n",
    "# Optional calibration happens in the next cell.\n",
    "\n",
    "modern_cutoff = CONFIG[\"modern_cutoff\"]\n",
    "start = CONFIG[\"backtest_start\"] or modern_cutoff\n",
    "\n",
    "# If odds exist, default end to odds coverage (keeps backtest comparable to Vegas).\n",
    "# Otherwise, end at the max game_date in games.\n",
    "end_default = odds_max_date if HAS_ODDS and odds_max_date is not None else games[\"game_date\"].max()\n",
    "end = CONFIG[\"backtest_end\"] or end_default\n",
    "\n",
    "min_gp = int(CONFIG[\"min_games_per_team\"])\n",
    "\n",
    "games_slice = games[(games[\"game_date\"] >= modern_cutoff) & (games[\"game_date\"] <= end)].copy()\n",
    "games_slice = games_slice.sort_values([\"game_date\", \"game_id\"]).reset_index(drop=True)\n",
    "\n",
    "# Rolling state per team (since modern_cutoff)\n",
    "gp = {}\n",
    "pf = {}\n",
    "pa = {}\n",
    "last_date = {}\n",
    "\n",
    "rows = []\n",
    "skipped_no_history = 0\n",
    "\n",
    "for _, g in games_slice.iterrows():\n",
    "    gdate = g[\"game_date\"]\n",
    "    home_id = int(g[\"home_team_id\"])\n",
    "    away_id = int(g[\"away_team_id\"])\n",
    "\n",
    "    # Prior state BEFORE updating with this game\n",
    "    home_gp = gp.get(home_id, 0)\n",
    "    away_gp = gp.get(away_id, 0)\n",
    "\n",
    "    home_off = (pf.get(home_id, 0.0) / home_gp) if home_gp > 0 else np.nan\n",
    "    home_def = (pa.get(home_id, 0.0) / home_gp) if home_gp > 0 else np.nan\n",
    "    away_off = (pf.get(away_id, 0.0) / away_gp) if away_gp > 0 else np.nan\n",
    "    away_def = (pa.get(away_id, 0.0) / away_gp) if away_gp > 0 else np.nan\n",
    "\n",
    "    home_is_b2b = bool((home_id in last_date) and ((gdate - last_date[home_id]).days == 1))\n",
    "    away_is_b2b = bool((away_id in last_date) and ((gdate - last_date[away_id]).days == 1))\n",
    "\n",
    "    # Emit scored row only if both teams have enough history\n",
    "    if (home_gp >= min_gp) and (away_gp >= min_gp) and (gdate >= start):\n",
    "        raw_home = 0.5 * (home_off + away_def) + float(CONFIG[\"home_bonus\"]) - (float(CONFIG[\"b2b_penalty\"]) if home_is_b2b else 0.0)\n",
    "        raw_away = 0.5 * (away_off + home_def) - float(CONFIG[\"away_penalty\"]) - (float(CONFIG[\"b2b_penalty\"]) if away_is_b2b else 0.0)\n",
    "\n",
    "        actual_home = float(g[HOME_COL])\n",
    "        actual_away = float(g[AWAY_COL])\n",
    "\n",
    "        rows.append({\n",
    "            \"game_id\": int(g[\"game_id\"]),\n",
    "            \"game_date\": gdate,\n",
    "            \"home_team_id\": home_id,\n",
    "            \"away_team_id\": away_id,\n",
    "\n",
    "            \"home_off_ppg_prev\": float(home_off),\n",
    "            \"home_def_ppg_prev\": float(home_def),\n",
    "            \"away_off_ppg_prev\": float(away_off),\n",
    "            \"away_def_ppg_prev\": float(away_def),\n",
    "\n",
    "            \"home_is_b2b\": home_is_b2b,\n",
    "            \"away_is_b2b\": away_is_b2b,\n",
    "\n",
    "            \"exp_home_pts_raw\": float(raw_home),\n",
    "            \"exp_away_pts_raw\": float(raw_away),\n",
    "\n",
    "            # placeholders to fill after calibration (or copy raw)\n",
    "            \"exp_home_pts\": float(raw_home),\n",
    "            \"exp_away_pts\": float(raw_away),\n",
    "\n",
    "            \"actual_home_pts\": actual_home,\n",
    "            \"actual_away_pts\": actual_away,\n",
    "        })\n",
    "    elif gdate >= start:\n",
    "        skipped_no_history += 1\n",
    "\n",
    "    # UPDATE state with this game AFTER scoring (prevents leakage)\n",
    "    gp[home_id] = home_gp + 1\n",
    "    pf[home_id] = pf.get(home_id, 0.0) + float(g[HOME_COL])\n",
    "    pa[home_id] = pa.get(home_id, 0.0) + float(g[AWAY_COL])\n",
    "    last_date[home_id] = gdate\n",
    "\n",
    "    gp[away_id] = away_gp + 1\n",
    "    pf[away_id] = pf.get(away_id, 0.0) + float(g[AWAY_COL])\n",
    "    pa[away_id] = pa.get(away_id, 0.0) + float(g[HOME_COL])\n",
    "    last_date[away_id] = gdate\n",
    "\n",
    "backtest_df = pd.DataFrame(rows).sort_values([\"game_date\", \"game_id\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"built backtest rows:\", len(backtest_df))\n",
    "print(\"skipped (insufficient history during scoring window):\", skipped_no_history)\n",
    "backtest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72417ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Walk-forward calibration (optional; leakage-free) ---\n",
    "df = backtest_df.copy()\n",
    "\n",
    "if df.empty:\n",
    "    raise RuntimeError(\"No backtest rows built. Try lowering min_games_per_team or widening the date range.\")\n",
    "\n",
    "def expanding_ols_yhat(x: pd.Series, y: pd.Series, min_train: int = 200) -> pd.Series:\n",
    "    # Walk-forward OLS for y ≈ a + b*x using cumulative sums; predictions use only prior rows.\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "\n",
    "    cum_x  = x.cumsum().shift(1).fillna(0.0)\n",
    "    cum_y  = y.cumsum().shift(1).fillna(0.0)\n",
    "    cum_x2 = (x * x).cumsum().shift(1).fillna(0.0)\n",
    "    cum_xy = (x * y).cumsum().shift(1).fillna(0.0)\n",
    "\n",
    "    n = pd.Series(np.arange(len(x)), index=x.index).astype(float)\n",
    "\n",
    "    den = n * cum_x2 - cum_x * cum_x\n",
    "    b = np.where(den != 0, (n * cum_xy - cum_x * cum_y) / den, 1.0)\n",
    "    a = np.where(n != 0, (cum_y - b * cum_x) / n, 0.0)\n",
    "\n",
    "    use = n >= float(min_train)\n",
    "    a = np.where(use, a, 0.0)\n",
    "    b = np.where(use, b, 1.0)\n",
    "\n",
    "    return pd.Series(a + b * x, index=x.index)\n",
    "\n",
    "if CONFIG[\"use_calibration\"]:\n",
    "    min_cal = int(CONFIG[\"min_calibration_rows\"])\n",
    "    df[\"exp_home_pts\"] = expanding_ols_yhat(df[\"exp_home_pts_raw\"], df[\"actual_home_pts\"], min_train=min_cal)\n",
    "    df[\"exp_away_pts\"] = expanding_ols_yhat(df[\"exp_away_pts_raw\"], df[\"actual_away_pts\"], min_train=min_cal)\n",
    "else:\n",
    "    df[\"exp_home_pts\"] = df[\"exp_home_pts_raw\"]\n",
    "    df[\"exp_away_pts\"] = df[\"exp_away_pts_raw\"]\n",
    "\n",
    "# Totals + errors\n",
    "df[\"total_pred\"] = df[\"exp_home_pts\"] + df[\"exp_away_pts\"]\n",
    "df[\"total_actual\"] = df[\"actual_home_pts\"] + df[\"actual_away_pts\"]\n",
    "\n",
    "df[\"home_abs_err\"] = (df[\"exp_home_pts\"] - df[\"actual_home_pts\"]).abs()\n",
    "df[\"away_abs_err\"] = (df[\"exp_away_pts\"] - df[\"actual_away_pts\"]).abs()\n",
    "df[\"total_abs_err\"] = (df[\"total_pred\"] - df[\"total_actual\"]).abs()\n",
    "\n",
    "backtest_df = df\n",
    "\n",
    "print(\"Backtest rows:\", len(df))\n",
    "print(\"MAE home:\", round(df[\"home_abs_err\"].mean(), 3))\n",
    "print(\"MAE away:\", round(df[\"away_abs_err\"].mean(), 3))\n",
    "print(\"MAE total:\", round(df[\"total_abs_err\"].mean(), 3))\n",
    "print(\"Bias total:\", round((df[\"total_pred\"] - df[\"total_actual\"]).mean(), 3))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bbbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 6: Environment drift correction (two-window blend; leakage-free) ---\n",
    "# Estimate a league-wide scoring \"field\" and correct totals using ONLY past residuals.\n",
    "\n",
    "df = backtest_df.copy().sort_values([\"game_date\", \"game_id\"]).reset_index(drop=True)\n",
    "\n",
    "resid = (df[\"total_actual\"] - df[\"total_pred\"]).astype(float)\n",
    "\n",
    "adj_fast = resid.rolling(50,  min_periods=50).mean().shift(1).fillna(0.0)\n",
    "adj_slow = resid.rolling(250, min_periods=250).mean().shift(1).fillna(0.0)\n",
    "\n",
    "df[\"env_drift_total\"] = 0.6 * adj_fast + 0.4 * adj_slow\n",
    "df[\"total_pred_env\"] = df[\"total_pred\"] + df[\"env_drift_total\"]\n",
    "df[\"total_abs_err_env\"] = (df[\"total_pred_env\"] - df[\"total_actual\"]).abs()\n",
    "\n",
    "print(\"MAE raw :\", round((df[\"total_pred\"] - df[\"total_actual\"]).abs().mean(), 3))\n",
    "print(\"MAE env :\", round(df[\"total_abs_err_env\"].mean(), 3))\n",
    "print(\"Bias raw:\", round((df[\"total_pred\"] - df[\"total_actual\"]).mean(), 3))\n",
    "print(\"Bias env:\", round((df[\"total_pred_env\"] - df[\"total_actual\"]).mean(), 3))\n",
    "\n",
    "backtest_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 7: Optional odds attach to backtest_df and Vegas baseline ---\n",
    "df = backtest_df.copy()\n",
    "\n",
    "if HAS_ODDS and odds is not None:\n",
    "    games_for_join = df[[\"game_id\", \"game_date\", \"home_team_id\", \"away_team_id\"]].copy()\n",
    "    games_for_join[\"game_date\"] = pd.to_datetime(games_for_join[\"game_date\"], errors=\"coerce\").dt.normalize().dt.date\n",
    "\n",
    "    joined, diag = attach_odds_to_games(games_for_join, odds)\n",
    "\n",
    "    odds_cols = [c for c in joined.columns if c not in games_for_join.columns]\n",
    "    df = df.merge(joined[[\"game_id\"] + odds_cols], on=\"game_id\", how=\"left\")\n",
    "\n",
    "    if \"total_points\" in df.columns:\n",
    "        dfo = df[df[\"total_points\"].notna()].copy()\n",
    "        print(\"[odds] rows with Vegas totals:\", len(dfo))\n",
    "        print(\"QEPC raw MAE   :\", round((dfo[\"total_pred\"] - dfo[\"total_actual\"]).abs().mean(), 3))\n",
    "        print(\"QEPC env MAE   :\", round((dfo[\"total_pred_env\"] - dfo[\"total_actual\"]).abs().mean(), 3))\n",
    "        print(\"Vegas total MAE:\", round((dfo[\"total_points\"] - dfo[\"total_actual\"]).abs().mean(), 3))\n",
    "    else:\n",
    "        print(\"[odds] attached, but total_points column not present (unexpected).\")\n",
    "else:\n",
    "    print(\"Skipping odds attach (odds CSV missing or loader unavailable on this machine).\")\n",
    "\n",
    "backtest_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10136d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 8: Quick diagnostics (shared-direction errors + bias) ---\n",
    "df = backtest_df.copy()\n",
    "\n",
    "df[\"err_home\"] = df[\"exp_home_pts\"] - df[\"actual_home_pts\"]\n",
    "df[\"err_away\"] = df[\"exp_away_pts\"] - df[\"actual_away_pts\"]\n",
    "df[\"err_total\"] = df[\"total_pred\"] - df[\"total_actual\"]\n",
    "df[\"err_total_env\"] = df[\"total_pred_env\"] - df[\"total_actual\"]\n",
    "\n",
    "print(\"Corr(err_home, err_away):\", round(df[\"err_home\"].corr(df[\"err_away\"]), 3))\n",
    "print(\"Mean err_total raw:\", round(df[\"err_total\"].mean(), 3))\n",
    "print(\"Mean err_total env:\", round(df[\"err_total_env\"].mean(), 3))\n",
    "print(\"Std err_total raw:\", round(df[\"err_total\"].std(), 3))\n",
    "print(\"Std err_total env:\", round(df[\"err_total_env\"].std(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
