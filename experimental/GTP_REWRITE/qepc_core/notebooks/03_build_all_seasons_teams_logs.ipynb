{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4717b8cd-3baa-4a65-9145-1dd29a3ef919",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# ðŸ§± QEPC â€“ Build All-Seasons Team Logs\n",
    "\n",
    "This notebook merges:\n",
    "\n",
    "- `NBA_API_QEPC_Format.csv` (multi-season logs from 2014â€“15 to 2023â€“24)\n",
    "- `Team_Stats.csv` (updated season logs, e.g. 2025â€“26 from nba_api)\n",
    "\n",
    "into a single canonical file:\n",
    "\n",
    "- `NBA_Team_Logs_All_Seasons.csv` in `data/raw/`\n",
    "\n",
    "We:\n",
    "1. Load & inspect both sources.\n",
    "2. Normalize dates and seasons.\n",
    "3. Align columns (union of both).\n",
    "4. Concatenate and de-duplicate by (gameId, teamId).\n",
    "5. Write the merged file with a backup of existing sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b80bc6-7eb4-4ba0-ba23-ee4eba315cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_build_schedule_all_seasons.ipynb\n",
    "# Goal: build NBA_Schedule_All_Seasons.csv from canonical team logs.\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== QEPC Schedule Bootstrap ===\")\n",
    "\n",
    "cwd = Path.cwd()\n",
    "core_root = None\n",
    "cur = cwd\n",
    "\n",
    "for _ in range(8):\n",
    "    if cur.name == \"qepc_core\":\n",
    "        core_root = cur\n",
    "        break\n",
    "    if cur.parent == cur:\n",
    "        break\n",
    "    cur = cur.parent\n",
    "\n",
    "if core_root is None:\n",
    "    raise RuntimeError(f\"Could not find qepc_core above {cwd}\")\n",
    "\n",
    "core_str = str(core_root)\n",
    "if core_str not in sys.path:\n",
    "    sys.path.insert(0, core_str)\n",
    "\n",
    "repo_root = core_root.parent.parent.parent\n",
    "repo_str = str(repo_root)\n",
    "if repo_str not in sys.path:\n",
    "    sys.path.append(repo_str)\n",
    "\n",
    "print(\"qepc_core root:\", core_root)\n",
    "print(\"repo root:     \", repo_root)\n",
    "\n",
    "import qepc\n",
    "from qepc.config import detect_project_root, QEPCConfig\n",
    "\n",
    "project_root = detect_project_root()\n",
    "cfg = QEPCConfig.from_project_root(project_root)\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"raw_root:    \", cfg.raw_root)\n",
    "print(\"=== Bootstrap OK ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0258e-a2a6-4380-997a-5a4aba26e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_root = cfg.raw_root\n",
    "team_logs_path = raw_root / \"NBA_Team_Logs_All_Seasons.csv\"\n",
    "\n",
    "print(\"Team logs path:\", team_logs_path)\n",
    "\n",
    "team_df = pd.read_csv(team_logs_path, low_memory=False, parse_dates=[\"gameDate\"])\n",
    "\n",
    "print(\"Team logs shape:\", team_df.shape)\n",
    "print(\"Date range:\", team_df[\"gameDate\"].min(), \"â†’\", team_df[\"gameDate\"].max())\n",
    "print(\"Seasons:\", sorted(team_df[\"Season\"].dropna().unique()))\n",
    "\n",
    "# Quick peek\n",
    "display(team_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765bc28-3b74-426f-b587-1b5a4d988b1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check how many team-rows per gameId\n",
    "\n",
    "per_game_counts = (\n",
    "    team_df.groupby(\"gameId\")\n",
    "           .size()\n",
    "           .rename(\"rows_per_game\")\n",
    "           .reset_index()\n",
    ")\n",
    "\n",
    "print(per_game_counts[\"rows_per_game\"].value_counts().sort_index())\n",
    "\n",
    "weird_games = per_game_counts[per_game_counts[\"rows_per_game\"] != 2]\n",
    "print(\"\\nGames that don't have exactly 2 rows:\", len(weird_games))\n",
    "\n",
    "if len(weird_games) > 0:\n",
    "    display(weird_games.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17022870-f110-42c4-aad6-91cd43b80902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only \"good\" games with exactly 2 team rows\n",
    "\n",
    "good_game_ids = per_game_counts.loc[per_game_counts[\"rows_per_game\"] == 2, \"gameId\"]\n",
    "team_good = team_df[team_df[\"gameId\"].isin(good_game_ids)].copy()\n",
    "\n",
    "print(\"Total games with exactly 2 rows:\", len(good_game_ids))\n",
    "\n",
    "# Split into home and away\n",
    "home_rows = team_good[team_good[\"home\"] == 1].copy()\n",
    "away_rows = team_good[team_good[\"home\"] == 0].copy()\n",
    "\n",
    "print(\"Home rows:\", len(home_rows))\n",
    "print(\"Away rows:\", len(away_rows))\n",
    "\n",
    "# If there are still duplicates (e.g. weird data), keep one row per (gameId, teamId)\n",
    "home_rows = (\n",
    "    home_rows.sort_values([\"gameId\", \"gameDate\"])\n",
    "             .drop_duplicates(subset=[\"gameId\", \"teamId\"], keep=\"last\")\n",
    ")\n",
    "away_rows = (\n",
    "    away_rows.sort_values([\"gameId\", \"gameDate\"])\n",
    "             .drop_duplicates(subset=[\"gameId\", \"teamId\"], keep=\"last\")\n",
    ")\n",
    "\n",
    "# Merge home + away on gameId\n",
    "schedule = home_rows.merge(\n",
    "    away_rows,\n",
    "    on=\"gameId\",\n",
    "    suffixes=(\"_home\", \"_away\"),\n",
    ")\n",
    "\n",
    "print(\"Merged schedule shape (raw):\", schedule.shape)\n",
    "display(schedule.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66503bf-53f4-476f-a9d3-efbeb1d6f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build canonical schedule table\n",
    "\n",
    "def pick_game_date(row):\n",
    "    # prefer home row date, fallback to away\n",
    "    if pd.notna(row[\"gameDate_home\"]):\n",
    "        return row[\"gameDate_home\"]\n",
    "    return row[\"gameDate_away\"]\n",
    "\n",
    "def pick_season(row):\n",
    "    # prefer home season, fallback to away\n",
    "    if pd.notna(row[\"Season_home\"]):\n",
    "        return row[\"Season_home\"]\n",
    "    return row[\"Season_away\"]\n",
    "\n",
    "sched = pd.DataFrame({\n",
    "    \"gameId\": schedule[\"gameId\"].astype(str),\n",
    "\n",
    "    \"gameDate\": schedule.apply(pick_game_date, axis=1),\n",
    "    \"Season\": schedule.apply(pick_season, axis=1),\n",
    "\n",
    "    \"homeTeamId\": schedule[\"teamId_home\"],\n",
    "    \"homeTeamAbbrev\": schedule.get(\"teamAbbrev_home\", schedule.get(\"teamAbbrev_home\", np.nan)),\n",
    "    \"homeTeamName\": schedule[\"teamName_home\"],\n",
    "    \"homeTeamCity\": schedule[\"teamCity_home\"],\n",
    "\n",
    "    \"awayTeamId\": schedule[\"teamId_away\"],\n",
    "    \"awayTeamAbbrev\": schedule.get(\"teamAbbrev_away\", schedule.get(\"teamAbbrev_away\", np.nan)),\n",
    "    \"awayTeamName\": schedule[\"teamName_away\"],\n",
    "    \"awayTeamCity\": schedule[\"teamCity_away\"],\n",
    "\n",
    "    \"homeScore\": schedule[\"teamScore_home\"],\n",
    "    \"awayScore\": schedule[\"teamScore_away\"],\n",
    "})\n",
    "\n",
    "# Derive homeWin\n",
    "sched[\"homeWin\"] = (sched[\"homeScore\"] > sched[\"awayScore\"]).astype(float)\n",
    "\n",
    "# Tidy dtypes\n",
    "sched[\"homeTeamId\"] = pd.to_numeric(sched[\"homeTeamId\"], errors=\"coerce\").astype(\"Int64\")\n",
    "sched[\"awayTeamId\"] = pd.to_numeric(sched[\"awayTeamId\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "sched[\"gameDate\"] = pd.to_datetime(sched[\"gameDate\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Canonical schedule shape:\", sched.shape)\n",
    "print(\"Date range:\", sched[\"gameDate\"].min(), \"â†’\", sched[\"gameDate\"].max())\n",
    "print(\"Seasons:\", sorted(sched[\"Season\"].dropna().unique())[:15])\n",
    "\n",
    "display(sched.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f6256-4a75-412d-a6ba-f8d2bbd68b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fix missing gameDate in schedule by rejoining from team logs ===\n",
    "\n",
    "print(\"Fixing gameDate via team logsâ€¦\")\n",
    "\n",
    "# Ensure both sides use the same gameId type\n",
    "team_dates = (\n",
    "    team_df.assign(gameId=team_df[\"gameId\"].astype(str))\n",
    "           .groupby(\"gameId\", as_index=False)\n",
    "           .agg(gameDate_fix=(\"gameDate\", \"min\"))\n",
    ")\n",
    "\n",
    "print(\"team_dates shape:\", team_dates.shape)\n",
    "print(\"team_dates date range:\",\n",
    "      team_dates[\"gameDate_fix\"].min(), \"â†’\", team_dates[\"gameDate_fix\"].max())\n",
    "\n",
    "# Drop existing gameDate in sched and merge the fixed one\n",
    "sched = sched.copy()\n",
    "sched[\"gameId\"] = sched[\"gameId\"].astype(str)\n",
    "\n",
    "sched = (\n",
    "    sched.drop(columns=[\"gameDate\"])\n",
    "         .merge(team_dates, on=\"gameId\", how=\"left\")\n",
    "         .rename(columns={\"gameDate_fix\": \"gameDate\"})\n",
    ")\n",
    "\n",
    "print(\"After fix â€“ schedule date range:\",\n",
    "      sched[\"gameDate\"].min(), \"â†’\", sched[\"gameDate\"].max())\n",
    "\n",
    "# Re-run per-season summary\n",
    "per_season_fixed = (\n",
    "    sched.groupby(\"Season\")\n",
    "         .agg(\n",
    "             games=(\"gameId\", \"nunique\"),\n",
    "             first_date=(\"gameDate\", \"min\"),\n",
    "             last_date=(\"gameDate\", \"max\"),\n",
    "         )\n",
    "         .sort_index()\n",
    ")\n",
    "\n",
    "print(\"\\nPer-season summary AFTER fix:\")\n",
    "print(per_season_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab308c-255d-49b4-8678-4e49a2847b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-season sanity check\n",
    "\n",
    "per_season = (\n",
    "    sched.groupby(\"Season\")\n",
    "         .agg(\n",
    "             games=(\"gameId\", \"nunique\"),\n",
    "             first_date=(\"gameDate\", \"min\"),\n",
    "             last_date=(\"gameDate\", \"max\"),\n",
    "         )\n",
    "         .sort_index()\n",
    ")\n",
    "\n",
    "print(per_season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48f379-54e9-442c-b2d0-3a1e9a824d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write canonical schedule file (opt-in)\n",
    "\n",
    "schedule_path = raw_root / \"NBA_Schedule_All_Seasons.csv\"\n",
    "backup_path = schedule_path.with_suffix(\".backup_before_rebuild.csv\")\n",
    "\n",
    "WRITE_CHANGES = True  # <-- flip to True when you're ready\n",
    "\n",
    "if WRITE_CHANGES:\n",
    "    if schedule_path.exists():\n",
    "        print(f\"Backing up existing schedule to: {backup_path}\")\n",
    "        schedule_path.rename(backup_path)\n",
    "\n",
    "    print(f\"Writing canonical schedule to: {schedule_path}\")\n",
    "    sched.to_csv(schedule_path, index=False)\n",
    "\n",
    "    # Quick reload check\n",
    "    sched_check = pd.read_csv(schedule_path, parse_dates=[\"gameDate\"])\n",
    "    print(\"Reloaded shape:\", sched_check.shape)\n",
    "    print(\"Reloaded date range:\", sched_check[\"gameDate\"].min(), \"â†’\", sched_check[\"gameDate\"].max())\n",
    "else:\n",
    "    print(\"WRITE_CHANGES=False â†’ dry run only, no file written.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff228bbe-f697-4378-bc75-7a30430b3c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
