{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6166e1-ad15-4377-8774-8318a02094fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üß™ QEPC ‚Äì Enrich All-Seasons Team Logs from nba_api\n",
    "\n",
    "This notebook:\n",
    "1. Loads `NBA_Team_Logs_All_Seasons.csv`.\n",
    "2. Finds games/teams with missing advanced team stats.\n",
    "3. Uses `nba_api` boxscore endpoints to fetch:\n",
    "   - points in the paint\n",
    "   - fast break points\n",
    "   - points off turnovers\n",
    "   - second chance points\n",
    "   - bench points\n",
    "   - biggest lead / scoring run\n",
    "   - lead changes / times tied\n",
    "4. Merges those into the master table and saves it back (with a backup).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04e9b8-455f-44eb-a4e6-0e8459f9a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04_enrich_team_logs_from_nba_api.ipynb\n",
    "# Goal: fill in advanced team stats (paint, fastbreak, bench, etc.)\n",
    "#       in NBA_Team_Logs_All_Seasons.csv using nba_api live boxscore.\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== QEPC Boxscore Enrichment Bootstrap ===\")\n",
    "\n",
    "# Find qepc_core by walking up from CWD\n",
    "cwd = Path.cwd()\n",
    "core_root = None\n",
    "cur = cwd\n",
    "\n",
    "for _ in range(8):\n",
    "    if cur.name == \"qepc_core\":\n",
    "        core_root = cur\n",
    "        break\n",
    "    if cur.parent == cur:\n",
    "        break\n",
    "    cur = cur.parent\n",
    "\n",
    "if core_root is None:\n",
    "    raise RuntimeError(f\"Could not find qepc_core above {cwd}\")\n",
    "\n",
    "core_str = str(core_root)\n",
    "if core_str not in sys.path:\n",
    "    sys.path.insert(0, core_str)\n",
    "\n",
    "# Repo root is three levels above qepc_core (qepc_project/experimental/GTP_REWRITE/qepc_core)\n",
    "repo_root = core_root.parent.parent.parent\n",
    "repo_str = str(repo_root)\n",
    "if repo_str not in sys.path:\n",
    "    sys.path.append(repo_str)\n",
    "\n",
    "print(\"qepc_core root:\", core_root)\n",
    "print(\"repo root:     \", repo_root)\n",
    "\n",
    "import qepc\n",
    "from qepc.config import detect_project_root, QEPCConfig\n",
    "\n",
    "project_root = detect_project_root()\n",
    "cfg = QEPCConfig.from_project_root(project_root)\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"raw_root:    \", cfg.raw_root)\n",
    "print(\"=== Bootstrap OK ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ef61e-d833-4a24-9616-745adba1617b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the merged all-seasons team logs file\n",
    "\n",
    "raw_root = cfg.raw_root\n",
    "all_seasons_path = raw_root / \"NBA_Team_Logs_All_Seasons.csv\"\n",
    "\n",
    "print(\"All-seasons path:\", all_seasons_path)\n",
    "\n",
    "df = pd.read_csv(all_seasons_path, low_memory=False)\n",
    "\n",
    "# Normalize dates\n",
    "df[\"gameDate\"] = pd.to_datetime(df[\"gameDate\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Date range:\", df[\"gameDate\"].min(), \"‚Üí\", df[\"gameDate\"].max())\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc605f2-ce38-4612-a58e-781b09f24830",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Columns we want to backfill from the NBA live boxscore endpoint\n",
    "ENRICH_COLS = [\n",
    "    \"pointsInThePaint\",\n",
    "    \"benchPoints\",\n",
    "    \"pointsFastBreak\",\n",
    "    \"pointsFromTurnovers\",\n",
    "    \"pointsSecondChance\",\n",
    "    \"biggestLead\",\n",
    "    \"biggestScoringRun\",\n",
    "    \"leadChanges\",\n",
    "    \"timesTied\",\n",
    "    \"timeoutsRemaining\",\n",
    "]\n",
    "\n",
    "print(\"Enrichment columns:\", ENRICH_COLS)\n",
    "\n",
    "# Ensure columns exist (create with NaN if missing)\n",
    "for col in ENRICH_COLS:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "\n",
    "# Rows where ANY of these enrichment columns are missing\n",
    "missing_any = df[ENRICH_COLS].isna().any(axis=1)\n",
    "print(\"Rows with any missing enrich-col:\", int(missing_any.sum()))\n",
    "\n",
    "# Focus on recent seasons where the live boxscore API is most reliable\n",
    "if \"Season\" in df.columns:\n",
    "    # You can adjust this list as you like\n",
    "    recent_mask = df[\"Season\"].isin([\n",
    "        \"2020-21\", \"2021-22\", \"2022-23\", \"2023-24\", \"2025-26\"\n",
    "    ])\n",
    "else:\n",
    "    # Fallback if Season is missing ‚Äì limit by date\n",
    "    recent_mask = df[\"gameDate\"] >= pd.Timestamp(\"2020-01-01\")\n",
    "\n",
    "rows_to_enrich = df[missing_any & recent_mask].copy()\n",
    "\n",
    "print(\"Rows to enrich (recent seasons + missing cols):\", len(rows_to_enrich))\n",
    "print(\"Unique games to enrich:\", rows_to_enrich[\"gameId\"].nunique())\n",
    "\n",
    "display(\n",
    "    rows_to_enrich.head(10)[\n",
    "        [\"gameDate\", \"Season\", \"teamCity\", \"teamName\", \"gameId\"] + ENRICH_COLS\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021c205-40d1-4781-ada0-5dac91249183",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the LIVE boxscore endpoint (JSON) from nba_api\n",
    "\n",
    "from nba_api.live.nba.endpoints import boxscore as live_boxscore\n",
    "\n",
    "print(\"nba_api live imports OK\")\n",
    "\n",
    "def std_game_id(game_id_val) -> str:\n",
    "    \"\"\"\n",
    "    Normalize our stored gameId into a standard 10-char NBA GAME_ID string.\n",
    "    Example: 22000001 -> '0002200001'\n",
    "    \"\"\"\n",
    "    if pd.isna(game_id_val):\n",
    "        return None\n",
    "    try:\n",
    "        n = int(game_id_val)\n",
    "    except (ValueError, TypeError):\n",
    "        return str(game_id_val)\n",
    "    return str(n).zfill(10)\n",
    "\n",
    "\n",
    "def _team_record_from_live(game_dict: dict, which: str, gid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Helper: pull team-level stats from live boxscore 'homeTeam' or 'awayTeam'.\n",
    "    which must be 'homeTeam' or 'awayTeam'.\n",
    "    \"\"\"\n",
    "    team = game_dict.get(which, {})\n",
    "    stats = team.get(\"statistics\", {}) or {}\n",
    "\n",
    "    return {\n",
    "        \"gameId\": gid,\n",
    "        \"teamId\": team.get(\"teamId\"),\n",
    "        \"teamCity_live\": team.get(\"teamCity\"),\n",
    "        \"teamName_live\": team.get(\"teamName\"),\n",
    "        \"teamScore_live\": team.get(\"score\"),\n",
    "\n",
    "        # enrichment fields matching our ENRICH_COLS\n",
    "        \"pointsInThePaint\":    stats.get(\"pointsInThePaint\"),\n",
    "        \"benchPoints\":         stats.get(\"benchPoints\"),\n",
    "        \"pointsFastBreak\":     stats.get(\"pointsFastBreak\"),\n",
    "        \"pointsFromTurnovers\": stats.get(\"pointsFromTurnovers\"),\n",
    "        \"pointsSecondChance\":  stats.get(\"pointsSecondChance\"),\n",
    "        \"biggestLead\":         stats.get(\"biggestLead\"),\n",
    "        \"biggestScoringRun\":   stats.get(\"biggestScoringRun\"),\n",
    "        \"leadChanges\":         stats.get(\"leadChanges\"),\n",
    "        \"timesTied\":           stats.get(\"timesTied\"),\n",
    "        \"timeoutsRemaining\":   team.get(\"timeoutsRemaining\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_team_boxscore_for_game_live(game_id_val, sleep_sec: float = 0.4):\n",
    "    \"\"\"\n",
    "    Fetch team-level boxscore info for a single gameId using the live boxscore endpoint.\n",
    "\n",
    "    Returns: DataFrame with up to TWO rows (home + away team).\n",
    "             Columns match our enrichment schema above.\n",
    "\n",
    "    On failure: returns None.\n",
    "    \"\"\"\n",
    "    gid = std_game_id(game_id_val)\n",
    "    if gid is None:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        bs = live_boxscore.BoxScore(game_id=gid)\n",
    "        data = bs.get_dict()\n",
    "        game = data.get(\"game\", {})\n",
    "        if not game:\n",
    "            print(f\"‚ö†Ô∏è No 'game' payload for gameId={gid}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # Most common reasons: invalid gameId, preseason, or NBA endpoint issues\n",
    "        print(f\"‚ö†Ô∏è Live boxscore error for gameId={gid}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # polite pause to be nice to the API\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    records = []\n",
    "    for which in [\"homeTeam\", \"awayTeam\"]:\n",
    "        if which in game:\n",
    "            rec = _team_record_from_live(game, which, gid)\n",
    "            records.append(rec)\n",
    "\n",
    "    if not records:\n",
    "        return None\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f59beb-8f17-4756-b948-1382c69a8185",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build / update a cache of enriched team-level stats from live boxscore\n",
    "\n",
    "cache_path = raw_root / \"boxscore_enrichment_cache.csv\"\n",
    "\n",
    "# Load existing cache if present\n",
    "if cache_path.exists():\n",
    "    cache_df = pd.read_csv(cache_path, low_memory=False)\n",
    "    print(f\"Loaded existing enrichment cache: {cache_path}  (rows: {len(cache_df)})\")\n",
    "else:\n",
    "    cache_df = pd.DataFrame()\n",
    "    print(\"No existing cache found; starting fresh.\")\n",
    "\n",
    "# Make sure gameId in cache is string for consistent merging\n",
    "if \"gameId\" in cache_df.columns:\n",
    "    cache_df[\"gameId\"] = cache_df[\"gameId\"].astype(str)\n",
    "\n",
    "# GameIds we've already fetched\n",
    "fetched_game_ids = set(cache_df[\"gameId\"].unique()) if not cache_df.empty else set()\n",
    "\n",
    "# Distinct gameIds we want to enrich (from rows_to_enrich)\n",
    "games_list = sorted(rows_to_enrich[\"gameId\"].dropna().astype(str).unique())\n",
    "print(\"Total distinct gameIds to process:\", len(games_list))\n",
    "\n",
    "records = []\n",
    "\n",
    "for idx, gid in enumerate(games_list, start=1):\n",
    "    if gid in fetched_game_ids:\n",
    "        continue  # already cached\n",
    "\n",
    "    print(f\"[{idx}/{len(games_list)}] Fetching gameId={gid} ...\", end=\"\\r\")\n",
    "\n",
    "    df_bs = fetch_team_boxscore_for_game_live(gid, sleep_sec=0.4)\n",
    "    if df_bs is None:\n",
    "        continue\n",
    "\n",
    "    # Standardize dtypes\n",
    "    df_bs = df_bs.copy()\n",
    "    df_bs[\"gameId\"] = df_bs[\"gameId\"].astype(str)\n",
    "\n",
    "    # Collect records\n",
    "    records.extend(df_bs.to_dict(orient=\"records\"))\n",
    "\n",
    "    # Every 25 new games, flush to disk\n",
    "    if idx % 25 == 0:\n",
    "        tmp_df = pd.DataFrame(records)\n",
    "        cache_df = pd.concat([cache_df, tmp_df], ignore_index=True)\n",
    "        cache_df.drop_duplicates(subset=[\"gameId\", \"teamId\"], keep=\"last\", inplace=True)\n",
    "        cache_df.to_csv(cache_path, index=False)\n",
    "        print(f\"\\nFlushed cache at {idx} games ‚Üí {len(cache_df)} rows\")\n",
    "        records = []\n",
    "\n",
    "# Final flush\n",
    "if records:\n",
    "    tmp_df = pd.DataFrame(records)\n",
    "    cache_df = pd.concat([cache_df, tmp_df], ignore_index=True)\n",
    "    cache_df.drop_duplicates(subset=[\"gameId\", \"teamId\"], keep=\"last\", inplace=True)\n",
    "    cache_df.to_csv(cache_path, index=False)\n",
    "    print(f\"\\nFinal cache flush ‚Üí {len(cache_df)} rows\")\n",
    "\n",
    "print(\"Enrichment cache complete; rows:\", len(cache_df))\n",
    "display(cache_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3698b-e465-40ce-b81e-20392b3e520d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Merge cache_df back into df (all-seasons team logs)\n",
    "\n",
    "print(\"=== Merging enrichment into all-seasons table ===\")\n",
    "\n",
    "enrich_df = cache_df.copy()\n",
    "\n",
    "# Standardize merge keys as strings / Int64\n",
    "df[\"gameId\"] = df[\"gameId\"].astype(str)\n",
    "enrich_df[\"gameId\"] = enrich_df[\"gameId\"].astype(str)\n",
    "\n",
    "df[\"teamId\"] = pd.to_numeric(df[\"teamId\"], errors=\"coerce\").astype(\"Int64\")\n",
    "enrich_df[\"teamId\"] = pd.to_numeric(enrich_df[\"teamId\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "merged = df.copy()\n",
    "\n",
    "key_cols = [\"gameId\", \"teamId\"]\n",
    "\n",
    "for col in ENRICH_COLS:\n",
    "    print(f\"Updating column: {col}\")\n",
    "    # Series to align on key_cols\n",
    "    update_series = enrich_df.set_index(key_cols)[col]\n",
    "\n",
    "    temp = merged.set_index(key_cols)\n",
    "    before_missing = temp[col].isna().sum()\n",
    "\n",
    "    temp[col] = temp[col].where(~temp[col].isna(), update_series)\n",
    "    after_missing = temp[col].isna().sum()\n",
    "\n",
    "    print(f\"  Missing before: {before_missing}, after: {after_missing}\")\n",
    "\n",
    "    merged = temp.reset_index()\n",
    "\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "display(merged.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9bd76-1d24-4ba4-bfe2-72fbcad5c923",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "WRITE_CHANGES = False  # <-- set to True when you're ready to commit changes\n",
    "\n",
    "if WRITE_CHANGES:\n",
    "    backup_path = all_seasons_path.with_suffix(\".backup_before_enrichment.csv\")\n",
    "    print(f\"Backing up original all-seasons file to: {backup_path}\")\n",
    "    df.to_csv(backup_path, index=False)\n",
    "\n",
    "    print(f\"Writing enriched all-seasons file to: {all_seasons_path}\")\n",
    "    merged.to_csv(all_seasons_path, index=False)\n",
    "\n",
    "    # Quick verification\n",
    "    check = pd.read_csv(all_seasons_path, low_memory=False)\n",
    "    check[\"gameDate\"] = pd.to_datetime(check[\"gameDate\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
    "    print(\"New shape:\", check.shape)\n",
    "    print(\"New date range:\", check[\"gameDate\"].min(), \"‚Üí\", check[\"gameDate\"].max())\n",
    "    for col in ENRICH_COLS:\n",
    "        print(f\"{col}: missing {check[col].isna().sum()} rows\")\n",
    "else:\n",
    "    print(\"WRITE_CHANGES=False ‚Üí dry run only; no files written.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f53f4-504c-455c-bed8-36026dfe108b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ec8f2-f38e-4239-8e9e-5c03c84d651a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49123dea-665e-4fb6-b6a9-e9ac89811825",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d53608-84ae-4eff-82c8-d5d07f054836",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
