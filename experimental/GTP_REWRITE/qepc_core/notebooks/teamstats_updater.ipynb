{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43481515-3e5c-4e9d-96fb-9fda075b9dd0",
   "metadata": {},
   "source": [
    "# üßº QEPC ‚Äì Update Team_Stats.csv from nba_api\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads the existing `Team_Stats.csv` from `data/raw`.\n",
    "2. Detects the last game date currently stored.\n",
    "3. Uses `nba_api` to fetch NEW team game logs after that date.\n",
    "4. Maps them into the Team_Stats schema.\n",
    "5. Concatenates & de-duplicates.\n",
    "6. Optionally writes the updated file back to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c25171-f6e9-4456-be1b-7ff5b9208cf6",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== QEPC Experimental Bootstrap (Team_Stats updater) ===\")\n",
    "\n",
    "cwd = Path.cwd()\n",
    "core_root = None\n",
    "cur = cwd\n",
    "\n",
    "# Walk up until we find qepc_core\n",
    "for _ in range(8):\n",
    "    if cur.name == \"qepc_core\":\n",
    "        core_root = cur\n",
    "        break\n",
    "    if cur.parent == cur:\n",
    "        break\n",
    "    cur = cur.parent\n",
    "\n",
    "if core_root is None:\n",
    "    raise RuntimeError(f\"Could not find qepc_core above {cwd}\")\n",
    "\n",
    "core_str = str(core_root)\n",
    "if core_str not in sys.path:\n",
    "    sys.path.insert(0, core_str)\n",
    "\n",
    "# Repo root is 3 levels up: .../qepc_project/experimental/GTP_REWRITE/qepc_core\n",
    "repo_root = core_root.parent.parent.parent\n",
    "repo_str = str(repo_root)\n",
    "if repo_str not in sys.path:\n",
    "    sys.path.append(repo_str)\n",
    "\n",
    "print(\"qepc_core root:\", core_root)\n",
    "print(\"repo root:     \", repo_root)\n",
    "\n",
    "import qepc\n",
    "from qepc.config import detect_project_root, QEPCConfig\n",
    "\n",
    "project_root = detect_project_root()\n",
    "cfg = QEPCConfig.from_project_root(project_root)\n",
    "\n",
    "print(\"project_root:  \", project_root)\n",
    "print(\"data/raw:      \", cfg.raw_root)\n",
    "print(\"=== Bootstrap OK ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be9fd4-449b-4a3b-b0a9-60cd3ac2526e",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "team_stats_path = cfg.raw_root / \"Team_Stats.csv\"\n",
    "print(\"Team_Stats path:\", team_stats_path)\n",
    "\n",
    "team_stats = pd.read_csv(team_stats_path)\n",
    "\n",
    "# Keep original string as backup (optional)\n",
    "team_stats[\"gameDate_raw\"] = team_stats[\"gameDate\"]\n",
    "\n",
    "# Robust datetime parse: force UTC, then drop tz info\n",
    "team_stats[\"gameDate\"] = pd.to_datetime(\n",
    "    team_stats[\"gameDate\"],\n",
    "    errors=\"coerce\",\n",
    "    utc=True,\n",
    ")\n",
    "\n",
    "# Convert to naive datetime (no timezone)\n",
    "team_stats[\"gameDate\"] = team_stats[\"gameDate\"].dt.tz_convert(None)\n",
    "\n",
    "# Filter to valid dates only\n",
    "valid_mask = team_stats[\"gameDate\"].notna()\n",
    "invalid_count = (~valid_mask).sum()\n",
    "\n",
    "print(\"Existing Team_Stats shape:\", team_stats.shape)\n",
    "print(\"Columns:\", list(team_stats.columns))\n",
    "\n",
    "if invalid_count > 0:\n",
    "    print(f\"‚ö†Ô∏è Dropping {invalid_count} rows with invalid gameDate\")\n",
    "    team_stats = team_stats[valid_mask].copy()\n",
    "\n",
    "min_date = team_stats[\"gameDate\"].min()\n",
    "max_date = team_stats[\"gameDate\"].max()\n",
    "\n",
    "print(f\"Date range in Team_Stats: {min_date} ‚Üí {max_date}\")\n",
    "\n",
    "# We'll fetch NEW games after this date\n",
    "last_date = max_date.date()\n",
    "date_from_for_api = (last_date + timedelta(days=1)).strftime(\"%m/%d/%Y\")\n",
    "\n",
    "print(f\"\\nLast recorded gameDate: {last_date}\")\n",
    "print(f\"We will request nba_api games from: {date_from_for_api} onward\")\n",
    "\n",
    "display(team_stats.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d9afb-e7b3-44e0-bde1-a11be6ecd53f",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.static import teams as nba_teams\n",
    "\n",
    "print(\"=== Fetching new games from nba_api ===\")\n",
    "\n",
    "# Get all NBA teams metadata for city/nickname mapping\n",
    "teams_meta = nba_teams.get_teams()\n",
    "teams_by_id = {t[\"id\"]: t for t in teams_meta}\n",
    "teams_by_abbrev = {t[\"abbreviation\"]: t for t in teams_meta}\n",
    "\n",
    "print(\"Loaded team metadata for\", len(teams_meta), \"teams\")\n",
    "\n",
    "# Call leaguegamefinder for Regular Season, all teams, games after date_from_for_api\n",
    "lgf = leaguegamefinder.LeagueGameFinder(\n",
    "    league_id_nullable=\"00\",\n",
    "    season_type_nullable=\"Regular Season\",\n",
    "    date_from_nullable=date_from_for_api,  # e.g. \"11/18/2025\"\n",
    ")\n",
    "\n",
    "df_new_raw = lgf.get_data_frames()[0]\n",
    "print(\"Raw nba_api new logs shape:\", df_new_raw.shape)\n",
    "\n",
    "if df_new_raw.empty:\n",
    "    print(\"‚úÖ No new games found after\", date_from_for_api)\n",
    "else:\n",
    "    print(\"Columns from nba_api:\", list(df_new_raw.columns))\n",
    "    display(df_new_raw.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be4a11-7cd1-445f-8658-ef527dab7bd0",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if df_new_raw.empty:\n",
    "    new_team_stats = pd.DataFrame(columns=team_stats.columns)\n",
    "    print(\"No new games to map; skipping mapping step.\")\n",
    "else:\n",
    "    df = df_new_raw.copy()\n",
    "\n",
    "    # Standardize datetime\n",
    "    df[\"gameDate\"] = pd.to_datetime(df[\"GAME_DATE\"], errors=\"coerce\")\n",
    "\n",
    "    # Basic stats mapping\n",
    "    df[\"teamScore\"] = df[\"PTS\"]\n",
    "    df[\"reboundsTotal\"] = df[\"REB\"]\n",
    "    df[\"assists\"] = df[\"AST\"]\n",
    "    df[\"threePointersMade\"] = df[\"FG3M\"]\n",
    "    df[\"threePointersAttempted\"] = df[\"FG3A\"]\n",
    "    df[\"blocks\"] = df[\"BLK\"]\n",
    "    df[\"steals\"] = df[\"STL\"]\n",
    "    df[\"fieldGoalsAttempted\"] = df[\"FGA\"]\n",
    "    df[\"fieldGoalsMade\"] = df[\"FGM\"]\n",
    "    df[\"fieldGoalsPercentage\"] = df[\"FG_PCT\"]\n",
    "    df[\"threePointersPercentage\"] = df[\"FG3_PCT\"]\n",
    "    df[\"freeThrowsAttempted\"] = df[\"FTA\"]\n",
    "    df[\"freeThrowsMade\"] = df[\"FTM\"]\n",
    "    df[\"freeThrowsPercentage\"] = df[\"FT_PCT\"]\n",
    "    df[\"reboundsDefensive\"] = df[\"DREB\"]\n",
    "    df[\"reboundsOffensive\"] = df[\"OREB\"]\n",
    "    df[\"foulsPersonal\"] = df[\"PF\"]\n",
    "    df[\"turnovers\"] = df[\"TOV\"]\n",
    "    df[\"plusMinusPoints\"] = df[\"PLUS_MINUS\"]\n",
    "    df[\"numMinutes\"] = df[\"MIN\"]\n",
    "\n",
    "    # Team identity from teams metadata\n",
    "    def map_team_city(row):\n",
    "        meta = teams_by_id.get(row[\"TEAM_ID\"])\n",
    "        return meta[\"city\"] if meta else row[\"TEAM_NAME\"]\n",
    "\n",
    "    def map_team_nickname(row):\n",
    "        meta = teams_by_id.get(row[\"TEAM_ID\"])\n",
    "        return meta[\"nickname\"] if meta else row[\"TEAM_NAME\"]\n",
    "\n",
    "    def map_team_abbrev(row):\n",
    "        meta = teams_by_id.get(row[\"TEAM_ID\"])\n",
    "        return meta[\"abbreviation\"] if meta else row[\"TEAM_ABBREVIATION\"]\n",
    "\n",
    "    df[\"teamCity\"] = df.apply(map_team_city, axis=1)\n",
    "    df[\"teamName\"] = df.apply(map_team_nickname, axis=1)\n",
    "    df[\"teamCity_hist\"] = df[\"teamCity\"]\n",
    "    df[\"teamName_hist\"] = df[\"teamName\"]\n",
    "    df[\"teamAbbrev_hist\"] = df.apply(map_team_abbrev, axis=1)\n",
    "\n",
    "    df[\"teamId\"] = df[\"TEAM_ID\"]\n",
    "    df[\"gameId\"] = df[\"GAME_ID\"]\n",
    "    df[\"league\"] = \"NBA\"\n",
    "\n",
    "    # Home/away and opponent info from MATCHUP\n",
    "    def parse_matchup(row):\n",
    "        matchup = row[\"MATCHUP\"]\n",
    "        # examples: \"DEN vs. CHI\", \"DEN @ CHI\"\n",
    "        if \" vs. \" in matchup:\n",
    "            team_abbr, opp_abbr = matchup.split(\" vs. \")\n",
    "            home = 1\n",
    "        elif \" @ \" in matchup:\n",
    "            team_abbr, opp_abbr = matchup.split(\" @ \")\n",
    "            home = 0\n",
    "        else:\n",
    "            # fallback\n",
    "            parts = matchup.split(\" \")\n",
    "            team_abbr = parts[0]\n",
    "            opp_abbr = parts[-1]\n",
    "            home = 0\n",
    "        team_abbr = team_abbr.strip()\n",
    "        opp_abbr = opp_abbr.strip()\n",
    "        return team_abbr, opp_abbr, home\n",
    "\n",
    "    parsed = df.apply(parse_matchup, axis=1, result_type=\"expand\")\n",
    "    df[\"TEAM_ABBR_FROM_MATCHUP\"] = parsed[0]\n",
    "    df[\"OPP_ABBR\"] = parsed[1]\n",
    "    df[\"home\"] = parsed[2].astype(int)\n",
    "\n",
    "    # Sanity check: sometimes TEAM_ABBREVIATION already matches\n",
    "    # Opponent meta\n",
    "    def map_opp_city(row):\n",
    "        meta = teams_by_abbrev.get(row[\"OPP_ABBR\"])\n",
    "        return meta[\"city\"] if meta else np.nan\n",
    "\n",
    "    def map_opp_nickname(row):\n",
    "        meta = teams_by_abbrev.get(row[\"OPP_ABBR\"])\n",
    "        return meta[\"nickname\"] if meta else row[\"OPP_ABBR\"]\n",
    "\n",
    "    def map_opp_id(row):\n",
    "        meta = teams_by_abbrev.get(row[\"OPP_ABBR\"])\n",
    "        return meta[\"id\"] if meta else np.nan\n",
    "\n",
    "    df[\"opponentTeamCity\"] = df.apply(map_opp_city, axis=1)\n",
    "    df[\"opponentTeamName\"] = df.apply(map_opp_nickname, axis=1)\n",
    "    df[\"opponentTeamId\"] = df.apply(map_opp_id, axis=1)\n",
    "\n",
    "    # Win / loss flag\n",
    "    df[\"win\"] = (df[\"WL\"] == \"W\").astype(int)\n",
    "\n",
    "    # Season label\n",
    "    # leaguegamefinder SEASON_ID like \"2025-26\"\n",
    "    if \"SEASON_ID\" in df.columns:\n",
    "        df[\"season\"] = df[\"SEASON_ID\"].str.extract(r\"(\\d{4})\").astype(float)\n",
    "    else:\n",
    "        df[\"season\"] = df[\"gameDate\"].dt.year  # fallback\n",
    "\n",
    "    # Dummy / unavailable fields\n",
    "    for col in [\n",
    "        \"pointsInThePaint\",\n",
    "        \"benchPoints\",\n",
    "        \"q1Points\",\n",
    "        \"q2Points\",\n",
    "        \"q3Points\",\n",
    "        \"q4Points\",\n",
    "        \"biggestLead\",\n",
    "        \"biggestScoringRun\",\n",
    "        \"leadChanges\",\n",
    "        \"pointsFastBreak\",\n",
    "        \"pointsFromTurnovers\",\n",
    "        \"pointsSecondChance\",\n",
    "        \"timesTied\",\n",
    "        \"timeoutsRemaining\",\n",
    "        \"coachId\",\n",
    "    ]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # Season wins/losses (approximate record *before* each game)\n",
    "    df = df.sort_values([\"TEAM_ID\", \"gameDate\"]).reset_index(drop=True)\n",
    "    df[\"is_win\"] = (df[\"WL\"] == \"W\").astype(int)\n",
    "\n",
    "    def add_record(g):\n",
    "        g = g.sort_values(\"gameDate\")\n",
    "        g[\"wins_so_far\"] = g[\"is_win\"].shift(1).fillna(0).cumsum()\n",
    "        g[\"games_so_far\"] = np.arange(len(g))\n",
    "        g[\"losses_so_far\"] = g[\"games_so_far\"] - g[\"wins_so_far\"]\n",
    "        return g\n",
    "\n",
    "    df = df.groupby(\"TEAM_ID\", group_keys=False).apply(add_record)\n",
    "    df[\"seasonWins\"] = df[\"wins_so_far\"]\n",
    "    df[\"seasonLosses\"] = df[\"losses_so_far\"]\n",
    "\n",
    "    # For now, opponentScore is not provided directly; set to NaN.\n",
    "    # (You already have a repair function in strengths to fix from pairs if needed.)\n",
    "    df[\"opponentScore\"] = np.nan\n",
    "\n",
    "    # Map to final Team_Stats column order: align to existing file\n",
    "    new_team_stats = df.copy()\n",
    "\n",
    "    # Ensure all existing columns are present\n",
    "    for col in team_stats.columns:\n",
    "        if col not in new_team_stats.columns:\n",
    "            new_team_stats[col] = np.nan\n",
    "\n",
    "    # Keep only columns that exist in Team_Stats, and in the same order\n",
    "    new_team_stats = new_team_stats[team_stats.columns]\n",
    "\n",
    "    print(\"Mapped new_team_stats shape:\", new_team_stats.shape)\n",
    "    display(new_team_stats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474947b-b03d-4ac7-829e-27055b7c60d0",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Existing Team_Stats rows:\", len(team_stats))\n",
    "print(\"New rows from nba_api:\", len(new_team_stats))\n",
    "\n",
    "# If no new games, just keep the original\n",
    "if new_team_stats.empty:\n",
    "    updated_team_stats = team_stats.copy()\n",
    "else:\n",
    "    combined = pd.concat([team_stats, new_team_stats], ignore_index=True)\n",
    "\n",
    "    # De-duplicate by (gameId, teamId) pair, keeping the first (existing) row\n",
    "    if {\"gameId\", \"teamId\"}.issubset(combined.columns):\n",
    "        before = len(combined)\n",
    "        combined = combined.drop_duplicates(subset=[\"gameId\", \"teamId\"], keep=\"first\")\n",
    "        after = len(combined)\n",
    "        print(f\"De-duplicated by (gameId, teamId): {before} ‚Üí {after} rows\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Missing 'gameId' or 'teamId' columns; skipping de-duplication by key\")\n",
    "\n",
    "    updated_team_stats = combined\n",
    "\n",
    "print(\"Final updated_team_stats rows:\", len(updated_team_stats))\n",
    "display(updated_team_stats.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91b2bd-c6ea-4b61-86b3-2146d22e53f7",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WRITE_CHANGES = True  # make sure this is True before running this cell\n",
    "\n",
    "if WRITE_CHANGES:\n",
    "    backup_path = team_stats_path.with_suffix(\".backup_before_update.csv\")\n",
    "    print(f\"Writing backup to: {backup_path}\")\n",
    "    team_stats.to_csv(backup_path, index=False)\n",
    "\n",
    "    print(f\"Writing updated Team_Stats to: {team_stats_path}\")\n",
    "    updated_team_stats.to_csv(team_stats_path, index=False)\n",
    "\n",
    "    print(\"‚úÖ Done writing. Re-reading file from disk to verify...\")\n",
    "\n",
    "    ts_disk2 = pd.read_csv(team_stats_path)\n",
    "    ts_disk2[\"gameDate\"] = pd.to_datetime(ts_disk2[\"gameDate\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
    "    print(\"On-disk shape (after write):\", ts_disk2.shape)\n",
    "    print(\"On-disk date range (after write):\", ts_disk2[\"gameDate\"].min(), \"‚Üí\", ts_disk2[\"gameDate\"].max())\n",
    "    display(ts_disk2.tail())\n",
    "else:\n",
    "    print(\"WRITE_CHANGES is False ‚Äì not writing anything to disk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a783e-8900-43d6-9379-689213fac10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
