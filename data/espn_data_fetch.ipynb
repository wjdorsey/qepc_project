{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664c2e24-0058-4656-ab38-b19d0530d2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH now includes: C:\\Users\\wdors\\qepc_project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Point this at your QEPC project folder\n",
    "project_root = Path(r\"C:\\Users\\wdors\\qepc_project\")\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"PYTHONPATH now includes:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5bb89c2-73ff-48be-b0e5-0da3af62ca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching injuries for ATL...\n",
      "Fetching injuries for BOS...\n",
      "Fetching injuries for BKN...\n",
      "Fetching injuries for CHA...\n",
      "Fetching injuries for CHI...\n",
      "Fetching injuries for CLE...\n",
      "Fetching injuries for DAL...\n",
      "Fetching injuries for DEN...\n",
      "Fetching injuries for DET...\n",
      "Fetching injuries for GS...\n",
      "Fetching injuries for HOU...\n",
      "Fetching injuries for IND...\n",
      "Fetching injuries for LAC...\n",
      "Fetching injuries for LAL...\n",
      "Fetching injuries for MEM...\n",
      "Fetching injuries for MIA...\n",
      "Fetching injuries for MIL...\n",
      "Fetching injuries for MIN...\n",
      "Fetching injuries for NO...\n",
      "Fetching injuries for NY...\n",
      "Fetching injuries for OKC...\n",
      "Fetching injuries for ORL...\n",
      "Fetching injuries for PHI...\n",
      "Fetching injuries for PHX...\n",
      "Fetching injuries for POR...\n",
      "Fetching injuries for SAC...\n",
      "Fetching injuries for SA...\n",
      "Fetching injuries for TOR...\n",
      "Fetching injuries for UTA...\n",
      "  Error fetching UTA: 400 Client Error: Bad Request for url: https://site.api.espn.com/apis/site/v2/sports/basketball/nba/injuries?team=UTA\n",
      "Fetching injuries for WAS...\n",
      "\n",
      "Saved 0 injury rows to C:\\Users\\wdors\\qepc_project\\data\\data\\Injury_Overrides_espn.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_URL = \"https://site.api.espn.com/apis/site/v2/sports/basketball/nba/injuries\"\n",
    "\n",
    "# Basic list of team codes; we can refine later\n",
    "TEAM_CODES = [\n",
    "    \"ATL\", \"BOS\", \"BKN\", \"CHA\", \"CHI\", \"CLE\", \"DAL\", \"DEN\", \"DET\", \"GS\",\n",
    "    \"HOU\", \"IND\", \"LAC\", \"LAL\", \"MEM\", \"MIA\", \"MIL\", \"MIN\", \"NO\", \"NY\",\n",
    "    \"OKC\", \"ORL\", \"PHI\", \"PHX\", \"POR\", \"SAC\", \"SA\", \"TOR\", \"UTA\", \"WAS\",\n",
    "]\n",
    "\n",
    "def fetch_team_injuries(team_code):\n",
    "    \"\"\"Fetch injury info for a single NBA team from ESPN.\"\"\"\n",
    "    resp = requests.get(BASE_URL, params={\"team\": team_code}, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # ESPN's structure: leagues -> teams -> injuries\n",
    "    for league in data.get(\"leagues\", []):\n",
    "        for team_block in league.get(\"teams\", []):\n",
    "            team_info = team_block.get(\"team\", {})\n",
    "            team_name = team_info.get(\"displayName\") or team_info.get(\"name\") or team_code\n",
    "\n",
    "            for inj in team_block.get(\"injuries\", []):\n",
    "                athlete = inj.get(\"athlete\", {})\n",
    "                status = inj.get(\"status\", {})\n",
    "\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"TeamCode\": team_code,\n",
    "                        \"Team\": team_name,\n",
    "                        \"PlayerName\": athlete.get(\"displayName\"),\n",
    "                        \"Position\": (athlete.get(\"position\") or {}).get(\"abbreviation\"),\n",
    "                        \"StatusShort\": (status.get(\"type\") or {}).get(\"name\"),\n",
    "                        \"StatusDetail\": status.get(\"detail\"),\n",
    "                        \"ESPNStatus\": (status.get(\"type\") or {}).get(\"description\"),\n",
    "                    }\n",
    "                )\n",
    "    return rows\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for code in TEAM_CODES:\n",
    "    print(f\"Fetching injuries for {code}...\")\n",
    "    try:\n",
    "        rows = fetch_team_injuries(code)\n",
    "        all_rows.extend(rows)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching {code}: {e}\")\n",
    "    time.sleep(0.3)  # polite delay\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Save into your project's data folder\n",
    "project_root = Path.cwd()  # assuming you're running this from qepc_project root\n",
    "out_path = project_root / \"data\" / \"Injury_Overrides_espn.csv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved {len(df)} injury rows to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1224e-c28d-4632-aa11-afff739aefe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888158ab-a772-4814-a7f1-40f6f11f72e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QEPC Paths] Project Root set: C:\\Users\\wdors\\qepc_project\n",
      "[QEPC Strength V2] Starting Advanced Calculation (Cutoff: Now)...\n",
      "[QEPC PlayerData] Successfully loaded 1635462 rows from PlayerStatistics.csv.\n",
      "[QEPC Opponent Processor] Loading raw team data for Weighted DRtg...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqepc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msports\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrengths_v2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m calculate_advanced_strengths\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 1) Build your base team strengths\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m advanced_strengths \u001b[38;5;241m=\u001b[39m calculate_advanced_strengths()\n\u001b[0;32m      7\u001b[0m advanced_team_strengths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      8\u001b[0m     advanced_strengths\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m\"\u001b[39m, as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 2) Load ESPN injury CSV that you generated locally\u001b[39;00m\n",
      "File \u001b[1;32m~\\qepc_project\\qepc\\sports\\nba\\strengths_v2.py:104\u001b[0m, in \u001b[0;36mcalculate_advanced_strengths\u001b[1;34m(cutoff_date, verbose)\u001b[0m\n\u001b[0;32m    101\u001b[0m df_ortg \u001b[38;5;241m=\u001b[39m team_stats[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORtg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolatility\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# --- PART 2: MERGE WITH DEFENSE ---\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m df_drtg \u001b[38;5;241m=\u001b[39m load_and_process_opponent_data()\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_drtg\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    107\u001b[0m     LA_ORtg \u001b[38;5;241m=\u001b[39m df_ortg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORtg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\qepc_project\\qepc\\sports\\nba\\opponent_data.py:57\u001b[0m, in \u001b[0;36mload_and_process_opponent_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(raw_path)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# 1. Standardization\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteamName\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeamName\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopponentTeamName\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpponentName\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgameDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgameDate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     71\u001b[0m     })\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:376\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m    374\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m union_categoricals(arrs, sort_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m concat_compat(arrs)\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_cat_dtypes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result[name]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m    378\u001b[0m         warning_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(name))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\concat.py:126\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    115\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    116\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of array concatenation with empty entries is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated. In a future version, this will no longer exclude \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    123\u001b[0m         )\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [astype_array(arr, target_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m to_concat]\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_concat[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# i.e. isinstance(to_concat[0], ExtensionArray)\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:135\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from qepc.sports.nba.strengths_v2 import calculate_advanced_strengths\n",
    "\n",
    "# 1) Build your base team strengths\n",
    "advanced_strengths = calculate_advanced_strengths()\n",
    "advanced_team_strengths = (\n",
    "    advanced_strengths\n",
    "    .groupby(\"Team\", as_index=False)\n",
    "    .mean(numeric_only=True)\n",
    ")\n",
    "\n",
    "# 2) Load ESPN injury CSV that you generated locally\n",
    "project_root = Path.cwd()\n",
    "inj_path = project_root / \"data\" / \"Injury_Overrides_espn.csv\"\n",
    "injuries = pd.read_csv(inj_path)\n",
    "\n",
    "injuries.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265e7a7-7d02-48a3-ae1a-acb59eb6c930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
