{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759d4938",
   "metadata": {},
   "source": [
    "# üèÄ QEPC Player Props Backtest\n",
    "\n",
    "This notebook backtests player prop predictions against historical results.\n",
    "\n",
    "## Features\n",
    "- **Time-travel backtesting** - No lookahead bias\n",
    "- **Multiple metrics** - Accuracy, Brier score, calibration\n",
    "- **Confidence levels** - HIGH/MEDIUM/LOW predictions\n",
    "- **Edge analysis** - Find betting opportunities\n",
    "\n",
    "## Requirements\n",
    "- `PlayerStatistics.csv` in `data/raw/` folder\n",
    "- `player_props_engine.py` and `props_backtest_engine.py` in same folder or `props/` subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac94e05-cd0a-4724-b041-ce4c1e8ea7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Import error: No module named 'props'\n",
      "Make sure:\n",
      "  ‚Ä¢ Your notebook kernel started from the qepc_project root, OR\n",
      "  ‚Ä¢ qepc_project is on sys.path via your QEPC bootstrap.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'props'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Imports from props package\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplayer_props_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PlayerPropsEngine, PropPrediction\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprops_backtest_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PropsBacktestEngine, BacktestSummary\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Props engines loaded successfully from props/ package!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'props'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "QEPC Player Props Backtest Notebook (Clean Version)\n",
    "\n",
    "Run this inside your qepc_project environment.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Imports from props package\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    from props.player_props_engine import PlayerPropsEngine, PropPrediction\n",
    "    from props.props_backtest_engine import PropsBacktestEngine, BacktestSummary\n",
    "    print(\"‚úÖ Props engines loaded successfully from props/ package!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Make sure:\")\n",
    "    print(\"  ‚Ä¢ Your notebook kernel started from the qepc_project root, OR\")\n",
    "    print(\"  ‚Ä¢ qepc_project is on sys.path via your QEPC bootstrap.\")\n",
    "    raise\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Let the engines auto-detect data/raw/PlayerStatistics.csv\n",
    "DATA_PATH = None\n",
    "\n",
    "BACKTEST_START = \"2024-11-01\"\n",
    "BACKTEST_END   = \"2024-11-15\"\n",
    "\n",
    "PROPS_TO_TEST = ['PTS', 'REB', 'AST', '3PM', 'PRA']\n",
    "MIN_MINUTES   = 15.0\n",
    "\n",
    "print(f\"\\nüìä Configuration:\")\n",
    "print(f\"   Data path override: {DATA_PATH!r} (None = auto-detect)\")\n",
    "print(f\"   Date Range: {BACKTEST_START} ‚Üí {BACKTEST_END}\")\n",
    "print(f\"   Props: {PROPS_TO_TEST}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Quick Test ‚Äì Single Player\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üß™ QUICK TEST: Single Player Prediction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize engine\n",
    "engine = PlayerPropsEngine(DATA_PATH)  # or PlayerPropsEngine() with no args\n",
    "engine.load_data()\n",
    "\n",
    "# Choose a player that you know exists in PlayerStatistics.csv\n",
    "test_player = \"LeBron James\"  # adjust as needed\n",
    "test_opponent = \"Golden State Warriors\"  # match opponentteamName in your data\n",
    "\n",
    "print(f\"\\nüìà Predictions for {test_player}:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for prop in ['PTS', 'REB', 'AST', 'PRA']:\n",
    "    pred = engine.predict(\n",
    "        player_name=test_player,\n",
    "        prop_type=prop,\n",
    "        opponent=test_opponent,\n",
    "        is_home=True,\n",
    "    )\n",
    "\n",
    "    if pred:\n",
    "        print(f\"\\n{prop}:\")\n",
    "        print(f\"  Projection: {pred.projection:.2f}\")\n",
    "        print(f\"  Range: {pred.floor:.1f} ‚Äì {pred.ceiling:.1f}\")\n",
    "        print(f\"  Confidence: {pred.confidence}\")\n",
    "        if prop == \"PTS\":\n",
    "            print(f\"  Over 25.5: {pred.over_prob(25.5):.1%}\")\n",
    "    else:\n",
    "        print(f\"\\n{prop}: Player not found or insufficient data.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Full Backtest\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üöÄ RUNNING FULL BACKTEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "backtest = PropsBacktestEngine(DATA_PATH)\n",
    "\n",
    "results = backtest.run_backtest(\n",
    "    start_date=BACKTEST_START,\n",
    "    end_date=BACKTEST_END,\n",
    "    props=PROPS_TO_TEST,\n",
    "    min_minutes=MIN_MINUTES,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Backtest complete: {len(results)} predictions generated\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Summary\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä BACKTEST SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if results:\n",
    "    summary = backtest.get_summary()\n",
    "    print(f\"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ           OVERALL PERFORMANCE               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Total Predictions:    {summary.total_predictions:>6}              ‚îÇ\n",
    "‚îÇ  Mean Absolute Error:  {summary.mean_absolute_error:>6.2f} pts     ‚îÇ\n",
    "‚îÇ  Median Abs Error:     {summary.median_absolute_error:>6.2f} pts   ‚îÇ\n",
    "‚îÇ  Mean % Error:         {summary.mean_pct_error*100:>6.1f}%         ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ           DIRECTIONAL ACCURACY              ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Overall Accuracy:     {summary.overall_accuracy*100:>6.1f}%       ‚îÇ\n",
    "‚îÇ  Over Accuracy:        {summary.over_accuracy*100:>6.1f}%          ‚îÇ\n",
    "‚îÇ  Under Accuracy:       {summary.under_accuracy*100:>6.1f}%         ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ           CALIBRATION                       ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Brier Score:          {summary.brier_score:>6.4f}                 ‚îÇ\n",
    "‚îÇ  (Lower is better, 0.25 = random)           ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ           BY CONFIDENCE                     ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  HIGH Confidence:      {summary.high_conf_accuracy*100:>6.1f}%     ‚îÇ\n",
    "‚îÇ  MEDIUM Confidence:    {summary.medium_conf_accuracy*100:>6.1f}%   ‚îÇ\n",
    "‚îÇ  LOW Confidence:       {summary.low_conf_accuracy*100:>6.1f}%      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ           SIMULATED BETTING                 ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  Bets Placed:          {summary.simulated_bets:>6}                 ‚îÇ\n",
    "‚îÇ  Bets Won:             {summary.simulated_wins:>6}                 ‚îÇ\n",
    "‚îÇ  ROI:                  {summary.simulated_roi*100:>6.1f}%          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"‚ùå No results to summarize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0566e-d779-4b7f-9237-12c5898d7dee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265f256",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add props folder to path\n",
    "for folder in [Path.cwd(), Path.cwd() / \"props\", Path.cwd().parent]:\n",
    "    if (folder / \"player_props_engine.py\").exists():\n",
    "        sys.path.insert(0, str(folder))\n",
    "        break\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Import engines\n",
    "from player_props_engine import PlayerPropsEngine, PropPrediction\n",
    "from props_backtest_engine import PropsBacktestEngine\n",
    "\n",
    "print(\"‚úÖ Props engines loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecee0b-5bb1-4f96-b63c-110e0850a5b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç Locating QEPC project root...\\n\")\n",
    "\n",
    "# Try direct import first\n",
    "try:\n",
    "    from notebook_context import *\n",
    "    print(\"‚úÖ Imported notebook_context directly\")\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ÑπÔ∏è  notebook_context not on path, searching...\")\n",
    "    \n",
    "    # Search current directory and parents\n",
    "    cwd = Path.cwd()\n",
    "    candidates = [cwd, cwd.parent, cwd.parent.parent]\n",
    "    \n",
    "    found_root = None\n",
    "    for root in candidates:\n",
    "        if (root / \"notebook_context.py\").exists():\n",
    "            found_root = root\n",
    "            print(f\"   Found at: {root}\")\n",
    "            break\n",
    "    \n",
    "    if found_root is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"‚ùå Could not find notebook_context.py\\n\"\n",
    "            f\"   Searched: {cwd} and parent directories\\n\"\n",
    "            f\"   Ensure you're in the qepc_project folder\"\n",
    "        )\n",
    "    \n",
    "    # Add to path and re-import\n",
    "    sys.path.insert(0, str(found_root))\n",
    "    os.chdir(found_root)\n",
    "    \n",
    "    from notebook_context import *\n",
    "    print(\"‚úÖ Imported after path adjustment\")\n",
    "\n",
    "# Verify project_root is defined\n",
    "try:\n",
    "    project_root\n",
    "except NameError:\n",
    "    project_root = Path.cwd()\n",
    "    print(\"‚ö†Ô∏è  project_root not defined, using CWD\")\n",
    "\n",
    "print(f\"\\nüìÅ Project Root: {project_root}\")\n",
    "print(f\"üìÇ Working Dir:  {os.getcwd()}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data/raw/PlayerStatistics.csv\"\n",
    "\n",
    "# Backtest date range - EDIT THESE\n",
    "BACKTEST_START = \"2024-11-01\"\n",
    "BACKTEST_END = \"2024-11-15\"\n",
    "\n",
    "# Props to test\n",
    "PROPS_TO_TEST = ['PTS', 'REB', 'AST', '3PM', 'PRA']\n",
    "\n",
    "print(f\"üìä Date Range: {BACKTEST_START} ‚Üí {BACKTEST_END}\")\n",
    "print(f\"üìä Props: {PROPS_TO_TEST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee1067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1) Import from your props package\n",
    "from props.player_props_engine import PlayerPropsEngine, PropsConfig\n",
    "\n",
    "# 2) Point to your data folder (adjust if yours is different)\n",
    "DATA_PATH = Path(\"data\")\n",
    "\n",
    "# 3) Initialize and load\n",
    "engine = PlayerPropsEngine(DATA_PATH)\n",
    "engine.load_data()\n",
    "\n",
    "# 4) Simple test prediction\n",
    "player_name = \"Jayson Tatum\"\n",
    "prop_type = \"PTS\"\n",
    "opponent = \"Los Angeles Lakers\"  # must match opponentteamName in PlayerStatistics\n",
    "\n",
    "prediction = engine.predict(\n",
    "    player_name=player_name,\n",
    "    prop_type=prop_type,\n",
    "    opponent=opponent,\n",
    "    is_home=True,\n",
    ")\n",
    "\n",
    "print(prediction)\n",
    "if prediction is not None:\n",
    "    print(\"Projection:\", prediction.projection)\n",
    "    print(\"Std dev:   \", prediction.std_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Full Backtest\n",
    "print(\"üöÄ Running backtest...\")\n",
    "\n",
    "backtest = PropsBacktestEngine(DATA_PATH)\n",
    "results = backtest.run_backtest(\n",
    "    start_date=BACKTEST_START,\n",
    "    end_date=BACKTEST_END,\n",
    "    props=PROPS_TO_TEST,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Complete: {len(results)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fa5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest Summary\n",
    "summary = backtest.get_summary()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"üìä BACKTEST SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Predictions: {summary.total_predictions}\")\n",
    "print(f\"\\n--- Accuracy ---\")\n",
    "print(f\"Overall Accuracy:  {summary.overall_accuracy:.1%}\")\n",
    "print(f\"Over Accuracy:     {summary.over_accuracy:.1%}\")\n",
    "print(f\"Under Accuracy:    {summary.under_accuracy:.1%}\")\n",
    "print(f\"\\n--- Error ---\")\n",
    "print(f\"Mean Abs Error:    {summary.mean_absolute_error:.2f} pts\")\n",
    "print(f\"Median Abs Error:  {summary.median_absolute_error:.2f} pts\")\n",
    "print(f\"\\n--- Calibration ---\")\n",
    "print(f\"Brier Score:       {summary.brier_score:.4f}\")\n",
    "print(f\"(0.25 = random, lower is better)\")\n",
    "print(f\"\\n--- By Confidence ---\")\n",
    "print(f\"HIGH:   {summary.high_conf_accuracy:.1%}\")\n",
    "print(f\"MEDIUM: {summary.medium_conf_accuracy:.1%}\")\n",
    "print(f\"LOW:    {summary.low_conf_accuracy:.1%}\")\n",
    "print(f\"\\n--- Simulated Betting ---\")\n",
    "print(f\"Bets: {summary.simulated_bets}, Wins: {summary.simulated_wins}\")\n",
    "print(f\"ROI: {summary.simulated_roi:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown by Prop Type\n",
    "prop_breakdown = backtest.breakdown_by_prop()\n",
    "print(\"\\nüìà BREAKDOWN BY PROP TYPE\")\n",
    "print(\"=\" * 50)\n",
    "display(prop_breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Results\n",
    "df_results = backtest.results_to_dataframe()\n",
    "\n",
    "print(f\"\\nüìã Sample Results ({len(df_results)} total)\")\n",
    "display(df_results.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biggest Misses\n",
    "print(\"\\n‚ö†Ô∏è TOP 10 BIGGEST MISSES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "biggest_misses = df_results.nlargest(10, 'abs_error')\n",
    "display(biggest_misses[['player', 'date', 'prop', 'projection', 'actual', 'abs_error', 'confidence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf130e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Analysis\n",
    "print(\"\\nüìê PROBABILITY CALIBRATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"If well-calibrated: Predicted ‚âà ActualOverRate\")\n",
    "\n",
    "calibration = backtest.calibration_analysis(bins=5)\n",
    "display(calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eed446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Results\n",
    "from datetime import datetime\n",
    "\n",
    "results_dir = Path(\"data/results/props_backtests\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"props_backtest_{BACKTEST_START}_to_{BACKTEST_END}_{timestamp}.csv\"\n",
    "output_path = results_dir / filename\n",
    "\n",
    "df_results.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Exported to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
