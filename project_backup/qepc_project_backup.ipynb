{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f4a3d3-aefd-4219-8623-3d4217abdaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Project root detected: C:\\Users\\wdors\\qepc_project\n",
      "ðŸ“ Backups directory: C:\\Users\\wdors\\qepc_project\\backups\n",
      "ðŸ—‚ï¸ Backup file will be created as: C:\\Users\\wdors\\qepc_project\\backups\\qepc_backup_20251202_230610.zip\n",
      "âš™ï¸ Max single-file size: 60 MB\n",
      "\n",
      "ðŸ“¦ Files to include: 194\n",
      "ðŸ“¦ Approx compressed input size: 3.09 MB\n",
      "ðŸš« Skipped by rules: 1736 files\n",
      "ðŸš« Skipped as too large (> 60 MB): 0 files\n",
      "\n",
      "  â†’ Added 100 files so far...\n",
      "\n",
      "âœ… Backup complete!\n",
      "ðŸ§¾ Backup file: qepc_backup_20251202_230610.zip (0.77 MB)\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§¾ QEPC Project Backup (Fast / Filtered)\n",
    "#\n",
    "# This backup:\n",
    "#   - Detects the project root (folder that has both data/ and notebooks/)\n",
    "#   - Creates backups/<qepc_backup_YYYYMMDD_HHMMSS>.zip\n",
    "#   - INCLUDES: code, notebooks, configs, light data\n",
    "#   - SKIPS:\n",
    "#       * data/raw (huge CSVs you can regenerate)\n",
    "#       * notebooks/02_utilities/data/raw\n",
    "#       * backups/ (older backups)\n",
    "#       * .git, __pycache__, .ipynb_checkpoints\n",
    "#       * any single file larger than MAX_FILE_MB\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Detect project root\n",
    "# ----------------------------\n",
    "here = Path.cwd().resolve()\n",
    "project_root = None\n",
    "\n",
    "for p in [here] + list(here.parents):\n",
    "    if (p / \"data\").exists() and (p / \"notebooks\").exists():\n",
    "        project_root = p\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not detect project root. \"\n",
    "        \"Open this notebook from inside C:/Users/wdors/qepc_project or a subfolder.\"\n",
    "    )\n",
    "\n",
    "print(f\"âœ… Project root detected: {project_root}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Backup config\n",
    "# ----------------------------\n",
    "\n",
    "backups_dir = project_root / \"backups\"\n",
    "backups_dir.mkdir(exist_ok=True)\n",
    "print(f\"ðŸ“ Backups directory: {backups_dir}\")\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_name = f\"qepc_backup_{timestamp}.zip\"\n",
    "backup_path = backups_dir / backup_name\n",
    "\n",
    "# Maximum single-file size to include (in MB)\n",
    "MAX_FILE_MB = 60\n",
    "MAX_FILE_BYTES = MAX_FILE_MB * 1024 * 1024\n",
    "\n",
    "print(f\"ðŸ—‚ï¸ Backup file will be created as: {backup_path}\")\n",
    "print(f\"âš™ï¸ Max single-file size: {MAX_FILE_MB} MB\\n\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Include / exclude rules\n",
    "# ----------------------------\n",
    "\n",
    "def should_exclude(path: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if this path should be excluded from the backup.\n",
    "    Decisions are based on the path *relative* to project_root.\n",
    "    \"\"\"\n",
    "    rel = path.relative_to(project_root)\n",
    "    parts = rel.parts\n",
    "\n",
    "    # Skip backup folder itself\n",
    "    if parts[0] == \"backups\":\n",
    "        return True\n",
    "\n",
    "    # Skip git metadata / caches / checkpoints\n",
    "    if parts[0] in {\".git\", \"__pycache__\"}:\n",
    "        return True\n",
    "    if \".ipynb_checkpoints\" in parts:\n",
    "        return True\n",
    "\n",
    "    # Skip virtualenvs if any live inside the project\n",
    "    if parts[0] in {\"venv\", \".venv\", \"env\", \".env\"}:\n",
    "        return True\n",
    "\n",
    "    # Skip heavy raw data â€“ these are regenerable\n",
    "    #  - data/raw/...\n",
    "    if len(parts) >= 2 and parts[0] == \"data\" and parts[1] == \"raw\":\n",
    "        return True\n",
    "\n",
    "    #  - notebooks/02_utilities/data/raw/...\n",
    "    if (\n",
    "        len(parts) >= 4\n",
    "        and parts[0] == \"notebooks\"\n",
    "        and parts[1] == \"02_utilities\"\n",
    "        and parts[2] == \"data\"\n",
    "        and parts[3] == \"raw\"\n",
    "    ):\n",
    "        return True\n",
    "\n",
    "    # Skip existing zip/tar archives inside project (other than the one we're making)\n",
    "    if rel.suffix in {\".zip\", \".tar\", \".gz\", \".bz2\"} and parts[0] != \"data\":\n",
    "        # You can adjust this rule if needed\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Collect files to back up\n",
    "# ----------------------------\n",
    "\n",
    "files_to_add = []\n",
    "skipped_large = []\n",
    "skipped_rules = []\n",
    "\n",
    "for path in project_root.rglob(\"*\"):\n",
    "    if not path.is_file():\n",
    "        continue\n",
    "\n",
    "    if should_exclude(path):\n",
    "        skipped_rules.append(path)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        size = path.stat().st_size\n",
    "    except OSError:\n",
    "        continue\n",
    "\n",
    "    if size > MAX_FILE_BYTES:\n",
    "        skipped_large.append((path, size))\n",
    "        continue\n",
    "\n",
    "    files_to_add.append((path, size))\n",
    "\n",
    "total_size_bytes = sum(size for _, size in files_to_add)\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"ðŸ“¦ Files to include: {len(files_to_add)}\")\n",
    "print(f\"ðŸ“¦ Approx compressed input size: {total_size_mb:.2f} MB\")\n",
    "print(f\"ðŸš« Skipped by rules: {len(skipped_rules)} files\")\n",
    "print(f\"ðŸš« Skipped as too large (> {MAX_FILE_MB} MB): {len(skipped_large)} files\\n\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Create the ZIP\n",
    "# ----------------------------\n",
    "\n",
    "with zipfile.ZipFile(backup_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    for idx, (path, size) in enumerate(files_to_add, start=1):\n",
    "        rel = path.relative_to(project_root)\n",
    "        zf.write(path, rel)\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"  â†’ Added {idx} files so far...\")\n",
    "\n",
    "print(\"\\nâœ… Backup complete!\")\n",
    "final_size_mb = backup_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"ðŸ§¾ Backup file: {backup_path.name} ({final_size_mb:.2f} MB)\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Show what was skipped (summary)\n",
    "# ----------------------------\n",
    "\n",
    "if skipped_large:\n",
    "    print(\"\\nâš ï¸ The following large files were skipped (size > \"\n",
    "          f\"{MAX_FILE_MB} MB):\")\n",
    "    for path, size in skipped_large:\n",
    "        print(f\"  - {path.relative_to(project_root)}  ({size / (1024*1024):.2f} MB)\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece749e-0fa9-473a-8ef0-b996a1fb2ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
